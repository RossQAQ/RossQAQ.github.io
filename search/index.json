[{"content":"本文是文章 Understanding String and \u0026amp;str in Rust 的阅读翻译，查看原文。\n根据你的编程背景，Rust 的各种字符串类型可能会迷惑你，比如 String, str。这篇文章中，我们会澄清 String 和 str 的区别，更细致的说就是 String, \u0026amp;String, 以及 \u0026amp;str，尤其是决定好什么时候该用什么。\n理解了这篇文章中的内容有助于你更高效的使用 Rust 的字符串，也有助于你更好的理解他人的代码，看看别人是怎么处理字符串的。\n首先，我们需要从理论层面上来看，例如不同字符串类型的结构，以及他们在内存位置、可变性的不同之处。之后，我们会看一下实践中他们的区别，讨论如何正确使用这些类型。最后，我们会简单举例说明。\n如果你是 Rust 刚刚起步，那么这篇文章应该会很好的帮助你。它会解释为什么有的时候你的关于字符串的代码无法编译。\n理解 Rust 字符串类型们 这一部分中，我们会解释在语言层面这些类型的区别以及他们的 implications。泛泛地说，就是他们在所有权和内存层面的区别。\nRust 的所有的字符串类型总是保证为有效的 UTF-8.\n什么是 String String 是所有权类型，需要被分配。它具有动态大小，因而编译器无法知道它的大小，但它内部的数组的容量可以随时改变，这个类型自己基本是以下形式：\n1 2 3 pub struct String { vec: Vec\u0026lt;u8\u0026gt;, } 因为它包含了一个 Vec，我们知道它有一个指向一个区块的指针，一个 size 以及一个 capcity。size 是字符串的有效长度，capcity 告诉我们字符串的长度最大在多少时需要重新分配内存。指针指向一个连续的字符数组，capcity size 都在它内部了。\nStrings 非常的灵活，我们总是可以创建一个新的，动态的可修改的字符串。但这也一些开销，我们总是需要分配内存。\n什么是 \u0026amp;String \u0026amp;String 类型是 String 的引用。这意味着它不是一个拥有所有权的类型，它的大小在编译期是可知的，因为它只是一个指向 String 的指针。\n关于 \u0026amp;String 没有太多可以说的内容。但因为它没有所有权，我们可以到处传递 \u0026amp;String，只要我们引用的内容没有出作用域，我们并不需要担心内存分配。\n大多数情况下，String 和 \u0026amp;String 的区别基本是在借用上。\n有意思的一件事是，\u0026amp;String 可以在编译期被 Rust deref 为 \u0026amp;str。这在 API 的灵活性上很有用。但反之是不行的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 fn coerce_success(data: \u0026amp;str) { println!(\u0026#34;{}\u0026#34;, data); } fn coerce_fail(data: \u0026amp;String) { println!(\u0026#34;{}\u0026#34;, data); } fn main() { let s = \u0026#34;hello_world\u0026#34;; let mut mutable_string = String::from(\u0026#34;Hello\u0026#34;); coerce_success(\u0026amp;mutable_string); coerce_fail(s); } 什么是 \u0026amp;str 最终，我们看看 \u0026amp;str，因为 \u0026amp;str 由指向内存的指针组成（包括一个 size），它的 size 在编译期是已知的。\n内存可以是 heap，stack，或者是二进制可执行文件的 static 内存。**它也不是一个所有权类型，而是一个对字符串切片的只读引用。**Rust 保证当 \u0026amp;str 在作用域内时，底层的内存不会改变，即使跨线程。\n就像上文说的，\u0026amp;String 可以转换为 \u0026amp;str，这意味着 \u0026amp;str 作为函数的参数很好用（如果不需要所有权和可变形的话）。\n\u0026amp;str 在需要一个字符串切片（视图）时很好用。然而，记住 \u0026amp;str 只是一个指向 str 的指针，而 str 的大小在编译期不可知，而它天然时不可变的，所以 capcity 也不可变。\n很重要的是，像上文提到过的，\u0026amp;str 指向的内存中 \u0026amp;str 存活期间是不可变的，即使是 str 的所有者也不行。\n实践中 \u0026amp;str 的含义 理解了上面的概念那么你就可以让代码过编译了。\n此外，还有一些 API 的语义表达，以及一些性能方面的考虑。\n在性能方面，你需要考虑知道创建一个 String 总是需要内存分配。如果你可以避免额外的分配，那你就应该这么做，因为他们需要一些时间以及对你的运行时造成一些负担。\n嵌套循环的示例 考虑一个情况，在一个嵌套的循环中，你总是需要某一个字符串的不同部分。如果你每次创建一个 String，那么你每次都要为子串分配内存，以及还要做一大堆其他事情。而实际上你仅仅需要 \u0026amp;str 的字符串切片。\n同样的事情在传递数据时也会发生，如果你到处传递拥有所有权的 String 实例而不是可变借用（\u0026amp;mut String）或者是他们的只读视图，那么就会发生很多本可以避免的内存分配。\n所以为了性能，知道什么时候发生内存分配以及你什么时候不需要分配是很重要的，因为你可以重用字符串的切片。\nAPI 设计 谈到 API 的设计，那么事情就有一些复杂了，你需要在心中明确的了解你的 API 目标，并且为你的用户选择一个正确的类型来达成这个目标。\n例如，因为 \u0026amp;String 可以转换为 \u0026amp;str，但不能反过来，所以如果只需要一个只读的字符串视图，那么在参数中使用 \u0026amp;str 一般是正确的。\n此外，如果一个函数需要修改给定的 String，就完全不能传递 \u0026amp;str 了，因为它是不可变的，你需要创建一个新的 String 之后它会返回。如果你需要修改，那么使用 \u0026amp;mut String\n拥有所有权的字符串 在你需要具有所有权类型的字符串时需要思考这些事，例如你需要把字符串传给一个线程，或者需要创建一个成员中具有所有权字符串的结构体时。这些情况下，你需要直接使用 String，因为 \u0026amp;String 和 \u0026amp;str 都是借用的类型。\n在某些情况下，所有权和可变性都很重要，在 String 和 \u0026amp;str 之间的选择很重要。在大部分情况下，你用了不正确的类型都会无法编译，如果你对这些类型的属性以及它们之间的转换没有正确的理解的话，你可能会写出迷惑的 API。\n我们看看例子。\nString 和 \u0026amp;str 用法的例子 以下的示例展示了上面提到的一些情况，以及包含一些解决的方法。\n记住，这些都是独立的、人为设置的例子，在实际中还要考虑其他的因素，然而，你可以把这个当作基本的宗旨。\n常量字符串\n这是最简单的例子，如果你需要一个字符串常量，那么推荐采用以下的方式\n1 const CONST_STRING: \u0026amp;\u0026#39;static str = \u0026#34;some constant string\u0026#34;; CONST_STRING 是只读且满足静态生命周期的字符串，在执行中被直接装入内存。\n字符串可变性\n如果你有一个 String，你想在函数中修改它，那么你可以使用 \u0026amp;mut String 作为参数\n1 2 3 4 5 6 7 8 9 fn main() { let mut mutable_str = String::from(\u0026#34;hello\u0026#34;); do_some_mutation(\u0026amp;mut mutable_string); println!(\u0026#34;{}\u0026#34;, mutable_string); } fn do_some_mutation(input: \u0026amp;mut String) { input.push_str(\u0026#34;add this to the end\u0026#34;); } 但要注意的是如果长度超过 capcity，那么也会重新分配内存。\n具有所有权的字符串\n当你想从函数中返回字符串，或者你想把所有权也一并传递给其他线程等\n1 2 3 4 5 6 7 8 fn main() { let s = \u0026#34;Hello World\u0026#34;; println!(\u0026#34;{}\u0026#34;, do_something(s)); } fn do_something(intput: \u0026amp;str) -\u0026gt; String { input.to_ascii_uppercase(); } 1 2 3 4 5 6 7 struct Owned { bla: String, } fn create_owned(other_bla: String) -\u0026gt; Owned { Owned {bla: other_bla}; } 只读参数/切片 如果不需要修改字符串，用 \u0026amp;str 作为参数类型即可，String 也可以用，因为 \u0026amp;String 可以被 deref 为 \u0026amp;str。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 const CONST_STRING: \u0026amp;\u0026#39;static str = \u0026#34;some constant string\u0026#34;; fn main() { let s = \u0026#34;hello_world\u0026#34;; let mut mutable_string = String::from(\u0026#34;hello\u0026#34;); print_something(\u0026amp;mutable_string); print_something(s); print_something(CONST_STRING); } fn print_something(something: \u0026amp;str) { println!(\u0026#34;{}\u0026#34;, something); } 如你所见，我们可以使用 \u0026amp;String, \u0026amp;'static str，以及 \u0026amp;str 作为输入的参数。\n在结构体中使用 Rust 的字符串类型 结构体中我们可以使用 String 和 \u0026amp;str，主要的问题是看你的结构体是否需要拥有某个字符串的所有权。如果你使用 \u0026amp;str，那么你需要使用 Rust 的生命周期标注，保证结构体对象存活时间不长于它借用的字符串，否则就会无法编译。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 struct Owned { bla: String, } struct Borrowed\u0026lt;\u0026#39;a\u0026gt; { bla: \u0026amp;\u0026#39;a str, } fn create_something() -\u0026gt; Borrowed { let o = Owned { bla: String::from(\u0026#34;bla\u0026#34;), }; let b = Borrowed {bla: \u0026amp;o.bla}; b } 这个代码无法通过编译，因为 Borrowed 中的值存活的时间比 O 更长。\n这样写即可：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 struct Owned { bla: String, } struct Borrowed\u0026lt;\u0026#39;a\u0026gt; { bla: \u0026amp;\u0026#39;a str, } fn main() { let o = Owned { bla: String::from(\u0026#34;bla\u0026#34;), }; let b = create_something(\u0026amp;o.bla); } fn create_something(other_bla: \u0026amp;str) -\u0026gt; Borrowed { let b = Borrowed { bla: other_bla }; b } Rust 的字符串操作 Rust 提供了很多 built-in 方法来操作字符串，我们会在这一部分中探索一下。\nRoses：终于到重点了，想必上面的内容对 C++ 程序员来说不成问题。\nRust 的字符串切片 可以使用字符串切片来引用字符串的子集。使用两个中括号+数字的形式来切片，自然也是左闭右开。\n1 2 3 4 let hello_world = String::from(\u0026#34;hello world\u0026#34;); let ello = \u0026amp;hello_world[1..5]; let orld = \u0026amp;hello_world[7..11]; 省略左侧数字可以从 0 开始，省略右侧数字可以直接索引到最后一个字符。\n可以这样引用整个 String，\n1 let hello_world_ref = \u0026amp;hello_world[..]; 如前文所说，Rust 把存储的字符串是 UTF-8 编码的顺序字节，也就是说，上面的例子只对 单字节 的字符有效。如果你的字符由多个字节组成，你就必须中字符的边缘切片。否则 Rust 就会 panic，因为你中多个字节组成的字符的中间切片来。\n例如，❤️这个emoji，就是6个字节编码而成，6～11 之间的索引都用来表示这个 emoji，也就是说，start_index 和 end_index 在 6～12 之间都会 panic。\n1 2 3 4 let hello_love = String::from(\u0026#34;hello ❤️\u0026#34;); let heart = \u0026amp;hello_love[6..12]; let broken_heart = \u0026amp;hello_love[6..8]; //error 使用 contains 来进行模式匹配 contains 方法，就像它的名字表示的一样，是检查一个字符串切片的位置。你可以使用它来检查一个字符串切片是否是另一个字符串的子集。返回值是 bool。\n传递给它的参数必须是 \u0026amp;str ，char，或者 chars 的切片。\n使用 starts_with 来进行模式匹配 在 Rust 中，你可以使用 start_with 方法来检查一个字符串切片是否以另一个字符串开头。返回值也是 bool。\n注意这个方法大小写敏感。\n使用 find 来进行模式匹配 find 方法会查找模式在字符串切片中第一次出现的位置，返回值是 Option。\n注意这个方法也是大小写敏感。\n使用 rfind 来进行模式匹配 rfind 和 find 非常像，它是查找一个字符串最后出现的位置，返回值也是 Option。\nRust 中的字符串转换 Rust 中转换为字符串 你可以使用 to_string 方法将任何实现了 ToString trait 的类型的值转换为字符串。\n1 2 3 4 5 6 7 8 9 10 let my_bool: bool = true; let my_int: i32 = 23; let my_float: f32 = 3.14; let my_char: char = \u0026#39;a\u0026#39;; println!(\u0026#34;{}\u0026#34;, my_bool.to_string()); println!(\u0026#34;{}\u0026#34;, my_int.to_string()); println!(\u0026#34;{}\u0026#34;, my_float.to_string()); println!(\u0026#34;{}\u0026#34;, my_char.to_string()); 实现了 Display trait 的类型天然实现了 ToString，你就不需要再实现一次了。\n前文提到 Rust 中主要有两种字符串类型。有时你需要把一种转换为另外一种。你可以使用 String::from 把字符串切片转换为 String\n1 let my_string = String::from(\u0026#34;Hello World\u0026#34;); 相反，可以使用 as_str 方法把 String 转换为字符串切片，as_str 方法借用了底层的数据。\n1 2 let my_string = String::from(\u0026#34;Hello World\u0026#34;); let my_string_slice = my_string.as_str(); 解析字符串 你可能会写把字符串类型解析为其他类型，他们需要实现 FromStr trait。parse 方法就可以使用了。\n1 2 3 let my_string = \u0026#34;10\u0026#34;; let parsed_string: u32 = my_string.parse().unwrap(); 因为你要把字符串解析为其他类型，所以你需要显式指明类型，就像例子一样。Rust 文档中提供了 实现 FromStr trait 的 built-in 类型，关于 trait 可以看 Rust traits: A deep dive\n之后会尝试翻译。\n除了中前面指明类型，你还可以用 Rust 的 \u0026ldquo;turbofish\u0026rdquo; 语法，即：\n1 2 3 let my_string = \u0026#34;10\u0026#34;; let parsed_string = my_string.parse::\u0026lt;u32\u0026gt;().unwrap(); 如果你使用 parse 方法，需要确保字符串提供了有效的字符。你正在解析的字符串可能包含无效字符，比如 units，尾随的空格，locale 的格式，例如千分隔符。\n你可以使用 built-in 的 trim, trim_start, trim_matches, replace 来移除这些字符，这样你就可以正确解析了，就像例子：\n1 2 let price = \u0026#34; 200,000 \u0026#34;; println!(\u0026#34;{}\u0026#34;, price.trim().replace(\u0026#34;,\u0026#34;, \u0026#34;\u0026#34;).parse::\u0026lt;u32\u0026gt;().unwrap()); 类似的，你解析的字符表示的数字可能会溢出，注意潜在的错误。\nparse 返回的是一个错误，如果不能解析成制定类型的话。注意正确的进行错误处理。\n如果有更加复杂的解析需求，使用 regex crate，它有一些 rust build-in 没有的能力。\n1 2 3 4 5 6 7 8 use regex::Regex; fn main() { let price = \u0026#34;$ 1,500\u0026#34;; let regx = Regex::new(r\u0026#34;[^0-9.]\u0026#34;).unwrap(); println!(\u0026#34;{}\u0026#34;, regx.replace_all(price, \u0026#34;\u0026#34;)); } 总结 本文探索了 Rust 中 String str 两个类型的字符串，看了看应该如何正确使用它们。我们也提供了很多示例代码来解释两个字符串类型常规的使用情况。\n我希望这篇文章可以解决你的关于 Rust 字符串的困扰，帮助你写出更高效的 Rust 代码。\n","date":"2024-07-04T00:00:00Z","permalink":"https://rossqaq.github.io/article/rust-string-types/","title":"理解 Rust 的各种字符串类型"},{"content":"Linkers, Loaders and Shared Libraries in Windows, Linux, and C++ - Ofek Shilon - CppCon 2023 - YouTube\n术语 演讲使用同一个术语指代不同平台下的事物，\n动态库（Shared Library）\n指代：shared object, dynamic object, dynamic shared object, DLL, dynamic shared library\n二进制文件（Binary）\n指代：可执行文件 / 动态库，模块，组件\n符号（Symbol）\n指代：函数 / 全局变量\nLinux\n指代：所有 unix-like 系统，大部分情况下包括 MacOS（有一个不同）\n链接简介 源文件经过编译器处理之后，就变成了 object 文件，它包含了一堆区域，存放了程序的代码、数据等等。链接器做两件事，把分散在不同 object 文件中的同名区域放在一起，把它们拼接成更大的区域；其次把这些区域重排，把对运行时有类似需求的区域在硬盘上相邻排列。最后，loader 把这些相邻的区块取出，称之为段，以页对齐的要求映射到内存中。映射之后，调整每个段的权限。\n","date":"2024-06-29T00:00:00Z","image":"https://rossqaq.github.io/cppcon2023-cover.png","permalink":"https://rossqaq.github.io/article/cppcon-2023-lib/","title":"linker, loader, 以及动态库"},{"content":"本文是系列博客 How I Finally Understood async/await in Rust - p2 的精读翻译，只翻译了重要的内容。\n原博客：how I finally understood async/await in Rust (part 2) - hēg denu - Hayden Stainsby (hegdenu.net)\n序言 这是我理解 Rust async/await 的系列文章之二，你并不是我，但我希望这篇文章可以帮助你。\n之前的文章，我们了解了最简单的异步函数，然后我们写了一个自定义的 future，通过这个 future，我们理解了为什么我们的 future 是异步的；为什么在被 awaited 前它不会执行任何东西。在前文中，一个很重要的部分被我们跳过了。\n我们的 future 只返回 Poll::Ready，那么 pending 的 future 呢？我们来看看返回 Poll::Pending 会怎么样。\n如何唤醒 pending 的 future 首先，我们回顾一下 future 被 poll 的时候发生了什么。\n可以创建一个比上一节更简单的 future。\nReady future 这个 future 除了返回 Poll::Ready 外，什么都不会做。\n我们甚至都不需要给它实现什么成员。\n所以我们一个 unit struct，给它实现 Future\n1 2 3 4 5 6 7 8 9 10 11 12 use std::{future::Future, task::Poll}; struct Ready; impl Future for Ready { type Output = (); fn poll(self: std::pin::Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut std::task::Context\u0026lt;\u0026#39;_\u0026gt;) -\u0026gt; Poll\u0026lt;Self::Output\u0026gt; { println!(\u0026#34;Ready: Poll\u0026#34;); Poll::Ready(()) } } 我们不需要返回值，所以 Output 是 unit 类型 ()。Poll 的实现也非常简单，单纯的返回一个 Poll::Ready(())\n虽然它已经很简单了， 但我们还是看一下他的状态图。\n显然，这个 future 里没有 state。此外，如果这个 future 被不正确的多次 poll 也没有任何处理的后续。\n总而言之，它非常简单。\n现在，我们把 future 包装成一个函数。\n1 2 3 fn ready() -\u0026gt; Ready { Ready{} } 我们返回的是一个实现了 Future trait 的 Ready unit 结构图，因为它实现了 Future，所以我们可以 await 它。\n（不要把这个 Ready future 和 Poll::Ready 混淆）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 use std::{future::Future, task::Poll}; struct Ready; impl Future for Ready { type Output = (); fn poll(self: std::pin::Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut std::task::Context\u0026lt;\u0026#39;_\u0026gt;) -\u0026gt; Poll\u0026lt;Self::Output\u0026gt; { println!(\u0026#34;Ready: Poll\u0026#34;); Poll::Ready(()) } } fn ready() -\u0026gt; Ready { Ready {} } #[tokio::main] async fn main() { println!(\u0026#34;Before ready().await!\u0026#34;); ready().await; println!(\u0026#34;After ready().await\u0026#34;); } 在 .await 的背后，是 poll 函数被调用了，它直接返回 Poll::Ready，结果直接被返回给 caller。为了完整性，以下是使用 Ready future 的时序图。\n这个 future 在你只想要一个永远返回 Ready 的 future 的测试的时候很有用，实际上，其他人也这么想。\n在 futures crate 中有一个泛型版本的 futures::future::ready\n我们想知道的不仅仅是返回 Poll::Ready，我们继续。\nPending future 我们来实现 Ready future 的另外一个版本，这一次让它返回 pending，我们把这个结构体也命名为 Pending，之后为其实现 Future trait.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 struct Pending; impl Future for Pending { type Output = (); fn poll(self: std::pin::Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut std::task::Context\u0026lt;\u0026#39;_\u0026gt;) -\u0026gt; Poll\u0026lt;Self::Output\u0026gt; { println!(\u0026#34;Pending: poll()\u0026#34;); Poll::Pending } } fn pending() -\u0026gt; Pending { Pending {} } 同理，不要把这个 Pending 结构体和 Poll::Pending 搞混。\n你可能会问，为什么在函数中包装 futures 呢？\n有两个原因。首先是因为风格，在这个系列的博客中，我们一直在探讨 async/await 背后到底发生了什么，所以把函数和函数放在一起对比比较好。总之，就是看到一个能被 await 的函数就像是 async 函数原本应该是的样子。\n原因二是抽象，如果在我们自己的函数中构造 future，我们可以把 API 细节对用户隐藏，甚至阻止用户从我们的 crate 或者 模块 外部构造我们的 future，这可以让兼容性提高。甚至，我们不需要返回我们的 future 类型，只是返回某些直线了 Future trait 的对象即可。\n1 2 3 fn pending() -\u0026gt; impl Future\u0026lt;Output = ()\u0026gt; { Pending {} } 可以看到，我们完全不需要让 Pending 是 public。\n我们并不需要关注我们的返回类型到底是什么（Pending / impl Future\u0026lt;Output = ()\u0026gt;），我们试试刚才实现的 future。\n结果会是：\n1 2 Before poll().await! Pending: poll() 这个程序永远不会终止，它也不会吃满 CPU，也不会阻塞任何线程，但它只能执行到这里。\npoll() 只被调用了一次。看起来这个 future 是有问题的，但它也能在很多场景下发挥作用，比如测试。\n就像上一节的 ready() 一样，在 futures crate 中也有一个泛型版本的 pending，futures::future::pending。\n为什么 Pending 会让我们的程序挂起？\n看一下状态图。\n我们在通往 Final 的箭头上使用了虚线，代表它永远不会被 drop。\n时序图如下，\n也很明确。\n为什么我们的程序不会继续执行了呢？我们发现我们的 future 返回了 Poll::Pending 给我们的 async main() 函数，然后没有看到后面的 println!() 被调用，我们需要深入的了解一下背后发生了什么。\n解构 async main 我们需要了解 async main() 到底是怎么工作的。\n尤其是宏 #[tokio::main] 做了什么。\n这一部分是 .await 背后的行为，我们看看这个宏\n1 2 3 4 5 6 7 8 9 10 11 12 13 fn main() { let body = async { println!(\u0026#34;Before pending().await\u0026#34;); pending().await; println!(\u0026#34;After pending().await\u0026#34;); }; return tokio::runtime::Builder::new_multi_thread() .enable_all() .build() .expect(\u0026#34;Failed building the Runtime\u0026#34;) .block_on(body); } 可以通过 Rust Analyzer 的宏展开来查看。\n我们可以看到原来的函数体会自动被放进一个 async 函数块内，之后创建一个新的运行时并且把 async 函数块给它来执行。\n（使用 block_on 来把 future 给运行时，并等待它执行完。）\n一个 async 块也是一个 future。\n现在我们就知道 async main 到底做了什么了，所以可以升级一下我们的时序图。\n可以看到，实际上是异步运行时替我门调用了 poll() ，main future await pending future，还有一点很重要，当一个 future await 了另外一个返回 Poll::pending 的 sub-future 的时候，它自己也会给 caller 返回 Poll::Pending。\nRoses: 这是一个串联的任务关系。\n这种情况下，会返回到异步运行时，当任务被 poll 然后返回 Poll::Pending 后，任务自身会 sleep。\n之后异步运行时会选择另外一个任务来 poll（当然也有可能 poll 到同一个 task，如果它准备好了的话）\n（被调度 poll 意味着 被唤醒）\n这种情况下，异步运行时会 park 线程直到任务被唤醒。\n问题来了：什么时候任务会被唤醒？\n答案：当 waker 唤醒它的时候。\n那么什么是 waker？怎么获得一个 waker？\nThe Waker 提到 waker 的时候，指的均是 std::task::Waker. 它是一个标准库提供的结构体，文档的说法是：waker 是在任务准备好时通知其执行器唤醒任务的一个 handle。\n我们知道了可以用 waker 来唤醒任务。你需要在任务的 waker 上调用 wake() 或者 wake_by_ref()。\n之后任务会被唤醒然后继续被 poll。\n如何为我们的任务写一个 waker？\n这需要我们深入 p1 中被跳过的 context。\nContext The context is the way that information about the current async task is given to a future.\n我们讨论的是 std::task::Context，虽然在 p1 中它被跳过了，但实际上它并不复杂。文档的描述是：目前，Context 只提供 \u0026amp;Waker 来唤醒当前的任务。\n就这么简单。\n实际上，context 只有两个方法，第一个是 from_waker()，通过 waker 的引用来构造一个 context；第二个是 waker()，接收 context 的引用如何返回 waker 的引用。\n实际上，我认为 Context 的构造只是出于未来 API 的设计。\n我们来实现一个不会一直 pending 的 future 吧。\n不会永远 pending 我们用最简单的方法来实现一个 future，返回 Poll::Pending，但不会一直挂起我们的程序。\n有两个需要更改的地方，一个是只返回一次 Poll::Pending，但这还不够，poll() 不会在任务被唤醒的时候调用，所以第二步是唤醒我们的任务。我们可以在返回 Poll::Pending 前做这个。\n（这是最简单的方式，在 tokio-console 中被称之为 self wake）\n我们把这个 future 称之为 YieldNow，与 Ready 和 Pending 不同，我们需要它有一些状态。\n来看一下代码，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 struct YieldNow { yielded: bool, } impl Future for YieldNow { type Output = (); fn poll( mut self: std::pin::Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut std::task::Context\u0026lt;\u0026#39;_\u0026gt;, ) -\u0026gt; Poll\u0026lt;Self::Output\u0026gt; { println!(\u0026#34;YieldNow: poll()\u0026#34;); if self.yielded == true { return Poll::Ready(()); } self.yielded = true; cx.waker().wake_by_ref(); Poll::Pending } } YieldNow 只有一个字段，决定了我们有没有 yielded。这个语境下 yielding 代表控制流返回给异步运行时。如果我们已经 yielded，那么就返回一个 Poll::Ready；如果没有的话，就把这个字段设置为 true，之后我们唤醒 waker，最后，返回 Poll::Pending。\n但我们已经唤醒了我们的任务，这表示任务准备好再次被 poll 了。\n现在任务不会被阻塞了，然后把它包装到函数中：\n1 2 3 fn yield_now() -\u0026gt; YieldNow { YieldNow { yielded: false } } 现在我们的输出会是：\n1 2 3 4 Before yield_now().await YieldNow: poll() YieldNow: poll() After yield_now().await 我们可以清楚的看到 poll 被调用了两次。\nYield Now 正如前文提到的，我们把将控制流返回给运行时称之为 yielding。\n每次在 await 点返回 pending 时都会发生。\n（如果你有自定义的 future 直接调用了 poll()，可能不适用于这种情况）\n我们的 yield_now() 是自愿把控制权让给运行时的。自愿是因为这个任务实际上没有等待任何事情，可以继续执行。\n这个函数的命名来自于 Tokio, tokio::task::yield_now.\n我们来看看它的状态图。\n我们把 poll() 的返回值也在转换图中包括了进去，future 从 yielded = false 开始，第一次被 poll 时，返回 Poll::Pending() 并且将状态转换为 yielded = true，之后，future 会在下一次调用 poll 时返回 Poll::Ready(())，这个状态机没有特别复杂，有意思的部分是时序图，来看一下。\nYieldNow future 和 Pending future 很像，直到他对 waker 调用了 wake_by_ref()，之后 waker 调用异步运行时的 schedule() 来恢复执行当前任务\n（并不是完全跟 tokio 内部发生的事情吻合）\n现在，任务已经被调度了。\n于是我们看到了它与返回 Poll::Pending 的任务的区别。异步运行时现在有了一个任务准备去 poll，所以并不会 park 线程，而是又一次直接 poll 任务。这一次，我们的 YieldNow future 返回了 Poll::Ready，因为我们调用 block_on 的任务已经完成了，所以运行时把控制流返回到 main()，之后返回 future 的值。\n虽然这里是一个 unit type。\n现在我们已经理解了 pending 的 future 是怎么被唤醒了！\n","date":"2024-06-15T00:00:00Z","permalink":"https://rossqaq.github.io/article/rust-async-await-p2/","title":"如何理解 Rust 的 async/await？(p2)"},{"content":"本文是系列博客 How I Finally Understood async/await in Rust - p1 的精读翻译，只翻译了重要的内容。\n原博客：how I finally understood async/await in Rust (part 1) - hēg denu - Hayden Stainsby (hegdenu.net)\n序言 我一开始并不能理解 async, .await 这两个关键字背后的魔法，这使得我困惑于为什么我要写这样的代码？\n我想要分享一下最终我是怎么理解 Rust 的异步的。\n我们会探索一些我遇到过的问题，共四篇文章。\n首先需要回答的问题是\n为什么要写一个关于 async/await 的教程 目前已经有很多 beginner 教程了，为什么我还要写呢？从个人的角度来说，这些文章都没有让我顿悟。这也很正常，因为每个人都有不同的学习方式，可能没有文章能突然让你顿悟，或者你可能理解不了某些部分，然后你需要阅读一些其他文章补足这些部分。\n这些文章记录了我最终是如何理解异步的，如果能帮到你那就最好了。\n其他的文章推荐：\nLet\u0026rsquo;s talk about this async by Conrad Ludgate Pin and suffering by Amos (fasterthanlime) How to think about async/await in Rust by Cliff L. Biffle 为什么如果我不使用 await，就无事发生？ 刚接触 Rust 异步的新人可能会遇到的第一个问题就是，什么都没发生。\n1 tokio::time::sleep(std::time::Duration::from_millis(1000)); 这并不会 sleep，编译\t器会警告你这行代码无法正常工作：\n1 = note: futures do nothing unless you `.await` or poll them 我们来修复它：\n1 tokio::time::sleep(std::time::Duration::from_millis(1000)).await; 好了现在就可以正常 sleep 了。但，为什么？\n通常调用一个普通函数会立刻执行其函数体，那 async 函数特殊在哪呢？\n为了理解这个，我们来看一个简单的异步函数\n最最简单的异步函数 我们来启动一个并不异步的异步函数，看起来可能很蠢，但会帮助我们理解问题：\n1 2 3 async fn hello(name: \u0026amp;\u0026#39;static str) { println!(\u0026#34;hello, {name}\u0026#34;); } 然后我们需要在一个异步上下文中调用这个函数：\n1 2 3 4 #[tokio::main] async fn main() { hello(\u0026#34;world\u0026#34;).await; } 现在就可以正常运行了。\n我们都知道，如果移除了 .await 那么函数就不会执行，为什么呢？\n我们来写一个自己的 future 完成这个事情，\n特别地，我们需要实现 trait std::future::Future。\n什么是 future？\nfuture 代表了异步计算，直到操作完成你都可以一直持有 future，future 可以让你稍后访问计算的结果。\n这是一个在任何语言中都常见的通用的概念。\nfuture 的名字于 1977 年被提出，也并不是什么新东西了。(Futures_and_promises)\n我们需要知道的是，future 允许你使用异步运行时。通过 .awaiting 它，运行时会在稍后把结果给你。\n最最简单的 future 让我们把最简单的异步函数改为一个 future，一个 future 一般来讲有几个状态。\n实际上，大多数 future “基本上是” 状态机。\n状态机通过异步运行时来驱动它的状态，最少也需要两个状态，Init ，Done\nInit 状态是 future 的起始状态，Done 是 future 完成后的状态。非常简单。\n所以我们的 future 会建模为 enum\n在 Init 状态，我们需要保存传递给异步函数的参数。\n1 2 3 4 enum Hello { Init {name: \u0026amp;\u0026#39;static str}, Done, } 这怎么跟 C++ 协程这么像。协程本身确实也带有异步的色彩，但更灵活。\n状态转换图 根据以上：future 就是一个状态机，我们可以画出状态转换图\n之后实现 poll 的时候我们会写代码。\n总而言之，我们的 Hello 枚举在构造时就会转换为 Init 状态，某些东西调用它的 poll()，将其转换为 Done 状态。\n现在，对象仅能够被 dropped。\n目前它还不是个 future，所以也不能被 await，我们需要为其实现 Future trait\n这个跟 C++20 协程真的真的非常像，应该不是我思维混淆了吧。\n简单版本的 Future trait 我们先看一看比较简单的 std::future::Future trait\n首先，看一下：\n1 2 3 4 5 6 pub trait Future { type Output; // 要求 fn poll(self: Pin\u0026lt;\u0026amp;mut Self\u0026gt;, cx: \u0026amp;mut Context\u0026lt;\u0026#39;_\u0026gt;) -\u0026gt; Poll(Self:Output); } Future trait 声明了关联类型 Output，这是异步函数返回的类型。我们的 hello 函数什么都不返回，所以暂时跳过这里。\n还有一个方法，其参数接收一个 self 的可变引用以及一个可变的 Context，self 的引用被 pin 住。\n现在我们还不需要理解 pin，现在需要理解的是 \u0026amp;mut self，目前也不需要 Context，故跳过。\npoll 方法返回的是 std::task::Poll 枚举，该方法在仍然有工作没完成的情况下返回 Pending，当 future 可以返回时，就返回 Ready(T)。T 就是 Future 的关联类型 Output。\n以上，暂时不理解的地方都先跳过即可。\n实现 poll 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 use std::{future::Future, pin::Pin, task::Context}; impl Future for Hello { type Output = (); fn poll(mut self: Pin\u0026lt;\u0026amp;mut Self\u0026gt;, _cx: \u0026amp;mut Context\u0026lt;\u0026#39;_\u0026gt;) -\u0026gt; Poll\u0026lt;Self::Output\u0026gt; { match *self { Hello::Init {name} =\u0026gt; println!(\u0026#34;hello, {name}!\u0026#34;), Hello::Done =\u0026gt; panic!(\u0026#34;Please stop polling me~\u0026#34;), }; *self = Hello::Done; Poll::Ready(()) } } 我们一点一点的看，首先我们的异步函数不返回值。\n这意味着 Output 使用 unit type ()\n实际开发中，我们的异步函数通常都是这样。\n让我们看看 poll 的实现，关注点在 *self 上，记住，Hello 是一个枚举。\n如果我们处于初始状态 Init，那么就打印 hello, {name}!，这是我们异步函数的函数体。\n如果我们处于 Done 状态，就 panic。\n在 match 语句之后，我们将状态设置为 Done. 最后，返回 Ready(())\n记住，不返回任何值的函数实际上返回的是 unit type。\n然后，我们来看看怎么使用，但首先需要讨论一下 pending。\n关于是 Poll::Pending 和 panic!\npending futures 这个 future 非常简单，第一次被 poll 时会变成 ready 状态。\n但如果情况不是这样呢？\n这就是 Poll::Pending 的作用，之后我们会看如何使用 Pending。\nfuture panic panic 是干什么的？\nfuture 是一个 one shot 对象。一旦完成，就会返回 Ready(T)，然后就不能再调用它了。\n官方文档的描述如下：\nPanics Once a future has completed (returned Ready from poll), calling its poll method again may panic, block forever, or cause other kinds of problems; the Future trait places no requirements on the effects of such a call. However, as the poll method is not marked unsafe, Rust’s usual rules apply: calls must never cause undefined behavior (memory corruption, incorrect use of unsafe functions, or the like), regardless of the future’s state.\ntrait 并不强制要求 future panic，但实践中这是一个比较符合逻辑的操作。\n使用 future 我们需要构造 future 然后使用它，先将其包装成一个异步函数\n1 2 3 fn hello(name: \u0026amp;\u0026#39;static str) -\u0026gt; impl Future\u0026lt;Output = ()\u0026gt; { Hello::Init{ name } } 注意到这个函数 没有 被标记 async，这是因为我们正在使用一个手写的 future，不需要 async 关键字。\n所以我们返回的是 impl Future\u0026lt;Output = ()\u0026gt;\n翻译：实现了 Future trait 且关联类型对象是 unit type 的对象。\n我们也可以直接返回 Hello，效果是一样的，因为 Hello 也实现了 Future trait.\n函数体呢？\n我们构造了枚举中的 Init 状态然后返回它，现在，异步函数如果不 await 就不会执行任何行为的原因就很清楚了。\n因为我们本来也什么都没干，只是返回了一个构造出的对象，啥都没运行。\n我们要调用我们的 future，我们不能直接调用 poll()，因为没有传给他的 Context。\n（我们也不能创建一个 Context，不过这个以后再说。记住我们要理解的是如何使用 async/await，而不是异步运行时）\n幸运的是，await 关键字在我们手写的 future 上也可以正确运行。\n以下是 main 函数，注意关键字 async，我们必须在 await future 的语境中使用。\n1 2 3 4 #[tokio::main] async fn main() { hello(\u0026#34;world!\u0026#34;).await; } 很无聊，运行结果和之前的异步函数是一样的。\n时序图 Hello future 的时序图：\n看起来我们的 async main() 没有直接调用 poll()，但要记住，main 也是被 polled，所以它可以调用 Hello 的 poll()。\n（指拥有 context ，但现在先不讨论 context）\n","date":"2024-06-06T00:00:00Z","permalink":"https://rossqaq.github.io/article/rust-async-await/","title":"如何理解 Rust 的 async/await？"},{"content":"这几天一直在玩博德之门，终于想起来更新博客了。这次的 TCP Receiver 比上次的 Reassembler 简单多了…虽然有两个部分。\n下一次就是 TCP Sender 了，我估计可能是整个课程中最难的部分，学过 TCP 的应该都懂吧… 想想又要 close 又要处理 shutdown 又要处理重复的、未收到的部分，光想我就很累了。\n总览 p0 实现了 ByteStream，p1 实现了 Reassembler，这个模型在 TCP 中非常有用，但都不是 TCP 协议本身的内容。在 p2，会实现 TCPReceiver用来接收传入的字节流。\nTCPReceiver 从对应的 sender 接收信息（通过 receive() 方法），然后把它传给 Reassembler，写入 ByteStream。应用程序从这个 ByteStream 中读取信息，就像 p0 中你从 TCPSocket 中读取信息一样。\n同时，TCPReceiver 也要生成返回给 sender 的信息，通过 send() 方法。这些 receiver messages 是为了告诉 sender：\nfirst unassembled 字节的索引，也就是 acknowledgment number, ackno，也就是 receiver 需要的下一个字节的索引。 ByteStream 的剩余空间，即 window size 二者共同描述了 receiver 的窗口：允许 sender 发送的字节序号的范围。ackno 也是窗口的 left edge，ackno + window size 是 right edge（左闭右开）。\n在写 Reassembler 和 ByteStream 时已经完成了大部分的算法部分了；本 lab 把以上部分变成 TCP 的一部分。最难的地方是思考 TCP 如何表示流中的每个字节 —— 通常是 sequence number。\n开始 commit checkpoint 1 git fetch --all 来获取最新的代码 下载 checkpoint2 需要的代码 git merge origin/check2-startercode cmake -S . -B build 编译 cmake --build build 写 check2.md checkpoint 2：TCP Receiver TCP 是基于不可靠的 datagram 上的可靠的一对具有流量控制的字节流。TCP 连接中拥有两个参与者，每个参与者都要扮演 sender 和 receiver。\nTCP Receiver 要做的是从 sender 接收字节流，重组，然后决定需要发回的 ackno 以及流量控制。\nacknowledgement 代表着 receiver 需要的 下一个 字节的索引。sender 根据这个序号来决定是 send 还是 resend。\nflow control 代表 receiver 需要的字节索引的范围。sender 根据这个来获取 被允许 发送多少字节。\n64位 索引转换为 32位 seq number 我们根据 TCP 协议以 TCP 的方式来表示索引。上次实现的 Reassembler 使用的是 64位 的流索引，流总是从 0 开始。64位 的索引基本可以看成永远不会溢出。在 TCP 头部中，空间比较宝贵，使用的是 32位 sqeno 来表示索引，这样就要复杂一些。\n你的实现需要包装 32位 整数。TCP 的流可以非常长，没有规定 TCP 字节流的发送大小限制。索引到达 2^32-1 后需要从 0 开始重新计数。 **TCP seq number 的值开始时是随机的。**为了提高鲁棒性以及防止被旧的来自同一个 endpoint 的连接混淆，TCP 尽量保证 seq number 不会被猜出，并且不太可能重复。所以流开始时的 seq number 不为 0，而是随机的 32位 整数，叫做 ISN。这个数代表的是一个流的开始，即 SYN。剩下的 seq number 都从这个数字开始计数。 逻辑上的建立和关闭连接都要占用一个 seq number。SYN（流的开始）和 FIN（流的结束）的 control flags 被赋为 seq number，这些都要占用 一个 seq number（SYN 的是 ISN）。记住：SYN 和 FIN 并不是流本身的一部分，不是字节，它们代表的是字节流自身的开始和节数。 这些 seqnos 在每个 TCP 段的头部传输（有两个 stream，每一个都是单向的，每个流有单独的 seqnos 以及单独的随机 ISN）。可能会分开讨论 absolute sequence number 和 stream index。永远从 0 开始，并不被包装；后者是 Reassembler 中使用的，代表流需要的下一个字节的索引，从 0 开始。\n以下是举例说明，考虑一个仅有 3个 字节的字符串，\u0026lsquo;cat\u0026rsquo;，假设它的 SYN 是 seqno 2^32-2，那么有：\nelement SYN c a t FIN seqno 2^32 - 2 2^32 - 1 0 1 2 absolute seqno 0 1 2 3 4 stream index 0 1 2 在 absolute seqno 和 stream index 中转换很简单，单纯的加或减 1 即可。在 seqno 和 absolute seqno 中转换有点困难，很容易混淆。为了防止这些问题，我们把 seqno 包装为 Warp32 类型，将他和 absolute seqno（uint64_t）之间进行转换。Wrap32 是一个 wrapper type。\n已经定义好了这些 helper 函数（wrapping_integers.hh），你需要实现 wrapping_integers.cc：\nstatic Warp32 Warp32::wrap( uint64_t n, Wrap32 zero_point )\n转换 absolute seqno -\u0026gt; seqno。给出 absolute seqno 和 ISN（zero_point），返回 n 的 seqno\nuint64_t unwrap( Wrap32 zero_point, uint64_t checkpoint ) const\n转换 seqno -\u0026gt; absolute seqno。给出 Wrap32 类型的 seqno，ISN，以及一个 absolute checkpoint seqno，找到最接近 checkpoint 的对应的 absolute seqno\n注意：checkpoint 存在的意义是任何给出的 seqno 可能对应多个 absolute seqnos。例：ISN = 0，seqno 为 17 其对应的 absolute seqno 可能为 17，也可能是 2^32 + 17,2^33 + 17 等等。checkpoint 帮助你解决这种问题， 在你的实现中，使用 first unassembled index 作为 checkpoint。\n[!NOTE]\n最简单的实现会使用 wrapping_integers.hh 的 helper。wrap/unwrap 操作应该保留偏移量，两个相差 17 的 seqnos 对应两个同样相差 17 的 absolute seqnos。\n希望 wrap 的代码量只有 1行，unwrap 的代码量少于 10 行，如果你的实现代码量比较多，你可以思考一下。\n测试方法：cmake --build build --target check2\nwrap 没什么说的，注意范围是 0 ~ u32max，这里面共有 u32max + 1 个数，也就是 (1UL \u0026laquo; 32)，n 对它取余再加 zero 即可。\nunwrap 略复杂一点，首先你需要画一画数字轮盘，理解一下溢出时的行为，我们需要让他溢出，这样比较好算。需要求出距 checkpoint 的距离，我决定把它先 wrap 一下，顺时针和逆时针分别算出来比较。\n如果是顺时针方向比较小（在轮盘中，checkpoint 在左边，raw_value_ 在右边）那么自然是 checkpoint + 距离；\n如果是逆时针方向比较小（在轮盘中，raw_value_ 在左边，checkpoint 在右边）那么就是 checkpoint - 距离；\n因为包装了 checkpoint，所以最终求结果时已经是相对 zero_point 的结果了。\n但对于 raw_value_ \u0026gt;= checkpoint 的情况单独搞。\n10 行代码完全可以搞定。\n实现 TCP Receiver 这个部分实现的是 TCPReceiver，它需要：\n接收来自 sender 的消息，并且使用 Reassembler 重排 ByteStream 将 ackno 以及 window size 发给 sender 我们预期 15 行左右的代码就可以完成。\n首先，我们复习一下 TCP \u0026ldquo;sender messager\u0026rdquo; 的格式，它包含了 ByteStream 的信息。\n以下是从 TCPSender 发送给 TCPReceiver 的内容：\nTCPSenderMessage 结构包含五个字段 (minnow/util/tcp_sender_message.hh ) ，\n片开始的 seqno。如果置 SYN 位，那么这就是 SYN 位的序号，否则就是携带子串的序号。 SYN位，如果被置位，那么该片是字节流的开始，seq 包含的是 ISN —— zero point。 payload：字节流的子串（可能空）。 FIN位，如果被置位，那么 payload 代表字节流的结束。 RST位，如果被置位，那么 stream 出现错误，应该关闭连接。 1 2 3 4 5 6 7 8 9 10 11 12 13 struct TCPSenderMessage { Wrap32 seqno { 0 }; bool SYN {}; std::string payload {}; bool FIN {}; bool RST {}; // 使用了多少个 seqno size_t sequence_length() const { return SYN + payload.size() + FIN; } }; TCPReceiver 生成自己的消息发送回 TCPSender:\nTCPReceiverMessage 结构包含三个字段（minnow/util/tcp_receiver_message.hh ），\nackno，receiver 所需的 下一个 seqno。这个字段可选，如果 TCPReceiver 还没有收到 ISN 的话就为空。 window size，从当前的 ackno 开始，代表 receiver 一次希望接收的 seq 个数的大小，最大 65535 （u16 max） RST 位，如果置位，同 TCPSender::RST 1 2 3 4 5 6 struct TCPReceiverMessage { std::optional\u0026lt;Wrap32\u0026gt; ackno {}; uint16_t window_size {}; bool RST {}; }; TCPReceiver：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class TCPReceiver { public: // Construct with given Reassembler explicit TCPReceiver( Reassembler\u0026amp;\u0026amp; reassembler ) : reassembler_( std::move( reassembler ) ) // The TCPReceiver receives TCPSenderMessages from the peer\u0026#39;s TCPSender. void receive( TCPSenderMessage message ); // The TCPReceiver sends TCPReceiverMessages to the peer\u0026#39;s TCPSender. TCPReceiverMessage send() const; // Access the output (only Reader is accessible non-const) const Reassembler\u0026amp; reassembler() const { return reassembler_; } Reader\u0026amp; reader() { return reassembler_.reader(); } const Reader\u0026amp; reader() const { return reassembler_.reader(); } const Writer\u0026amp; writer() const { return reassembler_.writer(); } private: Reassembler reassembler_; }; receive() 这个方法会在每次有新的 segment 被接收时调用。该方法需要：\n如果有必要的话，设置 ISN。 第一个到达的设置了 SYN 的片的 seqno 需要设置为 ISN。你可能需要这个值，因为你要一直在 32位的 seqno/ackno 和 absolute seqno 之间转换。\n[!note]\n注意 SYN 只是一个位而已，它可以包含数据，也可以包含 FIN。\n**把数据传递给 Reassembler。**如果设置了 FIN 位，代表这一片的最后一个字节是整个字节流的结尾。记住，Reassembler 希望流的索引从 0 开始，所以你得 unwrap seqnos。\n首先要思考一下这几个 seqno 的关系。\nReassembler 所需要的 first_index 对应的是 stream_index，TCPReceiver 不管序号是多少，把它传给 Reassembler 就行。\nTCPSenderMessage 给出的 seqno 对应的是 seqno\nTCPReceiverMessage 要发送的 ackno 是 seqno + 1，类型是 Wrap32\n收到消息，判断是否 RST，然后判断是否 SYN，是 SYN 的话记录 zero_point，要把 message 插入到 Reassembler，需要 first_index 以及数据。\nackno 如何计算？ ackno 需要提醒 sender 重发未接收的数据。正常情况下则是 当前已经写入的字符 + 1 + 是否关闭。写入的字符 + 1 代表正常的 ackno，是否关闭代表是否计算 FIN 位。因为如果没有接受完，那么自然不应该计入 FIN，接收之后字节流会关闭，那自然需要计算 FIN。\nfirst_index 应该如何计算？考虑以下情况：\n片带 SYN，且携带数据。此时 first_index 为 unwrap(seqno) + 1（需要记录 zero point） 片不带 SYN 与 FIN。此时 first_index，即为 unwrap(seqno) 片仅带 FIN，此时 first_index 也为 unwrap(seqno) 片同时携带 SYN，FIN，此时 first_index 为 unwrap(seqno) + 1 记录 zero_point，unwrap 后 +1 就代表数据正式开始，对应 stream index(first_index) 为0。之后的就只需要算出unwrap 后的 seqno 跟其的差值即可。\n此外，需要处理索引不合法的错误数据。我目测就是 stream index 与 SYN 的序号相同时不合法。\n在 SYN 之前的数据一律丢弃，也就是说需要知道当前连接的状态。\nRST 在错误时发生，错误指 ByteStream 中出现错误（has_error()）或者报文中收到 RST 位，这时候要手动设置 ByteStream 的 set_error()。\n但最终我也没在 15 行内完成任务……用了25行。\n源代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // wrapping_integers.cc #include \u0026#34;wrapping_integers.hh\u0026#34; using namespace std; Wrap32 Wrap32::wrap( uint64_t n, Wrap32 zero_point ) { return Wrap32 { zero_point + static_cast\u0026lt;uint32_t\u0026gt;( n % ( 1UL \u0026lt;\u0026lt; 32 ) ) }; } uint64_t Wrap32::unwrap( Wrap32 zero_point, uint64_t checkpoint ) const { if ( raw_value_ \u0026gt;= checkpoint ) { return raw_value_ - zero_point.raw_value_; } auto wrapped_checkpoint = Wrap32::wrap( checkpoint, zero_point ).raw_value_; uint32_t counter_clockwise = wrapped_checkpoint - raw_value_; uint32_t clockwise = raw_value_ - wrapped_checkpoint; if ( counter_clockwise \u0026lt; clockwise ) { return checkpoint - counter_clockwise; } return checkpoint + clockwise; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 // tcp_receiver.hh #pragma once #include \u0026#34;reassembler.hh\u0026#34; #include \u0026#34;tcp_receiver_message.hh\u0026#34; #include \u0026#34;tcp_sender_message.hh\u0026#34; #include \u0026lt;optional\u0026gt; class TCPReceiver { public: // Construct with given Reassembler explicit TCPReceiver( Reassembler\u0026amp;\u0026amp; reassembler ) : reassembler_( std::move( reassembler ) ) {} /* * The TCPReceiver receives TCPSenderMessages, inserting their payload into the Reassembler * at the correct stream index. */ void receive( TCPSenderMessage message ); // The TCPReceiver sends TCPReceiverMessages to the peer\u0026#39;s TCPSender. TCPReceiverMessage send() const; // Access the output (only Reader is accessible non-const) const Reassembler\u0026amp; reassembler() const { return reassembler_; } Reader\u0026amp; reader() { return reassembler_.reader(); } const Reader\u0026amp; reader() const { return reassembler_.reader(); } const Writer\u0026amp; writer() const { return reassembler_.writer(); } private: Reassembler reassembler_; std::optional\u0026lt;Wrap32\u0026gt; zero_point_ {}; uint64_t ack_ {}; uint64_t stream_index_ {}; bool connected_ {}; }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // tcp_receiver.cc #include \u0026#34;tcp_receiver.hh\u0026#34; #include \u0026lt;numeric\u0026gt; using namespace std; void TCPReceiver::receive( TCPSenderMessage message ) { if ( message.RST ) { reassembler_.reader().set_error(); return; } if ( !message.SYN \u0026amp;\u0026amp; !connected_ ) { return; } if ( message.SYN ) { connected_ = true; zero_point_ = message.seqno; } else { if ( zero_point_ == message.seqno ) { return; } stream_index_ = message.seqno.unwrap( *zero_point_, reassembler_.writer().bytes_pushed() ) - 1; } auto sequence_len = message.sequence_length(); reassembler_.insert( stream_index_, std::move( message.payload ), message.FIN ); ack_ = reassembler_.writer().bytes_pushed() + 1 + reassembler_.writer().is_closed(); stream_index_ += sequence_len - message.FIN - message.SYN; this-\u0026gt;send(); } TCPReceiverMessage TCPReceiver::send() const { return TCPReceiverMessage { zero_point_.has_value() ? Wrap32::wrap( ack_, *zero_point_ ) : std::optional\u0026lt;Wrap32\u0026gt; {}, static_cast\u0026lt;uint16_t\u0026gt;( std::min( static_cast\u0026lt;uint64_t\u0026gt;( std::numeric_limits\u0026lt;uint16_t\u0026gt;::max() ), reassembler_.writer().available_capacity() ) ), reassembler_.writer().has_error() }; } ","date":"2024-05-29T00:00:00Z","permalink":"https://rossqaq.github.io/article/cs144-p2/","title":"CS144-2024 Winter - Lab 2"},{"content":"本系列博客并不是书《Rust for Rustaceans》的全文翻译，不保证内容准确，仅作为个人阅读后的学习记录。\n支持正版：Rust for Rustaceans by Jon Gjengset (rust-for-rustaceans.com)\n作者油管：Jon Gjengset - YouTube\n第一章 — 基石 Rust 中的各种概念非常重要，所以有必要保证你的基础坚挺。\n这一章会讨论变量、值、所有权、借用、生命周期等等，你需要完全了解后才能继续深入本书。\n内存 内存的每个部分并不相同，在多数语言环境下，你的程序都会访问：栈、堆、寄存器、text segments、memory-mapped 寄存器，memory-mapped 文件，还有 non volatile RAM。\n内存术语 在深入了解各个内存区域之前，首先需要知道值、变量、指针的区别。在 Rust 中，值是类型和这个类型值域中的元素的结合。值可以被转换为使用某种类型代表的字节序列。\n例如，6u8，就代表整数 6，以及内存中的字节是 0x06. 值跟变量存储的地址是无关的。\n值需要存储在一个地方，不管是栈还是堆，最常见的存储值的地方叫做 变量，栈上的一个 slot。\n指针存储了某个内存区域的地址值，所以指针指向一个地方，指针通过解引用可以访问其存储的地址值中的值。可以拥有多个指向同一块内存的指针变量。\n1 2 3 4 5 let x = 42; let y = 43; let var1 = \u0026amp;x; let mut var2 = \u0026amp;x; var2 = \u0026amp;y; 值：42、43、x的地址、y的地址\n变量：x，y，var1，var2\n与普通的变量不同的是字符串变量\n1 let string = \u0026#34;Hello World\u0026#34;; string 存储的还是一个指针，虽然看似我们把字符串字面量赋值给它了。但关于 string 实际指向了谁，以后再说。\n深入理解变量 之前给出的变量的定义可能确实没什么用，更重要的是你需要有一个更准确的 mental model 来帮助你理解程序的行为。有很多种模型，但总得来说，分两种 —— High-level models 和 Low-level models。High-level models 在你讨论代码本身时更有用，比如讨论生命周期、借用等。Low-level 模型在你使用 unsafe 时有用，比如使用裸指针。\n对阅读本书来说，知道这两种模型足够了。\n我大概懂了作者的意思了，放在 C++ 里就是说别老一天天想着你那引用的本质就是指针，不同的时候要从不同的抽象层级看待你的代码。\nHigh-Level Model 在 High-Level 角度，我们会把变量看成是值的名字，他们被初始化、被移动、被使用。在这种模型中，变量只有在拥有合法值的时候存在，你不能使用未初始化的变量，也不能使用值被移动的变量。\n想象一下，你的变量在被访问时，会从先前一次访问的地方向这里画一条线，这条线称之为 flow，它描述了两次访问之间的依赖关系。你的程序会有许多这样的线，他们跟踪变量的生命周期，编译器跟踪这些 flows，每个 flow 只能在与其他 flows 兼容时才能存在。例如，不能同时有两个平行的 flows 指向同一个可变变量，也不能跟没有值的变量借用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 let mut x; // 非法。x 没有值 assert_eq!(x, 42); x = 42;\t//(1) // ok. flow 从第一次赋值时开始， let y = \u0026amp;x;\t//(2)\t// 第二个 mutable flow from x x = 43;\t//(3) // 非法。 这个 flow 从 y 开始，但跟 x 的 flow 冲突。 assert_eq!(*y, 42);\t//(4) 程序有两个 flows，一条是从(1) 到 (3) 的独占 flow（\u0026amp;mut），另外一条是从 (1) 穿过 (2) 到 (4) 的共享 flow。borrow checker 会对这些 flows 进行检查。你不能让独占 flow 和共享 flow 并存（3），所以编译会报错。如果没有 (4)，那么可以通过编译。\n注意，如果声明了一个新的变量和之前的变量命名相同，它们仍然会被认为是不同的变量，这称为 shadowing。后面的变量以相同的名字 shadows 前面的变量。\nLow-Lovel Model 变量名字的内存位置不一定拥有合法的值。你可以把变量想象成是：value slot. 你赋值，slot 被填充，旧的值会被 drop. 当你访问时，编译器会对这个 slot 进行检查。\n这个层级的模型与 C/C++ 以及其他一些低级语言的模型是类似的，当你需要直面内存时你要这么考虑。\n当然，这里我们忽略的 CPU 寄存器的存在。\n这两种模型是并存的，你需要在你的脑子中建立起这种概念，而不是说谁比谁更好。如果你能在两个层面同时理解一段代码，那么你就会发现一段复杂的代码是如何工作、如何通过编译、如何按你的预期执行的。\n内存区域 我们已经知道如何与内存交互，我们需要讨论内存究竟是什么？对 Rust 来说，最重要的内存区域有三个：Stack, Heap, Static Memory.\nThe Stack stack 是一段程序在调用函数时使用的空间。每次一个函数被调用，都会在 stack 顶部分配一段连续的块内存，称之为 frame。栈底部的内存是 main 函数的 frame，随着其他函数的调用，frame 被一直 push 到栈中。函数的 frame 中保存了函数中所有的变量，以及函数调用需要的所有参数。函数返回时，frame 会被释放。\nstack frames 最后释放的行为和 Rust 的生命周期紧密相关。\n任何被释放的变量都无法再被访问，所以任何它的引用的生命周期都必须小于等于保存它的 frame 生命周期。\nThe Heap heap 是不和当前函数的栈绑定的内存块。heap 中的变量必须被显式地解分配。如果你想让某个变量的生命周期比当前函数的 frame 活得更久，那就可以使用 heap。如果这个值是某函数的返回值，那么 calling 函数可以在它的栈上给被调用的函数留一些空间供其写入返回值；但如果你想把这个值传给其他线程，那么你就得使用 heap。\nheap 允许你显式分配一段连续的内存，然后给你一个内存起始地址的指针。这段内存区域会在你解分配之前一直存在，解分配的过程通常称之为 freeing，对应 C 标准库中的函数。因为 heap 内存不会在函数返回后就释放的特性，你可以给某个值分配一个内存，然后把指针传递给另外一个线程，之后那个线程就可以安全的操作这个值了。\n在 Rust 中，最重要的与 heap 内存交互的机制是使用 Box 类型。写出如 Box::new(value) 的代码时，这个值会被在 heap 上分配，而你拿到的是一个指向 heap 的指针的值（Box\u0026lt;T\u0026gt;）。Box 被 dropped 时，内存就被释放了。\n如果你忘记了解分配 heap 内存，那就会内存泄漏，你需要避免。然而，有的时候你想要显示地泄露内存，例如，你需要一个只读的配置数据，整个程序都可以访问它，那么你可以使用 Box::leak 来获取一个它的 'static 引用。\nstack 和 heap 在这里都是操作系统概念，不要看网上的傻卵文章分什么什么区的，抽象层级不同。\n静态内存 静态内存 包括了很多东西，这片区域会在你的程序启动时自动读取到内存中。静态内存区域中的值的生命周期和你的应用程序一样长。静态内存含有程序的二进制代码，通常是只读的。你的程序执行时，它会遍历所有的 text 段的二进制代码，在函数调用时进行跳转；静态内存区域也包含了你使用 static 关键字声明的变量，也包含一些常量，比如字符串字面量。\n特殊的生命周期 'static 标记一个引用的生命周期和程序一样长。当然，一个 static 引用也不一定指向静态内存区的变量，但重要的是其生命周期而不是变量实际存储的位置。\n使用 Rust 时，遇到 'static 生命周期会比实际的静态变量更频繁，因为许多类型参数的 trait bound 会使用 T: 'static 。特别地，这个 bound 需要约束 T 要么是其他静态值的借用，要么就是拥有所有权能够自治的值（不能是 非 static 的借用）。一个比较好的例子是 std::thread::spawn 函数，它要求你传入的闭包是 'static，因为新的线程可能活的比当前线程更久。\n你可能会问 const 和 static 的区别。const 代表声明的 item 是常量，可以在编译期进行计算。常量不会占用内存。\n所有权 Rust 的内存模型基于一个思想：所有的值都有一个 所有者。一个作用域有责任释放其内部的每个值，这个通过 borrow checker 保证。移动会改变所有权，在原先的作用域中不能访问被移动的对象。\n有些类型不遵守这个规则，如果其实现了 Copy trait，那么这个变量就被认为永远不会被移动，而**每次都是进行拷贝。**不管是新的变量还是原来的变量，此时都可以被访问。大多数的基本类型都是 Copy，比如整型、浮点型等等。这样也可以避免内存释放的问题。这也可以消除非 Copy 类型的变量被 drop 时需要释放它拥有的资源。\n谁拥有某值的所有权，谁就要负责在值被 drop 时清理它的资源。drop 在变量出作用域时自动发生。一个类型总是会递归的 drop 它包含的所有值。\n说了这么多，就是一个弄清所有权防止被 double free。\nRust 总是会以逆序 drop 变量（包括函数参数），总是会以源码顺序 drop 一系列的值（比如数组）。\n借用和生命周期 Rust 允许值的拥有者通过引用把值借给其他人，不需要交出所有权。引用是指针能被如何使用的一种约定，例如他们是否互斥访问，或者还是也可能有其他的引用指向这个变量。\n看起来 Rust 的引用似乎跟指针有点纠缠不清。但在 C++ 里，引用就是引用，指针就是指针。\n共享引用 共享引用，\u0026amp;T，如其名所示，可以被共享的指针。\n","date":"2024-05-17T00:00:00Z","permalink":"https://rossqaq.github.io/article/rfr-fundations/","title":"Rust for Rustaceans - Chapter-1 基石"},{"content":"本系列博客并不是书《Rust for Rustaceans》的全文翻译，不保证内容准确，仅作为个人阅读后的学习记录。\n支持正版：Rust for Rustaceans by Jon Gjengset (rust-for-rustaceans.com)\n作者油管：Jon Gjengset - YouTube\n序章 无论是什么语言，书上的代码和你实际工作多年后的经验总是有很大差别。随着经验增长，你会使用更多技巧，对于核心概念建立起更全面的 mental models，学会设计和模式是怎么使用的，以及什么时候不要使用，并且在社区中发现越来越多的有用的库。\n这本书会带着我们花费少量的时间学会编写更好的代码。\n这本书中，我会深入浅出地讲解我多年写 Rust 的经验，把它们变成单独的、容易理解的资源。重点讲解 The Book 中缺失的内容，适合一些想要精进的 Rust 程序员。\n这本书不只是 guide，更是一个索引。你可以跳过任意章节，只阅读你感兴趣的（或者让你头疼的）章节，但我推荐你不要忽略第一章和第二章，因为它们介绍了 Rust 的基础概念，是你每天都要接触的内容。以下是一个总览：\n第一章，基石。 第二章，类型。 第三章，设计接口。 第四章，错误处理。 第五章，项目结构。 第六章，测试。 第七章，宏。 第八章，异步编程。 第九章，不安全代码。 第十章，并发（并行）。 第十一章，FFI，外部函数调用。 第十二章，非标准 Rust。 第十三章，Rust 生态。 ","date":"2024-05-15T00:00:00Z","permalink":"https://rossqaq.github.io/article/rfr-intro/","title":"Rust for Rustaceans - Chapter-0 序言"},{"content":"Structured Concurrency: Writing Safer Concurrent Code with Coroutines\u0026hellip; - Lewis Baker - CppCon 2019\nLewis Baker 不用介绍了，以前写过很多关于协程的文章，github还有库 cppcoro.\n这次介绍协程与结构化并发的关系，专注于协程；而 Roses 之前翻译的文章更多介绍的是结构化并发本身。\n安全性 异常安全 生命周期安全（悬垂引用/指针） 资源泄露 数据竞争/ API 竞争 forward progress / 死锁 本 lecture 主要介绍前三个。\n","date":"2024-05-14T00:00:00Z","image":"https://rossqaq.github.io/article/cppcon-2019-strutured-concurrency/cppcon2019-cover_hu93d2f8befaf9243db44dc194e94262d5_58262_120x120_fill_box_smart1_3.png","permalink":"https://rossqaq.github.io/article/cppcon-2019-strutured-concurrency/","title":"结构化并发与协程"},{"content":"总览 介绍了 TCP 是可靠的有序字节流，简单介绍了它的地位。以下的 assignments 会基于不可靠的 datagram 来实现可靠的 TCP 协议。在未来的 labs，需要两个 lab 0 中的 ByteStream，一个用于发送数据，一个用于接收数据。\n开始 依然是使用 Minnow 库：\n确保提交了 checkpoint 0 的代码，不要更改 src 之外的文件，以及 webget.cc。 git fetch 来获取最新的 lab assignments git merge name-of-cs144-origin/check1-startercode 来下载 checkpoint 1 的初始代码 确保 build 路径正确设置 编译 cmake --build build 打开并且编辑 writeups/check1.md 按顺序恢复子串 TCP receiver：接收 datagrams，并将其按顺序排列、丢弃重复的、重新请求发送丢失的。\nTCP sender：将大的数据流分成小的数据片（1460字节每片）。\n实现：Reassembler，接收子串。\n子串包含字符串、以及其第一个字节的索引 within the larget stream. 每个字节都有独立的索引，从 0 开始。 Reassembler 获取流的 下一个字节 后，就会把它写到输入端的 ByteStream customer 可以从其中读取内容。 实现所有 reassembler.hh 中的 public 接口，不允许自己修改 public 接口。\nReassembler 内部应该存储什么？ insert 通知 Reassembler 有新的字节流分片，以及其大小（字符串开头的索引）\n需要解决三个问题：\nBytes 是流中的 next bytes，直接写入。 Bytes 小于 stream 的可用容量范围内，但目前并不能写入，因为之前的 bytes 未知。暂存。 Bytes 超过了 stream 的可用容量范围。丢弃。Reassembler 不会存储任何不能被立刻写入的字节（包括太大、或者需要等待较早的字节已知的内容） 宗旨是 节省内存容量。到达的不管是什么数据，我们都用以下的图来描述：\n红色：Reassembler 内部存储的字节 绿色：ByteStream 存储的字节 蓝色：已经被 popped 的字节 FAQs 整个流的第一个字节的索引是什么？0.\n我的实现的性能应该是？\n选择的数据结构非常重要。不要选择耗时的数据结构或者占据大量空间的结构，Reassembler 会是你的 TCP 实现的基础。你有很多选择。我们已经准备了 benchmark，任何大于 0.1 Gbps 的都可以通过。最大可以实现 10 Gbps 的 Reassembler。\n如何处理不连续的子串？\n你可以假设他们并不存在。就是说，你可以假设存在唯一的底层字节流，所有的子字符串都是其准确的切片。\n我可能用到？\n你可以使用任何标准库组件。特别地，我们希望你至少使用一种数据结构。\n什么时候将 bytes 写入流？\n尽可能快。唯一不能写入的情况就是字节流的前一个字节还没准备好。\n子串可能会重复吗？ 是的。\n我可以向 Reassembler 添加 private 成员函数吗？\n当然。子串可能以任何顺序到达，所以你的数据结构需要记住子串的顺序，直到他们被 push 进入 Stream，即在该子串的前面所有字节都写入完成。\n我们的 re-assembly 结构可以存储重复子串吗？\n不可以。即使你可以正确的实现，但是这样会打破节约内存的规则。\nReassembler 会使用 ByteStream 的读端吗？\n不会。这是外部消费者做的。Reassembler 仅使用写端。\n你们预期的实现是多少？\n运行 ./scripts/lines-of-code 会打印你的代码行数。我们希望 Reassembler 在 50 - 60行左右（starter code 的基础上）\n更多 FAQs：https://cs144.github.io/lab_faq.html\n经过几个小时的折磨，终于弄清楚了 insert 的逻辑。\nbytes_pending() 很简单，记录一下 pending 长度就行，主要的问题在于 insert() 的情况比较复杂。\n按照 first_index 参数来区分情况，首先先去重，也就是 first_index \u0026lt; next_index_ 的情况，把重复的内容去掉。\n去重后记得更新 first_index。\n什么时候会写入呢？自己维护一个 next_index，然后 first_index == next_index 时就写入。\n要注意容量吗？并不用，p0 我们实现的 byte stream 已经处理了。\n此外，next_index 大概对应上图的 first unassembled index，而 first_index 是每个子串的 index。注意看图中红色的部分是断开的，那我们自然也不能用 std::vector\u0026lt;char\u0026gt; 来存储这些 bytes。我认为用 std::map\u0026lt;uint64_t, std::string\u0026gt; 存就可以，这样少一些复制。\n什么时候会保存在 Reassembler 中呢？**写入操作不需要保存，不会出现写一半存一半的情况。**只有前面的内容没收到时才保存。\n保存非常麻烦，要考虑容量问题。\n容量足够的话就不说了，直接存入；\n容量不够的话，要截断，怎么截断？\n容量，指的是 output stream 的容量，上面的图里画了。 截断时要留下 first_index - next_index 空间，这样才能够前文写入。\n我的做法是，先在 map 中查找有没有 first_index 的存在，有的话，比较两个字符串的大小，留下长的。\n之后就是遍历所有的结点，去掉重复的内容，怎么去除呢？\n插入字符串的 first_index ~ final_index 期间的所有 map 结点都 erase 就好。\n然后遍历所有的结点，把前一个结点和后一个结点重复的部分去除就行。\n但是要注意插入的字符串已经是某个 pending 字符串子串的情况。这种情况直接返回。\n记得要把 pending 的字符串写入，不会出现容量不够的情况，上面已经说了容量的计算了。然后把 first_index \u0026lt;= next_index_ 的内容全部写入，直接调用现有函数就行。\n最后关于 close 写端，需要在写入所有的字节后关闭，但可能字节为 0，所以我用了个 std::optional 来记录，如果没有确定 last index，那么就是空，否则就不为空，之后判断就行。\n这种解法已经是我能想到最快的了，跟字符串有关的操作全部都是 O(1)，没有复制开销，全部是移动，然后要遍历所有的结点。\n开发和 Debug 建议 你可以通过 cmake --build build --target check1 来测试代码（编译之后）\n我寻思 cmake --build 不应该已经编译了吗，不过我好像也没怎么用过 cmake 的指令\u0026hellip;\n重新读一次 Lab 0 的 using git 部分，确保代码最新。\n说了一堆，意思就是让你代码内容明确，然后写点注释\n保证 Modern C++\n如果你编译卡住了又没法修复，你可以删除 build 目录，然后根目录下 cmake -S . -B build\n提交 保证仅修改 /src 下的 .hh .cc 文件，不要修改 public 接口。\n在你写作业之前，请按顺序运行：\n确保已经 commit 了所有的修改，可以用 git status 查看。\ncmake --build build --target format\nVSCode + clang-format 大法好\ncmake --build build --target check1（确保所有测试通过）\n可选：cmake --build build --target tidy （改进代码）\n编写报告 check1.md，一行控制在 80 个字符以内，最好 20~50，这样容易读。\n太长了我又不写这个，不翻译。\n注意填写你做了几个小时，以及其他的评论\nThe mechanics of “how to turn it in” will be announced before the deadline.\nPlease let the course staff know ASAP of any problems at the lab session, or by posting a question on Ed. Good luck\n源代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 #pragma once #include \u0026#34;byte_stream.hh\u0026#34; #include \u0026lt;map\u0026gt; #include \u0026lt;optional\u0026gt; class Reassembler { public: // Construct Reassembler to write into given ByteStream. explicit Reassembler( ByteStream\u0026amp;\u0026amp; output ) : output_( std::move( output ) ) {} /* * Insert a new substring to be reassembled into a ByteStream. * `first_index`: the index of the first byte of the substring * `data`: the substring itself * `is_last_substring`: this substring represents the end of the stream * `output`: a mutable reference to the Writer * * The Reassembler\u0026#39;s job is to reassemble the indexed substrings (possibly out-of-order * and possibly overlapping) back into the original ByteStream. As soon as the Reassembler * learns the next byte in the stream, it should write it to the output. * * If the Reassembler learns about bytes that fit within the stream\u0026#39;s available capacity * but can\u0026#39;t yet be written (because earlier bytes remain unknown), it should store them * internally until the gaps are filled in. * * The Reassembler should discard any bytes that lie beyond the stream\u0026#39;s available capacity * (i.e., bytes that couldn\u0026#39;t be written even if earlier gaps get filled in). * * The Reassembler should close the stream after writing the last byte. */ void insert( uint64_t first_index, std::string data, bool is_last_substring ); // How many bytes are stored in the Reassembler itself? uint64_t bytes_pending() const; // Access output stream reader Reader\u0026amp; reader() { return output_.reader(); } const Reader\u0026amp; reader() const { return output_.reader(); } // Access output stream writer, but const-only (can\u0026#39;t write from outside) const Writer\u0026amp; writer() const { return output_.writer(); } private: void insert_or_store( uint64_t first_index, std::string data ); void write_stored_str(); void write( std::string data ); void store( uint64_t first_index, std::string data ); uint64_t truncate_head( uint64_t old_index, std::string\u0026amp; data ); private: ByteStream output_; // the Reassembler writes to this ByteStream std::map\u0026lt;uint64_t, std::string\u0026gt; pending_substr_ {}; uint64_t bytes_pending_ {}; uint64_t next_index_ {}; std::optional\u0026lt;uint64_t\u0026gt; total_pushed_len_ { std::nullopt }; }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 #include \u0026#34;reassembler.hh\u0026#34; #include \u0026lt;iostream\u0026gt; #include \u0026lt;utility\u0026gt; #include \u0026lt;vector\u0026gt; using namespace std; void Reassembler::insert( uint64_t first_index, string data, bool is_last_substring ) { if ( is_last_substring ) [[unlikely]] { total_pushed_len_ = first_index + data.length(); } insert_or_store( first_index, std::move( data ) ); write_stored_str(); if ( total_pushed_len_.has_value() \u0026amp;\u0026amp; output_.writer().bytes_pushed() == *total_pushed_len_ ) [[unlikely]] { output_.writer().close(); } } void Reassembler::insert_or_store( uint64_t first_index, std::string data ) { if ( first_index \u0026lt; next_index_ ) { first_index = truncate_head( first_index, data ); } if ( first_index \u0026gt; next_index_ ) { store( first_index, std::move( data ) ); } else { write( std::move( data ) ); } } void Reassembler::write_stored_str() { for ( auto\u0026amp; [first_index, data] : pending_substr_ ) { if ( first_index \u0026lt;= next_index_ ) { auto buf = std::exchange( data, \u0026#34;\u0026#34; ); bytes_pending_ -= buf.length(); insert_or_store( first_index, std::move( buf ) ); } } std::erase_if( pending_substr_, []( const auto\u0026amp; elem ) { return elem.second.empty(); } ); } void Reassembler::write( std::string data ) { output_.writer().push( std::move( data ) ); next_index_ = output_.writer().bytes_pushed(); } void Reassembler::store( uint64_t first_index, std::string data ) { if ( auto len = output_.writer().available_capacity() - ( first_index - next_index_ ); data.length() \u0026gt;= len ) { data.erase( data.begin() + len, data.end() ); } if ( data.empty() ) [[unlikely]] { return; } if ( pending_substr_.empty() ) [[unlikely]] { bytes_pending_ += data.length(); pending_substr_.emplace( first_index, std::move( data ) ); } else { auto final_index = first_index + data.length() - 1; if ( pending_substr_.contains( first_index ) ) { if ( pending_substr_[first_index].length() \u0026gt;= data.length() ) { return; } auto mapped_data = std::exchange( pending_substr_[first_index], \u0026#34;\u0026#34; ); bytes_pending_ -= mapped_data.length(); pending_substr_.erase( first_index ); } std::erase_if( pending_substr_, [\u0026amp;]( const auto\u0026amp; node ) { if ( node.first \u0026gt;= first_index \u0026amp;\u0026amp; node.first + node.second.length() - 1 \u0026lt;= final_index ) { bytes_pending_ -= node.second.length(); return true; } return false; } ); for ( const auto\u0026amp; [idx, str] : pending_substr_ ) { if ( first_index \u0026gt;= idx \u0026amp;\u0026amp; final_index \u0026lt;= idx + str.length() - 1 ) { return; } } bytes_pending_ += data.length(); pending_substr_.emplace( first_index, std::move( data ) ); auto begin_node = pending_substr_.lower_bound( first_index ); auto end_node = pending_substr_.upper_bound( final_index ); if ( begin_node != std::begin( pending_substr_ ) ) { begin_node = std::prev( begin_node ); } for ( auto node = begin_node; std::next( node ) != end_node; ++node ) { auto next_node = std::next( node ); auto this_final_index = node-\u0026gt;first + node-\u0026gt;second.length() - 1; auto next_first_index = next_node-\u0026gt;first; if ( this_final_index \u0026gt;= next_first_index ) [[likely]] { auto len = this_final_index - next_first_index + 1; bytes_pending_ -= len; node-\u0026gt;second.erase( node-\u0026gt;second.begin() + node-\u0026gt;second.length() - len, node-\u0026gt;second.end() ); } } } } uint64_t Reassembler::truncate_head( uint64_t old_index, std::string\u0026amp; data ) { data.erase( 0, next_index_ - old_index ); return next_index_; } uint64_t Reassembler::bytes_pending() const { return bytes_pending_; } ","date":"2024-05-12T00:00:00Z","permalink":"https://rossqaq.github.io/article/cs144-p1/","title":"CS144-2024 Winter - Lab 1"},{"content":"原文地址：Structured Concurrency – Eric Niebler\n全文会将 Structured 翻译为 结构化的/结构化\n写 C++ 协程库的时候遇到了各种各样的 lifetime 问题，发现 CppCon2023 有 lecture 描述了如何处理这些问题，什么才是正确的编程模式。这是那篇 lecture 中引用的一篇宗旨文章。\n注意，你需要对协程有比较深入的了解，或者至少你也得了解协程地语法以及其他某种语言的异步编程方式，你才能看懂这篇文章。\n序 太长不看版：“结构化并发” 指代的是一种异步操作结构，其子部分保证完成于父部分之前，就像函数调用保证在它的 caller 结束前完成一样。听起来这个很简单很无聊，但对 C++ 来讲所有事情都没那么简单。结构化并发对 C++ 协程异步架构的正确性和简单性有深远影响。它通过把异步 lifetimes 与 C++ 语句作用域对应，将 现代 C++ 风格 代入了我们的异步程序，以此消除了引用计数管理生命周期的需求。\n结构化编程与 C++ 在上世纪 50 年代，新生的计算工业提出了结构化编程：高级语言拥有词法范围（lexical scopes）、控制结构，而 subroutines 会使得程序相较于使用 test-and-jump 指令以及 goto 变得更容易读写和维护。这是一个巨大的进步，以至于没有人讨论结构化编程，因为它只是“编程”。\n意思就是概念早已经被人习惯了，现在没人提。\nC++，比其他语言更复杂，充分利用了结构化编程。对象生命周期的语义代表了它跟其作用域的严格嵌套和绑定。例如，你代码的 structure。函数的执行流嵌套，作用域嵌套，对象的生命周期嵌套。对象的生命周期在大括号 } 处结束，然后对象会按照构造顺序的逆序进行析构。\n现代 C++ 风格建立在这种结构化的基础上。对象拥有值语义，它们的行为就像 int，资源会在析构器中自动释放，这保证了对象不会在生命周期结束后被使用。这非常重要。\n当我们放弃将对象生命周期和其作用域绑定时，那么，我们会在堆上使用引用计数来管理一个对象、或者我们使用单例模式；此时，我们正在与语言优势对抗而不是跟语言协作。\n多线程带来的麻烦 编写正确的并发程序远比单线程程序困难得多。有许多原因，一是因为线程和单例一样都是动态分配的对象，根本不会嵌套在作用域内。即使你使用现代 C++ 提供 的线程，但当逻辑跟生命周期跨线程时，程序的层级结构会让人摸不着头脑。我们在单线程下用以管理代码复杂性的工具 —— 将嵌套的生命周期和嵌套的作用域绑定，无法替我们管理异步代码。\n为了进一步解释，我们看看将同步函数变为异步函数会发生什么：\n1 2 3 4 5 6 7 void computeResult(State \u0026amp; s); int doThing() { State s; computeResult(s); return s.result; } doThing 非常简单，它声明了一些内部状态，调用一个 helper，然后返回结果。现在我们要把两个函数都变成异步的，因为它们可能需要比较长的时间。我们直接使用 Boost future，它支持连续的链式调用：\n1 2 3 4 5 6 7 boost::future\u0026lt;void\u0026gt; computeResult(State\u0026amp; s); boost::future\u0026lt;int\u0026gt; doThing() { State s; auto fut = computeResult(s); return fut.then([\u0026amp;](auto\u0026amp;\u0026amp;) {return s.result; });\t// OOPS } 如果你使用过 future 的话，你可能会大喊：“不~~！”，.then 指定了一些在 computeResult() 完成后的工作，doThing() 之后返回结果 future。问题在于，doThing() 返回时，State 的生命周期结束了，并且 continuation 捕获了它的引用，现在这是悬垂引用，很可能会导致崩溃。\n问题在哪？futures 允许我们计算一个现在还不需要的结果，Boost 风格允许我们链式执行，但是 continuation 是一个单独的函数，具有单独的作用域。没有嵌套的作用域，没有嵌套的生命周期，我们需要手动管理 state 的生命周期。\n1 2 3 4 5 6 7 boost::future\u0026lt;void\u0026gt; computeResult(std::shared_ptr\u0026lt;State\u0026gt; s); boost::future\u0026lt;int\u0026gt; doThing() { auto s = std::make_shared\u0026lt;State\u0026gt;(); auto fut = computeResult(s); return fut.then([s](auto\u0026amp;\u0026amp;) {return s.result; }); } 因为两个异步操作都需要 state，所以它们都有责任确保其存活。\n另一种思考方式是：**这个异步计算的生命周期是什么？**它从 doTing() 被调用开始，直到 continuation，传入 then 的 lambda 返回。并没有作用域跟这个生命周期对应，这就是问题的根源。\n非结构化并发 当我们考虑 executor 时情况会变得更复杂。executors 用来解决执行时的上下文，你可以在它上面调度任务，通常可以是一个线程或者线程池。许多代码库都有 executor 的概念，其中有一些允许你使用 defer 或者其他策略安排调度。我们可以做一些有意思的事情，比如把计算从一个 IO 线程池挪到 CPU 线程池，或者延迟后重试一些异步操作。goto 可以派上用场，但是它非常低级，而且一点也不清晰。\n举个例子，最近我遇到了一个算法，它通过执行器和回调（listener）来重试某些资源的异步分配。以下是一个删减后的版本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // 异步操作完成后会调用该 continuation struct Manager::Listener : ListenerInterface { shared_ptr\u0026lt;Manager\u0026gt; manager_; executor executor_; size_t retriesCount_; void onSucceeded() override { /* 分配成功了…… */ } void onFailed() override { // 分配失败，向 executor 请求过后再分配一次 auto alloc = [manager = manager_]() { manager-\u0026gt;allocate(); }; // 未来某个时刻重新分配 executor_.execute_after( alloc, 10ms * (1 \u0026lt;\u0026lt; retriesCount_)); } }; // 使用以上的类作为 continuation 尝试异步分配资源 void Manager::allocate() { // 我们已经尝试过很多次了吗？ if (retriesCount_ \u0026gt; kMaxRetries) { /* 通知观察者，分配失败了 */ return; } // 再试一次： ++retriesCount_; allocator_.doAllocate( make_shared\u0026lt;Listener\u0026gt;( shared_from_this(), executor_, retriesCount_)); } allocate() 成员函数首先检查异步操作执行了多少寸，如果没执行过，就直接调用 doAllocate() ，传一个回调来通知它是成功还是失败。失败的话，handler 会向执行器再提交一个 deferred 任务，会重新调用 alloate，过后再重试分配。\n这是一个有繁多状态并且非常迂回的异步算法。逻辑生成了很多函数、很多对象，控制流和数据流都不明显。还得注意保证对象生存期的引用计数。向执行器提交任务让它更加困难。这段代码中的执行器没有 continuation 的概念，所以在任务执行中的错误也无处可去。allocate() 函数不能通过异常传递错误以此从错误中恢复，错误处理必须手动完成。如果我们想支持取消，也是同理。\n这是一种 非结构化并发：我们以一种 临时 的方式 queue up 异步操作；我们串联相关的工作，使用 continuations 或者 strand 执行器保证顺序一致；我们使用强弱引用计数保证数据在我们需要时存活。没有正式的描述任务 A 是任务 B的子任务的概念，无法强制子任务在父任务前完成，我们也不能指着代码中的某一处说：这是算法。\n如果你不介意的话，通过执行器进行的跳跃有那么一点像是非 local 的 goto 语句，不管是时间上还是空间上。“X ms 后，在某个线程上，立刻 jump 到程序中的这一点。”\n这种 non local 的不连续性使得我们很难推导程序的正确性和效率。将这种非结构化的并发扩展到整个程序，然后处理许多并发的实时事件，手动处理代外异步数据的控制和数据量，控制并发访问共享状态，管理对象生命周期都很难受。\n结构化并发 在很久之前，非结构化的编程就已经给结构化风格让路了。有 C++ 协程的支持，使得如今的很多异步代码也发生了类似的变化。如果我们使用协程重写以上算法（使用了 cppcoro），看起来就会是：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 尝试分配资源，失败就会重试 cppcoro::task\u0026lt;\u0026gt; Manager::allocate() { // 尝试分配，直到次数达到 kMaxRetries; for (int retriesCount = 1; retriesCount \u0026lt;= kMaxRetries; ++retriesCount) { try { co_await allocator_.doAllocate(); co_return; // success! } catch (...) {} // 失败，让出线程，稍后重试 co_await scheduler_.schedule_after( 10ms * (1 \u0026lt;\u0026lt; retriesCount)); } // 错误，失败太多次 throw std::runtime_error( \u0026#34;Resource allocation retry count exceeded.\u0026#34;); } 说明：cppcoro 的 scheduler 和 上文的 executor 概念类似。\n我们列出以上做法的优点：\n只有一个函数，非常有逻辑性。 状态（例如 retriesCount）可以被轻松的维护，而不需要使用引用计数。 我们可以使用普通的 C++ 错误处理技术。 保证结构化，即异步调用 alllocator_.doAllocate() 在函数继续执行前完成。 第四点有深刻的意义。考虑文章开头的简单的例子，以下的使用协程的实现非常安全：\n1 2 3 4 5 6 cppcoro::task\u0026lt;\u0026gt; computeResult(State\u0026amp; s); cppcoro::task\u0026lt;int\u0026gt; doThing() { State s; co_await computeResult(s); co_return s.result; } 以上代码很安全，因为我们知道 computeResult 会在 doThing 恢复前完成，也即 s 析构之前。\n有了结构化并发，将 local 变量作为引用传递给子任务来 await 非常安全。\n取消 如果使用结构化并发的方法，那么并发操作的生命周期就会严格内嵌于资源的生命周期中，绑定在其作用域上，允许我们避免像是 shared_ptr 之类的垃圾回收机制。这样代码会更加效率，只需要更少的堆分配以及很少的 atomic ref count 操作，当然代码也更易读而且 bug 更容易分析。\n然而，这种方法有一个隐含的要求，即我们必须在父操作完成前 join 并且 wait 子操作。我们并不能 detach 这些子操作，然后让资源自动释放。为了避免在结果已经使用过的子操作上进行不必要的等待，我们需要一个机制来取消这些子操作，这样它们才能尽快结束。因此，结构化并发模型需要对取消操作的深度支持，以避免不必要的延迟。\n注意，我们会在每次向子协程传递 local 变量的时候依赖结构化生命周期以及结构化并发。我们必须确保子协程完成并且不再需要那个变量，之后父协程中 local 变量作用域结束再被销毁。\n结构化并发 \u0026gt; 协程 当我说起“结构化并发”时，我不仅仅是说协程，虽然协程是最明显的表现方式。为了解释我的意思，我们简单的讨论一下协程是什么、不是什么。注意，C++的协程根本没有固有的并发性质！它们只是编译器把函数改为回调的一种方式。\n考虑以下简单的协程：\n1 2 3 4 5 6 7 cppcoro::task\u0026lt;\u0026gt; computeResult(State\u0026amp; s); cppcoro::task\u0026lt;int\u0026gt; doThing() { State s; co_await computeResult(s); co_return s.result; } co_await 是什么意思？很老套的答案：这取决于作者想让 cppcoro::task\u0026lt;\u0026gt; 是什么。完整的答案是，co_await 暂停当前协程，将协程中剩下的内容打包（这里即 co_return s.result;），作为 continuation，然后把它传入 awaitable 对象（这里是 task\u0026lt;\u0026gt; 通过 computeResult 返回）。awaitable 会把它存到某个地方，在子任务完成之后就可以调用了。这是 cppcoro::task\u0026lt;\u0026gt; 做的。\n换句话说，task\u0026lt;\u0026gt; 类型以及语言的协程一起将结构化并发置于无聊的回调之上。以上。这就是所有的 magic。只是回调而已，但是是另一种模式的回调，而这种模式使其变得结构化。这种模式保证了子操作在父操作前完成，就是这种属性带来了收益。\n一旦我们认识到结构化并发只是回调的一种特殊模式后，我们就会发现我们可以不使用协程实现结构化并发。使用回调当然不是什么新鲜事，这些模式可以被编码到一个库中然后变得可复用。这就是 libunifex 做的。如果你关注 C++ 标准委员会，就知道这是 Executors 提案 中的 sender/receiver 抽象。\n使用 libunifex 作为结构化并发的基础，我们就可以写出以下的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 unifex::any_sender_of\u0026lt;\u0026gt; computeResult(State\u0026amp; s); auto doThing() { return unifex::let_with( // 声明 \u0026#34;local variable\u0026#34;: [] {return State{};}, // 使用 local 来构造异步任务 [](State\u0026amp; s) { return unifex::transform( computeResult(s), [\u0026amp;] { return s.result; })； }); } 我们都有协程了为什么还要写这个？你需要一个更好的解释，我只能抛砖引玉。有了协程，你会在协程第一次被调用时进行分配，然后在它每次恢复后间接调用一个函数。编译器有时可以消除其开销，有时不行。而通过结构化并发的方式直接使用回调，我们可以直接获得同样的收益但是没有协程调用的开销。\n这种风格的编程导致了不一样的开销：很难编写出跟协程一样可读性的代码。我认为未来 90% 的异步代码都会因可维护性而使用协程编写。对于 hot code，选择性地使用 lower-level 的方式替代协程。\n并发 我在上面提到，协程本身并不是并发的；它们只是回调的一种编写方式。协程本质上是顺序的，而task\u0026lt;\u0026gt; 的惰性（协程开始时暂停，被 awaited 时才执行）代表我们不能使用它来向程序中引入并发。已有的 future-based 代码经常假设操作已经 eagerly 开始，引入 临时 的并发你就需要小心的处理。这会迫使你一遍又一遍地使用 临时 的风格重新实现并发模式。\n有了结构化并发，我们就可以在算法中贯彻并发模式并且以结构化的方式引入并发。例如，我们如果有一堆 tasks 并且想要等待它们都完成后把它们的结果作为 tuple 返回，我们可以将其传入 cppcoro::when_all 并且 co_await 结果。（libunifex 也有 when_all 算法）\n目前，不管是 cppcoro 还是 libunifex 都没有 when_any，所以你不能运行并发操作然后当 第一个 操作完成后就返回。虽然这是一个非常重要又有趣的基础算法。为了维护结构化并发的保证，当第一个子任务完成时，when_any 需要取消其他所有的任务，并且等待它们完成。此算法的效果取决于其他的异步操作对于你的取消请求的响应速度，这表明了对取消的深度支持在现代异步程序中的重要性。\nMigration 目前，我已经讨论了什么是结构化并发以及它为什么重要。我还没有讨论我们怎么达成。如果你已经使用协程来编写异步 C++ 了，恭喜。你可以继续享受到结构化并发带来的收益，也许还对协程为什么具有改革性有了更深的理解。\n对于缺少结构化并发的代码，对取消的支持，或者是异步机制的抽象都极具难度。它可能从引入复杂性开始，开辟一座孤岛，周围的代码保证结构化并发需要的条件。例如，这包括创建一个任务的取消操作，即使底层的执行上下文不直接提供取消。增加的复杂性可以被隔离在一层中，结构化并发的孤岛构建于其之上。然后剩下的就是简单的操作了，对于采用 future- 或者 callback-style 的代码，把它们转化为协程方式，理清父子关系、所有权，以及生命周期。\n总结 co_await 的加入在不干预计算结构的基础上把同步函数变成异步函数。被 awaited 的异步操作必须在调用它的函数完成前完成，就像是普通的函数调用。革新的地方是：没有改变的地方。作用域和生命周期仍然像往常一样嵌套，只是现在的作用域并不是连续的了。使用传统的回调和 future，这种结构就没有了。\n协程，以及更广泛意义上的结构化并发，带来的是现代 C++ 的风格：值语义，算法驱动的设计，清晰的所有权语义 with deterministic finalization，以上这些都加入了一步变成。它这么做的方式是因为它把异步的生命周期绑定回普通的 C++ 作用域上。协程把我们的异步函数变成拥有挂起点的回调函数，回调函数使用非常特殊的模式被调用，以此来维护严格嵌套的作用域、生命周期，以及函数栈（function activations）\n我们在代码中使用 co_await ，然后我们可以继续使用我们熟悉的：异常来进行错误处理、local 变量、析构函数释放资源、值/引用传递参数，以及其他任何的 good、safe、惯用的现代 C++。\n感谢阅读。\n了解更多的话，一定要看看 CppCon 2019 Lewis Baker 的 Structured Concurrency: Writing Safer Concurrent Code with Coroutines\u0026hellip; 的演讲。\n","date":"2024-05-12T00:00:00Z","permalink":"https://rossqaq.github.io/article/coro-structed-con/","title":"Structured Concurrency"},{"content":"准备做一下 CS144 系列，恰好锻炼一下我的网络编程。\n由于发现网上已经有很多代码了，所以我干脆也放出来了，其实这些公开课是不应该公开代码的。\n概述 讲了一大堆说明以及政策，大意就是实验和未来工作的难度类似，你可以从中学到东西；后面的实验通常会基于前面的实验，所以不要跳过前面的实验。\n配置环境 这里我的是 WSL Ubuntu-24.04，其他内容照着 pdf 装就可以。这个实验要求使用 C++20，还挺好的，非常新。\n手动上网 手动获取网页\n发送 email\n获取网页 在浏览器中访问 cs144.keithw.org/hello 然后观察结果 现在将要手动获取网页信息，就和浏览器一样。 在虚拟机里，telnet cs144.keithw.org http, 这样 telnet 会建立 TCP 连接以及一个 http 服务。 [按照说明书继续即可]。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ❯ telnet cs144.keithw.org http Trying 104.196.238.229... Connected to cs144.keithw.org. Escape character is \u0026#39;^]\u0026#39;. GET /hello HTTP/1.1 Host: cs144.keithw.org Connection: close HTTP/1.1 200 OK Date: Thu, 09 May 2024 12:57:56 GMT Server: Apache Last-Modified: Thu, 13 Dec 2018 15:45:29 GMT ETag: \u0026#34;e-57ce93446cb64\u0026#34; Accept-Ranges: bytes Content-Length: 14 Connection: close Content-Type: text/plain Hello, CS144! Connection closed by foreign host. 作业：使用上面的技巧来从 url cs144.keithw.org/lab0/sunetid 中获得你自己的 id，把 sunetid 替换成你自己的 id，然后查看自己的私有 SUNet ID, X-Your-Code-Is: blabla. 记得把它存一下。 呃，发个 GET 请求，没什么好说。\n发邮件 还是使用 TCP，这次换 SMTP 协议发邮件。\n这一步前面似乎也没法连斯坦福的服务器，跳过好了。\n作业：给 cs144grader@gmail.com 发邮件。\n监听和连接 这一节主要使用的是 netcat 来让自己作为服务器。照着做即可。\nnc 默认的实现基本可以看作为一个聊天服务器。\n使用 OS stream socket 编写网络程序 这一节是编写一个 Socket Stream 程序，就是熟悉熟悉 Linux 的底层 socket API 而已。\n提到现实生活中经常使用的 UDP datagrams（每个包上限 1500 字节）作为数据传输方式，介绍了一些 UDP 的不稳定性，以及 TCP 的来历。\nlab 0 会使用 OS 内置的 TCP 编写一个叫做 webget 的程序，获取一个网页的内容。之后会从 0 开始实现一个 TCP。\nGetting Started - 获取初始代码 clone 个代码然后按说明来在 github 上 private 备份并且完成其他的构建步骤。\n现代 C++ 介绍 这里介绍了一大堆 C++ 的内容，多用 RAII。以下需要遵守：\n多看 cppref 不要用 malloc() 和 free() 不要用 new/delete 使用 smart pointers 代替裸指针 CS144中，不要用模板、线程、锁、虚函数 避免 char* 以及 strlen strcpy 这种 C 字符串函数 不要用 C 风格转换。 多传 const ref 除非变量需要被修改，否则多让它 const 除非对象需要被修改，否则方法也 const 避免全局变量，每个变量尽可能让其作用域更小 在提交作业前，使用 cmake --build build --target tidy 来改进代码，然后使用 cmake --build build --target format 来格式化代码 在 git 的使用上：尽可能频繁的提交小的更改，并且用 commit message 描述清楚你的更改。\n读 Minnow support code 为了支持这种格式的编程，Minnow 的类包装了 OS 接口，尤其是 socket fd。\n请阅读 public API，(util/socket.hh, util/file_descriptor.hh) 注意，Socket 是 FileDescriptor 的一种， 而 TCPSocet 是 Socket 的一种。\n编写 webget 该来实现 webget 了~\n在 build 里，打开 ../apps/webget.cc\n使用 TCPScoket Address 两个类在 get_URL 函数里完成这个程序\n提示\n注意 HTTP 每一个完整请求以 CRLF 结尾（\\r\\n）\n不要忘记在你的请求里写上 Conncetion: close，这样就能告诉服务器，在这条报文后面没有其他的请求了，然后服务器才会立刻对你进行响应。你会发现你收到的 stream 会以 EOF 结尾。\n所以要 read 多次，直到 EOF\n预计写个十几行代码\n使用 make 编译你的程序\n通过 ./apps/webget cs144.keithw.org /hello 来测试你的程序；你当然也可以跟其他 http 服务器做实验。\n当它们看起来正常之后，使用 cmake --build build --target check_webget 来运行测试。\ngraders 会使用不同的 host name 进行测试，所以你得保证它在任何服务器上正常工作。\n想通过测试记得把 buf 的内容输出…\nin-memory 版本的可靠字节流 功能描述：\n写者在输入端写入字节流，读者在输出端读取字节流； 写入和读取的顺序相同； 字节流是有限的：写者在结束输入后，无法再写入其他字节；读者读到 EOF 代表没有数据可读； 字节流在构造时确定容量；容量指的是构造时某一方预期的最大存储量，这么做是为了限制写者写入的数量； 读者读取字节并且将其弹出后，写者被允许继续写入； 注意：字节流长度有限，但写者在输入结束前可以写入任意多数据，必须处理字节流长度比容量大的情况。容量为 1 的字节流也可以持有 TB 级别的字节数。 单线程下运行； 被第六点迷惑了，我还以为是字节流保存所有输入的数据……实则只保存 available len 的数据。\n那其实一点也不难，buffer 直接用 std::vector\u0026lt;char\u0026gt; 即可。\n当然，std::vector\u0026lt;char\u0026gt; 无可避免的会有复制，这样实现吞吐量肯定比较低，不过我也懒得优化了。以后有空再说吧。\n想优化的话你可以换成 std::vector\u0026lt;std::string\u0026gt; 这样的容器，erase 多余的内容然后直接移动就是了。erase 擦除末尾的元素是 O(1) 移动开销也很低，估计会快不少。\n源代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 #pragma once #include \u0026lt;cstdint\u0026gt; #include \u0026lt;deque\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;string_view\u0026gt; #include \u0026lt;vector\u0026gt; class Reader; class Writer; class ByteStream { public: explicit ByteStream( uint64_t capacity ); // Helper functions (provided) to access the ByteStream\u0026#39;s Reader and Writer interfaces Reader\u0026amp; reader(); const Reader\u0026amp; reader() const; Writer\u0026amp; writer(); const Writer\u0026amp; writer() const; void set_error() { error_ = true; }; // Signal that the stream suffered an error. bool has_error() const { return error_; }; // Has the stream had an error? protected: // Please add any additional state to the ByteStream here, and not to the Writer and Reader interfaces. uint64_t capacity_; bool error_ {}; uint64_t bytes_buffered_ {}; uint64_t bytes_pushed_ {}; uint64_t bytes_popped_ {}; bool closed_ { false }; std::vector\u0026lt;char\u0026gt; buf_; }; class Writer : public ByteStream { public: void push( std::string data ); // Push data to stream, but only as much as available capacity allows. void close(); // Signal that the stream has reached its ending. Nothing more will be written. bool is_closed() const; // Has the stream been closed? uint64_t available_capacity() const; // How many bytes can be pushed to the stream right now? uint64_t bytes_pushed() const; // Total number of bytes cumulatively pushed to the stream }; class Reader : public ByteStream { public: std::string_view peek() const; // Peek at the next bytes in the buffer void pop( uint64_t len ); // Remove `len` bytes from the buffer bool is_finished() const; // Is the stream finished (closed and fully popped)? uint64_t bytes_buffered() const; // Number of bytes currently buffered (pushed and not popped) uint64_t bytes_popped() const; // Total number of bytes cumulatively popped from stream }; /* * read: A (provided) helper function thats peeks and pops up to `len` bytes * from a ByteStream Reader into a string; */ void read( Reader\u0026amp; reader, uint64_t len, std::string\u0026amp; out ); 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 #include \u0026#34;byte_stream.hh\u0026#34; #include \u0026lt;algorithm\u0026gt; using namespace std; ByteStream::ByteStream( uint64_t capacity ) : capacity_( capacity ), buf_() { buf_.reserve( capacity_ ); } bool Writer::is_closed() const { return closed_; } void Writer::push( string data ) { auto len = std::min( data.length(), available_capacity() ); if ( len \u0026gt; 0 \u0026amp;\u0026amp; !closed_ ) [[likely]] { std::copy( data.begin(), data.begin() + len, std::back_inserter( buf_ ) ); bytes_buffered_ += len; bytes_pushed_ += len; } } void Writer::close() { closed_ = true; } uint64_t Writer::available_capacity() const { return capacity_ - bytes_buffered_; } uint64_t Writer::bytes_pushed() const { return bytes_pushed_; } bool Reader::is_finished() const { return !static_cast\u0026lt;bool\u0026gt;( bytes_buffered_ ) \u0026amp;\u0026amp; closed_; } uint64_t Reader::bytes_popped() const { return bytes_popped_; } string_view Reader::peek() const { return std::string_view { buf_.data(), bytes_buffered_ }; } void Reader::pop( uint64_t len ) { if ( len \u0026gt; bytes_buffered_ ) [[unlikely]] { len = bytes_buffered_; } buf_.erase( buf_.begin(), buf_.begin() + len ); bytes_buffered_ -= len; bytes_popped_ += len; } uint64_t Reader::bytes_buffered() const { return bytes_buffered_; } ","date":"2024-05-08T00:00:00Z","permalink":"https://rossqaq.github.io/article/cs144-p0/","title":"CS144-2024 Winter - Lab 0"},{"content":"VS Code 快捷键 快捷键 Win 功能 快捷键 MacOS ctrl + shift + P 打开命令面板 cmd + shift + p ctrl + p 快速打开工作区文件 cmd + p ctrl + shift + n 打开新窗口 cmd + shift + N ctrl + shift + w 关闭新窗口 cmd + W alt + ↑/↓ 移动当前行 opt + ↑/↓ shift + alt + ↑/↓ 向 ↑/↓ 复制当前行 opt + shift + ↑/↓ ctrl + shift + k 删除一行 cmd + shift + k ctrl + enter 向下插入一行 cmd + enter ctrl + shift +enter 向上插入一行 cmd + shift + enter ctrl + shift + \\ 跳转匹配括号 cmd + shift + \\ ctrl + [ / ] 调整缩进 cmd + [ / ] Home / End 跳到某一行行首/行尾 fn + left/right ctrl + Home / End 调到文件首/尾 fn + ↑/↓ ctrl + ↑/↓ 以行为单位滚动屏幕 fn + ctrl + ↑/↓ alt + PgUp/PgDn 滚动整屏 fn + cmd + ↑/↓ ctrl + / 注释当前行 cmd + / shift + alt + A 插入一块注释 shift + opt + A ctrl + T 查找符号 cmd + T ctrl + G 跳转到某行 ctrl + G ctrl + P 跳转到某文件 cmd + p ctrl + shift + o 跳转到符号 cmd + shift + o alt + ←/→ 当前打开的文件中切换 ctrl + -/ ctrl + shift + - ctrl + F 查找 cmd + f ctrl + H 替换 cmd + opt + f alt + enter 选择所有 opt + enter alt + click 插入光标 opt + click ctrl + alt + ↑/↓ 向上/向下插入光标 ctrl + u undo 光标 ctrl + L 选择当前行 cmd + l shift + alt + 鼠标 多行选择 shift + opt + click ctrl + o 打开文件 cmd + o ctrl + k, ctrl + o 打开工作区 ctrl + ` 显示终端 ctrl + ` ctrl + shift + ` 新建终端 ctrl + shift + ` 关闭终端 cmd + delete ","date":"2024-05-01T00:00:00Z","permalink":"https://rossqaq.github.io/article/basic-skills/","title":"程序员基础素养"},{"content":"Back to Basics: Forwarding References - How to Forward Parameters in Modern C++ - Mateusz Pusz 2023 (youtube.com)\nSlides\n最近写模版，所以回顾一下万能引用。\n（感觉这个主讲人是德国口音，有点喜感hhh）\n值类别 \u0026ldquo;Generalized\u0026rdquo; Lvalues：lvalue 是具有 identity 的对象、位域或者函数。 \u0026ldquo;Pure\u0026rdquo; Rvalues：prvalue 是运算符和操作数计算的结果，或者对象的初始化，或者位域 \u0026ldquo;Expiring\u0026rdquo; Lvalue：xvalue 代表可以被重用的资源（你应该对他使用 move，当然 别 return std::move） 之后主讲人发起了个 quiz，做题，以下传入的表达式的值类别是什么？\n1 foo(42);\t// prvalue 1 2 int i{42}; foo(i);\t// lvalue 1 2 int i{42}; foo(std::move(i));\t// xvalue 1 2 int make_int() {return 42;} foo(make_int());\t// prvalue。译者注：函数调用是纯右值 接下来是重载的选择：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 void f(int* ptr); void f(const int* ptr); int i{42}; const int ci{42}; int make_int() {return 42}; // 以下那些可以编译？ f(i); f(ci); f(std::move(i)); f(std::move(ci)); f(42); f(make_int()); 都不能编译，因为函数参数是指针。为了让他能编译，我们需要取地址，继续：\n1 2 3 4 5 6 7 8 9 10 11 12 void f(int* ptr); int i{42}; const int ci{42}; int make_int() {return 42}; f(\u0026amp;i);\t// √ f(\u0026amp;ci);\t// × f(\u0026amp;std::move(i));\t// × f(\u0026amp;std::move(ci));\t// × f(\u0026amp;42);\t// × f(\u0026amp;make_int());\t// × 1 2 3 4 5 6 7 8 9 10 11 12 void f(const int* ptr); int i{42}; const int ci{42}; int make_int() {return 42}; f(\u0026amp;i);\t// √ f(\u0026amp;ci);\t// √ f(\u0026amp;std::move(i));\t// × f(\u0026amp;std::move(ci));\t// × f(\u0026amp;42);\t// × f(\u0026amp;make_int());\t// × 1 2 3 4 5 6 7 8 9 10 11 12 void f(int\u0026amp; ref); int i{42}; const int ci{42}; int make_int() {return 42}; f(i);\t// √ f(ci);\t// × f(std::move(i));\t// × f(std::move(ci));\t// × f(42);\t// × f(make_int());\t// × 1 2 3 4 5 6 7 8 9 10 11 12 13 void f(const int\u0026amp; ref); int i{42}; const int ci{42}; int make_int() {return 42}; // 全能编译 f(i);\tf(ci);\tf(std::move(i));\tf(std::move(ci));\tf(42);\tf(make_int());\t指针 vs. 引用 Ptr Ref 是对象 Alias（不是对象） 总是占用内存 一般不占用内存 数组的指针合法 数组不能创建引用 指针的指针 引用不能引用引用 void 指针 不能引用 void 可以未初始化 必须初始化 初始化之后可以重新赋值 不能更改 可以 cv 修饰 不能 cv 修饰 我看看谁再说引用的本质是指针。\n1 2 3 4 5 6 7 8 9 10 11 12 void f(int\u0026amp;\u0026amp; ref); int i{42}; const int ci{42}; int make_int() {return 42}; f(i);\t// × f(ci);\t// × f(std::move(i));\t// √ f(std::move(ci));\t// × const int\u0026amp;\u0026amp; f(42);\t// √ f(make_int());\t// √ 1 2 3 4 5 6 7 8 9 10 11 12 void f(const int\u0026amp;\u0026amp; ref);\t// 很奇怪，但确实合法，但确实看起来没有用 int i{42}; const int ci{42}; int make_int() {return 42}; f(i);\t// × f(ci);\t// × f(std::move(i));\t// √ f(std::move(ci));\t// √ f(42);\t// √ f(make_int());\t// √ 传参 1 2 3 4 5 void foo(const int\u0026amp; x) { int temp = x; x = 0;\t// Error } foo(make_int()); const lvalue 不能被修改 即使你传的是右值也不行 所以 C++11 加入了右值引用，为了解决这个情况\n1 2 3 4 5 6 void foo(int\u0026amp;\u0026amp; x) { int temp = x; x = 0;\t// OK } foo(make_int()); 右值可以被修改 暗示移动语义 右值引用类型的参数 右值引用的变量在表达式中被使用时，是左值\n1 2 3 4 5 void boo(int\u0026amp;\u0026amp; x); void foo(int\u0026amp;\u0026amp; x) { boo(x);\t// error } 如果你想让他生效，你得 move 一下\n1 2 3 4 5 void boo(int\u0026amp;\u0026amp; x); void foo(int\u0026amp;\u0026amp; x) { boo(std::move(x));\t// error } 所以实际上你在参数中看到右值，那么你需要使用移动语义。如果你是传参的那个，看到参数接受右值，那么也代表你在之后最好不要复用传入的参数。\n此外，std::move 也并不 move，只是 cast to rvalue type。\n万能引用 万能引用的形式有如下两种：\n1 2 template\u0026lt;typename T\u0026gt; void f(T\u0026amp;\u0026amp; x); void f(auto\u0026amp;\u0026amp; x); 要求是：\n推导语境 声明为右值（长得一样） 无 cv 限定 比如：\n以下这些都不是万能引用\n1 2 3 4 5 6 7 8 9 10 11 12 13 template\u0026lt;typename T\u0026gt; int g(const T\u0026amp;\u0026amp; y); template\u0026lt;typename T\u0026gt; struct A { template\u0026lt;typename U, typename Z = T\u0026gt; A(T\u0026amp;\u0026amp; t, U\u0026amp;\u0026amp; u, Z\u0026amp;\u0026amp; z); // \u0026#39;u\u0026#39; \u0026#39;z\u0026#39; 是万能引用，t 不是推导语境 }; template\u0026lt;typename T\u0026gt; void foo(std::vector\u0026lt;T\u0026gt;\u0026amp;\u0026amp; v); auto\u0026amp;\u0026amp; z = {1, 2, 3};\t// initializer list 在哪都特殊 1 2 3 4 5 6 7 8 9 10 11 12 13 template\u0026lt;typename T\u0026gt; void f(T\u0026amp;\u0026amp; x); int i{42}; const int ci{42}; int make_int() {return 42}; f(i);\t// f\u0026lt;int\u0026amp;\u0026gt;(int\u0026amp;) f(ci);\t// f\u0026lt;const int\u0026amp;\u0026gt;(const int\u0026amp;) f(std::move(i));\t// f\u0026lt;int\u0026gt;(int\u0026amp;\u0026amp;) f(std::move(ci));\t// f\u0026lt;const int\u0026gt;(const int\u0026amp;\u0026amp;) f(42);\t// f\u0026lt;int\u0026gt;(int\u0026amp;\u0026amp;) f(make_int());\t// f\u0026lt;int\u0026gt;(int\u0026amp;\u0026amp;) 注意引用折叠：当传入的参数是左值时，万能引用此时会推导为 T\u0026amp;。可以跟以下对比：\n1 2 3 4 5 6 7 8 9 10 11 12 13 template\u0026lt;typename T\u0026gt; void f(const T\u0026amp; x); int i{42}; const int ci{42}; int make_int() {return 42}; f(i);\t// f\u0026lt;int\u0026gt;(const int\u0026amp;) f(ci);\t// f\u0026lt;int\u0026gt;(const int\u0026amp;) f(std::move(i));\t// f\u0026lt;int\u0026gt;(const int\u0026amp;) f(std::move(ci));\t// f\u0026lt;int\u0026gt;(const int\u0026amp;) f(42);\t// f\u0026lt;int\u0026gt;(const int\u0026amp;) f(make_int());\t// f\u0026lt;int\u0026gt;(const int\u0026amp;) 推荐做法 如果你需要一个函数，可以绑定所有的类型，但是只是读取数据，那么你应该使用 const T\u0026amp; (当然，各种 range 也可以)\n转发函数的参数 假设我们实现一些功能：\n1 2 3 void f(int\u0026amp;) {std::cout \u0026lt;\u0026lt; \u0026#34;lvalue\\n\u0026#34;; } void f(const int\u0026amp;) {std::cout \u0026lt;\u0026lt; \u0026#34;const lvalue\\n\u0026#34;; } void f(int\u0026amp;\u0026amp;) {std::cout \u0026lt;\u0026lt; \u0026#34;rvalue\\n\u0026#34;; } 我们需要处理数据，然后把他们传入参数，我们总不能对每个函数都写个 wrapper 吧？所以我们需要完美转发。\n完美转发可以保留函数参数的值类别，通过 std::forward 转发给别的函数。\n1 2 3 4 5 template\u0026lt;typename T\u0026gt; void wrapper(T\u0026amp;\u0026amp; v) { do_something(); f(std::forward\u0026lt;T\u0026gt;(v)); } std::forward 只会将右值保留为右值\n简单实现：\n1 2 3 4 template\u0026lt;typename T\u0026gt; [[nodiscard]] constexpr T\u0026amp;\u0026amp; forward(std::type_identity_t\u0026lt;T\u0026gt;\u0026amp; param) { return static_cast\u0026lt;std::type_identity_t\u0026lt;T\u0026gt;\u0026amp;\u0026amp;\u0026gt;(param); } 注：std::type_identity 用于**建立非推导语境。**正常的 forward 实现也是非推导语境，所以你需要手动指定模板类型参数。\nSinks: 可扩展性 1 2 3 4 5 6 7 class MyClass { public: explicit MyClass(const std::string\u0026amp; txt) : txt_(txt) {} explicit MyClass(std::string\u0026amp;\u0026amp; txt) : txt_(std::move(txt)) {} private: std::string txt_; }; 考虑这种情况，那么显然重载两个构造函数是最好的。\n但是这么做缺乏可扩展性，如果你的成员多了，那得重载多少个构造函数？\n所以你可以考虑使用值类型，这样让用户来决定传什么：\n1 2 3 4 5 6 7 8 class MyClass { public: explicit MyClass(std::string txt1, std::string txt2) : txt1_(std::move(txt1)), txt2(std::move(txt2)) {} private: std::string txt1_; std::string txt2_; }; 但如果你的类型移动开销高的话，那可能你也不想用这种方法，那你需要完美转发：\n1 2 3 4 5 6 7 8 9 class MyClass { public: template\u0026lt;typename T, typename U\u0026gt; MyClass(T\u0026amp;\u0026amp; txt1, U\u0026amp;\u0026amp; txt2) : txt1_(std::forward\u0026lt;T\u0026gt;(txt1)), txt2(std::forward\u0026lt;U\u0026gt;(txt2)) {} private: std::string txt1_; std::string txt2_; }; 但这样的话还有别的问题，别人不知道你到底需要什么类型，没准给你传个int 或者 double 进来，\n那么你就需要一些 Concepts\n1 2 3 4 5 6 7 8 9 class MyClass { public: template\u0026lt;std::same_as\u0026lt;std::string\u0026gt; T, std::same_as\u0026lt;std::string\u0026gt; U\u0026gt; MyClass(T\u0026amp;\u0026amp; txt1, U\u0026amp;\u0026amp; txt2) : txt1_(std::forward\u0026lt;T\u0026gt;(txt1)), txt2(std::forward\u0026lt;U\u0026gt;(txt2)) {} private: std::string txt1_; std::string txt2_; }; 此时如果我传一些 std::string 左值，他就不会工作了，why？\n1 2 std::string txt{\u0026#34;abc\u0026#34;}; MyClass c(txt, txt); 明显 std::string 和推导出的 std::string\u0026amp; 不是一个类型。所以你还得 remove cvr。\n1 2 3 4 5 6 7 8 9 10 11 class MyClass { public: template\u0026lt;typename T, typename U\u0026gt; requires std::same_as\u0026lt;std::remove_cvref_t\u0026lt;T\u0026gt;, std::string\u0026gt;\u0026amp;\u0026amp; std::same_as\u0026lt;std::remove_cvref_t\u0026lt;U\u0026gt;, std::string\u0026gt; MyClass(T\u0026amp;\u0026amp; txt1, U\u0026amp;\u0026amp; txt2) : txt1_(std::forward\u0026lt;T\u0026gt;(txt1)), txt2(std::forward\u0026lt;U\u0026gt;(txt2)) {} private: std::string txt1_; std::string txt2_; }; 那么传 const char[] 也不能过编译，所以我们也不能这么干，应该写：\n1 2 3 4 5 6 7 8 9 class MyClass { public: template\u0026lt;std::convertible_to\u0026lt;std::string\u0026gt; T, std::convertible_to\u0026lt;std::string\u0026gt; U\u0026gt; MyClass(T\u0026amp;\u0026amp; txt1, U\u0026amp;\u0026amp; txt2) : txt1_(std::forward\u0026lt;T\u0026gt;(txt1)), txt2(std::forward\u0026lt;U\u0026gt;(txt2)) {} private: std::string txt1_; std::string txt2_; }; 此外，可以使用 std::convertible_from 允许显式转换。\n问题，以下的代码？ 1 2 3 4 5 6 7 8 9 10 11 12 13 class int_or_empty { int value_{}; bool empty_{true}; public: int_or_empty() = default; template\u0026lt;std::convertible_to\u0026lt;int\u0026gt; T\u0026gt; constexpr int_or_empty(T\u0026amp;\u0026amp; v) : value_{std::forward\u0026lt;T\u0026gt;(v)}, empty_{false} {} constexpr bool empty() const {return empty_;} constexpr operator int() const {return value_;} } 这个代码有点像 optional。\n1 2 3 4 5 6 int_or_empty empty;\t// It is empty int_or_empty one{1}; // It 1 int_or_empty empty2{empty};\t// 不行，因为 empty 可以隐式转换为 int // 但如果 empty 是 const 就可以，因为这样不能转换了 // 即使你有拷贝构造也不可以 这个问题主讲称之为：“Too perfect forwarding”\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 class int_or_empty { int value_{}; bool empty_{true}; public: int_or_empty() = default; template\u0026lt;std::convertible_to\u0026lt;int\u0026gt; T\u0026gt; requires (!std::same_as\u0026lt;std::remove_cvref_t\u0026lt;T\u0026gt;, int_or_empty\u0026gt;) constexpr int_or_empty(T\u0026amp;\u0026amp; v) : value_{std::forward\u0026lt;T\u0026gt;(v)}, empty_{false} {} constexpr bool empty() const {return empty_;} constexpr operator int() const {return value_;} } 你还是得约束一下。\n推荐做法 如果构造函数参数是 完美转发的 单个模板参数 或者 一个参数包，一定要注意，他们可能会劫持你的拷贝构造。\nT\u0026amp;\u0026amp; 和移动语义 如果我就想接受右值引用，不想让他是万能引用怎么办？\n1 2 3 4 5 6 7 8 9 10 11 template\u0026lt;typename T\u0026gt; void foo(T\u0026amp;\u0026amp;); std::vector obj {1, 2, 3}; const std::vector cobj {1, 2, 3}; foo(obj);\t// 不想编译 foo(cobj);\t// 不想编译 foo(std::move(obj));\t// rvalue √ foo(std::move(cobj));\t// rvalue √ foo(std::vector{1, 2, 3});\t// rvalue √ 这里显然委员会的设计有问题（确实，之前nikolai 讲移动语义的时候也提到了，他们在设计完美转发的时候不太成熟就放出来了）\n你需要约束一下：\n1 2 3 4 5 6 7 8 9 10 11 12 template\u0026lt;typename T\u0026gt; requires (!std::is_lvalue_reference_v\u0026lt;T\u0026gt;)\t// 这里 T 会被推导为 std::vector\u0026lt;int\u0026gt;\u0026amp;，这样就可以避免左值时的调用了 void foo(T\u0026amp;\u0026amp;); std::vector obj {1, 2, 3}; const std::vector cobj {1, 2, 3}; foo(obj);\t// × foo(cobj);\t// × foo(std::move(obj));\t// rvalue √ foo(std::move(cobj));\t// rvalue √ foo(std::vector{1, 2, 3});\t// rvalue √ 只使用 std::is_reference_v\u0026lt;T\u0026gt; 是不行的，因为有的人可能会显示调用这个函数（foo\u0026lt;std::vector\u0026lt;int\u0026gt;\u0026amp;\u0026amp;\u0026gt;(v)）\n捕获参数 协程的状态存储协程参数：\nby-value 那么参数会 move 或者 copy by-reference 那么依然会是引用 所以你给协程传参时要注意生命周期，不然可能会悬垂引用。那怎么办呢？\n1 2 3 4 5 6 7 8 9 10 11 12 13 template\u0026lt;typename T\u0026gt; task\u0026lt;void\u0026gt; foo(T\u0026amp;\u0026amp; t) { ... } template\u0026lt;typename U\u0026gt; task\u0026lt;void\u0026gt; boo(U\u0026amp;\u0026amp; u) { return foo(std::forward\u0026lt;U\u0026gt;(u)); } int main() { int i{123}; co_await boo(i);\t// T -\u0026gt; int\u0026amp;; t -\u0026gt; int\u0026amp; co_await boo(42);\t// T -\u0026gt; int; t -\u0026gt; int\u0026amp;\u0026amp; } co_await boo(i) 没问题，因为 i 存在于函数的栈上。但如果是临时变量，它就释放了。\n所以 foo 那个协程，根据上面的规则，保留了引用（即使是右值引用）那么生命周期就会出问题。\n那该咋办呢？\n1 2 template\u0026lt;typename T\u0026gt; task\u0026lt;void\u0026gt; foo(T t) { ... } 其他都不变，这样就可以了。此时\n1 co_await boo(42);\t// T -\u0026gt; int; t -\u0026gt; int 这样就可以直接拷贝，不会有右值引用的生命周期问题了。\n完美的返回参数 1 2 3 4 template\u0026lt;typename T\u0026gt; auto wrapper(T\u0026amp;\u0026amp; v) { return foo(std::forward\u0026lt;T\u0026gt;(v)); } auto 并不行，他总是会想返回值。auto\u0026amp;\u0026amp; 也不好，我们应该使用：\n1 2 3 4 template\u0026lt;typename T\u0026gt; decltype(auto) wrapper(T\u0026amp;\u0026amp; v) { return foo(std::forward\u0026lt;T\u0026gt;(v)); } 这样 decltype(auto) 会在返回临时变量的时候返回值，返回引用的时候返回引用。\n当然，也可能需要先完美转发，再完美的返回。\n1 2 3 4 5 template\u0026lt;typename T\u0026gt; decltype(auto) wrapper(T\u0026amp;\u0026amp; v) { auto\u0026amp;\u0026amp; ret = foo(std::forward\u0026lt;T\u0026gt;(v)); return foo2(std::forward\u0026lt;decltype(ret)\u0026gt;(ret)); } 这是万能引用吗？ 1 2 3 for (auto\u0026amp;\u0026amp; x : f()) { // ... } 在泛型语境中，使用 auto\u0026amp;\u0026amp; 来遍历 for 循环是最安全的。\n总结 只读情况下使用 const MyClass\u0026amp; 一起使用 const MyClass\u0026amp; and MyClass\u0026amp;\u0026amp; 在移动消耗不高的情况下 使用 MyClass 开销比较大时考虑 使用 T\u0026amp;\u0026amp; 来转发参数 注意接收一个参数的构造函数 记住它会绑定一切而不是仅仅你想要的类型 记住它不是右值引用 使用 decltype(auto) 作为函数的返回类型来完美返回另外一个函数的调用结果 使用 auto\u0026amp;\u0026amp; 来存储一会要转发的万能引用 一般在泛型语境的 range-based-for 中使用 ","date":"2024-03-24T00:00:00Z","image":"https://rossqaq.github.io/cppcon2023-cover.png","permalink":"https://rossqaq.github.io/article/cppcon-2023-fwdref/","title":"C++ 转发引用（万能引用）"},{"content":"本文来自 Raymond Chen 的系列博客\n[Mundane std::tuple tricks: Getting started](Mundane std::tuple tricks: Getting started - The Old New Thing (microsoft.com))\nMundane std::tuple tricks: Selecting via an index sequence\nMundane std::tuple tricks: Selecting via an index sequence, part 2\nMundane std::tuple tricks: Creating interesting index sequences\nMundane std::tuple tricks: Creating more interesting index sequences\nMundane std::tuple tricks: Finding a type in a tuple\n未取得授权，私自翻译，仅用于学习目的，如若侵权联系我删除。\nGetting Started C++ 标准库的 tuple 充满魔法，它可以将一堆类型或者值 grab 到一个单个的单位，并且 C++ 标准库也提供了很多帮助函数来辅助操作。\n例如，std::make_tuple 让你可以从一堆值中构造 tuple，用来解决你捕获参数包之后把它变成可以操作的东西：\n1 2 3 [](auto... args) { auto args_tuple = std::make_tuple(std::move(args)...); } 我们学习过，std::tuple_element_t 可以让你从 tuple 中获取单个类型，std::get 可以获取单个值。\n标准库提供 std::tuple_cat 来串联 N 个 tuple 的值，但标准库没有提供串联 N 个 tuple 类型的版本，我们可以自己实现一个：\n1 2 3 4 5 6 7 8 9 10 11 template\u0026lt;typename T1, typename T2\u0026gt; struct tuple_cat_helper; template\u0026lt;typename... T1, typename... T2\u0026gt; struct tuple_cat_helper\u0026lt;std::tuple\u0026lt;T1...\u0026gt;, std::tuple\u0026lt;T2...\u0026gt;\u0026gt; { using type = std::tuple\u0026lt;T1..., T2...\u0026gt;; } template\u0026lt;typename T1, typename T2\u0026gt; using tuple_cat_t = typename tuple_cat_helper\u0026lt;T1, T2\u0026gt;::type; // example is std::tuple\u0026lt;int, char, double\u0026gt; using example = tuple_cat_t\u0026lt;std::tuple\u0026lt;int\u0026gt;, std::tuple\u0026lt;char, double\u0026gt;\u0026gt;; 我们定义了一个特化的模板 tuple_cat_helper 来析取所有的 tuple 类型并且生成新的类型，串联两个 tuple 列表。之后定义了 _t 的版本。\n或者也可以偷懒，让 std::tuple_cat 来做：\n1 2 template\u0026lt;typename T1, typename T2\u0026gt; using tuple_cat_t = decltype(std::tuple_cat(std::declval\u0026lt;T1\u0026gt;(), std::declval\u0026lt;T2\u0026gt;())); 然后为了让他支持多个 Tuple：\n1 2 template\u0026lt;typename... Tuples\u0026gt; using tuple_cat_t = decltype(std::tuple_cat(std::declval\u0026lt;Tuple\u0026gt;()...)); 写的更少，做的更多。\n标准库中有工具把它们组合在一起，但是没有工具把它们分开。\nBonus chatter: I wasn’t quite telling the truth when I said that make_tuple can capture a template parameter pack. We’ll come back to this issue later.\n通过 index sequence 进行选择 1 上一次，我们组合了 tuples。组合他们很简单，但想要分开他们有点难。\nstd::index_sequence (C++14) 由标准库提供的类型，捕获 0 个或更多的非负整数序列，然后把它们转换为一个类型。它是 std::integer_sequnence 的特化。std::integer_sequence 会捕获用户提供的类型的整数序列，而 std::index_sequence 的用户提供类型是 std::size_t。\ntuple 的拆分涉及到包含一个 std::index_sequence 的参数包展开。（译者：原文用的 fold expression，但这里明显不是 C++17 的折叠表达式，应该是说包展开吧。）\n1 2 3 4 5 // 不要这么做，之后会解释： template\u0026lt;typename Tuple, std::size_t... Ints\u0026gt; auto select_tuple(Tuple\u0026amp;\u0026amp; tuple, std::index_sequence\u0026lt;Ints...\u0026gt;) { return std::make_tuple( std::get\u0026lt;Ints\u0026gt;(std::forward\u0026lt;Tuple\u0026gt;(tuple))... ); } 以上这一段是拆分 tuple 的核心，我们来解释一下。\n第一个参数是需要操作的 tuple，使用万能引用传入，这样我们就可以对他进行转发了。这会保留右值性（rvalue-ness），这在某些情况比如 tuple 是 move-only 的时候非常好用。（在 both copyable and movable 情况下也有帮助，因为它会选择移动，这样的话开销更小）。\n剩下的参数是 size_t 数值，代表 index_sequence 的 index。\n表达式：\n1 (std::get\u0026lt;Ints\u0026gt;(std::forward\u0026lt;Tuple\u0026gt;(tuple))...); 是 std::make_tuple 的参数列表。表达式会对每个 Ints 包中的值调用，结果就是生成一系列的参数然后来提取 tuple 中对应索引的值。\n例如：\n1 auto res = select_tuple(std::make_tuple(\u0026#39;x\u0026#39;, 3.14, \u0026#39;z\u0026#39;), std::index_sequence\u0026lt;2, 1, 1, 2\u0026gt;{}); 我们提供了一个 3 个元素的 tuple，并且选择 2, 1, 1, 2 对应索引的元素。表达式会展开为：\n1 2 3 4 (std::get\u0026lt;2\u0026gt;(std::forward\u0026lt;Tuple\u0026gt;(tuple)), std::get\u0026lt;1\u0026gt;(std::forward\u0026lt;Tuple\u0026gt;(tuple)), std::get\u0026lt;1\u0026gt;(std::forward\u0026lt;Tuple\u0026gt;(tuple)), std::get\u0026lt;2\u0026gt;(std::forward\u0026lt;Tuple\u0026gt;(tuple))) 从 tuple 中提取项 2, 1, 1, 2，然后把它们传递给 make_tuple ，重新把它们组成一个 tuple ('z', 3.14, 3.14, 'z')。注意索引 1 和 2 都被提取了多次，0没有被提取；也要注意结果 tuple 的 size 跟使用的索引匹配，而不是原 tuple 的 size。\n注意如果 tuple 里的类型是 movable 类型，那么提取 \u0026lt;2, 1, 1, 2\u0026gt; 会导致它们的项被多次移动。这样的话结果就乱了，所以你通常不应该对一个值提取多次。（虽然并没有阻止这么做）。\n不过我们的 select_tuple 也有缺陷。\n通过 index sequence 进行选择 2 上次我们编写了 select_tuple 函数接收一个 tuple 和一个 index sequence 为参数，并且产生一个新的基于 index sequence 选择元素的 tuple。我们有：\n1 2 3 4 5 6 7 // Don\u0026#39;t use this; see discussion. template\u0026lt;typename Tuple, std::size_t... Ints\u0026gt; auto select_tuple(Tuple\u0026amp;\u0026amp; tuple, std::index_sequence\u0026lt;Ints...\u0026gt;) { return std::make_tuple( std::get\u0026lt;Ints\u0026gt;(std::forward\u0026lt;Tuple\u0026gt;(tuple))...); } 你如果想使用它的话：\n1 2 std::tuple\u0026lt;int, char, float\u0026gt; t{ 1, \u0026#39;x\u0026#39;, 2.0 }; auto t2 = select_tuple(t, std::index_sequence\u0026lt;0, 2\u0026gt;{}); t2 是 std::tuple\u0026lt;int, float\u0026gt;{1, 2.0}\n但这个函数有问题。\n提问：什么时候 std::make_tuple\u0026lt;T\u0026gt;() 返回的不是 std::tuple\u0026lt;T\u0026gt; ？\nstd::make_tuple\u0026lt;T\u0026gt; Produces std::tuple\u0026lt;T\u0026gt; int int const int int int\u0026amp; int int\u0026amp;\u0026amp; int std::reference_wrapper\u0026lt;int\u0026gt; int\u0026amp; std::reference_wrapper\u0026lt;const int\u0026gt; int\u0026amp; std::reference_wrapper\u0026lt;int\u0026amp;\u0026gt; int\u0026amp; std::reference_wrapper\u0026lt;int\u0026amp;\u0026amp;\u0026gt; int\u0026amp; 答案：当 T 是可以退化，或者是 reference_wrapper 类型的时候\n退化是一个 C++ 术语，指代的是在传值给函数时类型发生的变化的行为：\n引用会退化为底层数值类型 cv 会被移除 数组退化为指针 函数退化为函数指针 但是 make_tuple 有额外的规则：如果退化的类型是一个 reference_wrapper ，那么其结果是底层的引用类型。\n我们并不想发生那样的转换。如果你从 tuple 中选择的类型是个引用，那么你想要结果 tuple 也有相同的引用类型。\n所以不能使用 make_tuple，我们得显式的指明我们要的类型：\n1 2 3 4 5 template\u0026lt;typename Tuple, std::size_t... Ints\u0026gt; auto select_tuple(Tuple\u0026amp;\u0026amp; tuple, std::index_sequence\u0026lt;Ints...\u0026gt;) { return std::tuple\u0026lt;std::tuple_element_t\u0026lt;Ints, Tuple\u0026gt;...\u0026gt;( std::get\u0026lt;Ints\u0026gt;(std::forward\u0026lt;Tuple\u0026gt;(tuple))...); } 或者也可以：\n1 2 3 4 5 template\u0026lt;typename Tuple, std::size_t... Ints\u0026gt; std::tuple\u0026lt;std::tuple_element_t\u0026lt;Ints, Tuple\u0026gt;...\u0026gt; select_tuple(Tuple\u0026amp;\u0026amp; tuple, std::index_sequence\u0026lt;Ints...\u0026gt;) { return { std::get\u0026lt;Ints\u0026gt;(std::forward\u0026lt;Tuple\u0026gt;(tuple))... }; } 好了，helper 都有了，我们可以玩更花哨的了。\n创建有趣的 index sequence C++ 标准库对于操作 index sequences 只给了一个 helper，std::make_integer_sequence 以及它的近亲 std::make_index_sequence，也就是 size_t。\n注意，std::make_index_sequnece 的模板参数是结果 index sequence 的大小，并不是最高那个值。\n即使只有从 0 开始的 index sequences，我们也能干很多有趣的事情。\n1 2 3 4 5 6 template\u0026lt;typename Tuple\u0026gt; auto remove_last(Tuple\u0026amp;\u0026amp; tuple) { constexpr auto size = std::tuple_size_v\u0026lt;Tuple\u0026gt;; using indices = std::make_index_sequence\u0026lt;size - 1\u0026gt;; return select_tuple(std::forward\u0026lt;Tuple\u0026gt;(tuple), indices{}); } remove_last 函数移除 tuple 的最后一个元素并且 return 剩下的。我们通过提取源 tuple 的 size 来做到这一点，让他 -1，然后生成一个新的 index sequence（0~size - 2），元素个数就为 size - 1\n那么，其他的 index sequence 怎么样呢？我们得自己实现\n1 2 3 4 5 6 7 8 9 10 11 12 template\u0026lt;std::size_t N, typename Seq\u0026gt; struct offset_sequence; template\u0026lt;std::size_t N, std::size_t Ints...\u0026gt; struct offset_sequence\u0026lt;N, std::index_sequence\u0026lt;Ints...\u0026gt;\u0026gt; { using type = std::index_sequence\u0026lt;Ints + N...\u0026gt;; } template\u0026lt;std::size_t N, typename Seq\u0026gt; using offset_sequence_t = typename offset_sequence\u0026lt;N, Sqe\u0026gt;::type; // example = index_sequence\u0026lt;3, 4, 5, 6\u0026gt; using example = offset_sequence_t\u0026lt;3, std::make_index_sequence\u0026lt;4\u0026gt;\u0026gt;; 为了实现 index sequence 的偏移版本，我们生成一个新的 index sequence 它持有的序列是原来的序列 + offset N。魔法发生在参数包展开：\n1 using type = std::index_sequence\u0026lt;Ints + N...\u0026gt;; 这会取出原 index sequence 的每个数，然后 +N，之后用来重新生成一个新的序列。\n现在我们就可以移除 tuple 的第一个元素了\n1 2 3 4 5 6 template\u0026lt;typename Tuple\u0026gt; auto remove_first(Tuple\u0026amp;\u0026amp; tuple) { constexpr auto size = std::tuple_size_v\u0026lt;Tuple\u0026gt;; using indices = offset_sequence_t\u0026lt;1, std::make_index_sequence\u0026lt;size - 1\u0026gt;\u0026gt;; return select_tuple(std::forward\u0026lt;Tuple\u0026gt;(tuple), indices{}); } 实际上，我们可以移除第 N 个元素\n1 2 3 4 5 6 7 8 9 10 template\u0026lt;std::size_t N, typename Tuple\u0026gt; auto remove_Nth_element(Tuple\u0026amp;\u0026amp; tuple) { constexpr auto size = std::tuple_size_v\u0026lt;Tuple\u0026gt;; using first = std::make_index_sequence\u0026lt;N\u0026gt;; using rest = offset_sequence\u0026lt;N + 1, std::make_index_sequence\u0026lt;size - N - 1\u0026gt;\u0026gt;; return std::tuple_cat( select_tuple(std::forward\u0026lt;Tuple\u0026gt;(tuple), first{}); select_tuple(std::forward\u0026lt;Tuple\u0026gt;(tuple), rest{}); ); } 我们想要的是提取前 N 个元素，然后跳过第 N 个，之后提取 N + 1 个元素到结尾。\n提取前 N 个很简单：直接选择从 0 ~ N - 1的\n提取剩余的需要一些思考：我们想要 N + 1 开始，知道 size - 1 结束，长度为 (size - 1) - (N + 1) + 1 = size - N - 1. 好了，现在我们生成了长度为 size - N - 1 的整数序列，起始点就是 N + 1.\n我们调用两次 select_tuple，一次获取前半部分，一次获取后半部分，之后用 std::tuple_cat 组合。\n另一种方法是只选择一次，如果这么做的话，我们需要结合两个 index sequences\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 template\u0026lt;typename Sqe1, typename Seq2\u0026gt; struct cat_sequence; template\u0026lt;std::size_t... Ints1, std::size_t... Ints2\u0026gt; struct cat_sequence\u0026lt;std::index_sequence\u0026lt;Ints1...\u0026gt;, std::index_sequence\u0026lt;Ints2...\u0026gt;\u0026gt; { using type = std::index_sequence\u0026lt;Ints1..., Ints2...\u0026gt;; } template\u0026lt;typename Seq1, typename Seq2\u0026gt; using cat_sequence_t = typename cat_sequence\u0026lt;Seq1, Seq2\u0026gt;::type; // example = index_sequence\u0026lt;3, 1, 4, 1, 5, 9\u0026gt; using example = cat_sequence_t\u0026lt;std::index_sequence\u0026lt;3, 1, 4\u0026gt;, std::index_sequence\u0026lt;1, 5, 9\u0026gt;\u0026gt;; 魔法发生在：\n1 using type = std::index_sequence\u0026lt;Ints1..., Ints2...\u0026gt;; 接收两个 sequence 并且把他们挨着组成一个单个的序列。\n我们现在可以这样使用：\n1 2 3 4 5 6 7 8 9 10 template\u0026lt;std::size_t N, typename Tuple\u0026gt; auto remove_Nth_element(Tuple\u0026amp;\u0026amp; tuple) { constexpr auto size = std::tuple_size_v\u0026lt;Tuple\u0026gt;; using first = std::make_index_sequence\u0026lt;N\u0026gt;; using rest = offset_sequence_t\u0026lt;N+1, std::make_index_sequence\u0026lt;size-N-1\u0026gt;\u0026gt;; using indices = cat_sequence_t\u0026lt;first, rest\u0026gt;; return select_tuple(std::forward\u0026lt;Tuple\u0026gt;(tuple), indices{}); } 创建更有趣的 index sequence 我们可以泛化之前的版本，\n1 2 3 4 5 6 7 8 9 template\u0026lt;std::size_t F(std::size_t), typename Seq\u0026gt; struct modify_sequence; template\u0026lt;std::size_t F(std::size_t), typename std::size_t... Ints\u0026gt; struct modify_sequence\u0026lt;F, std::index_sequence\u0026lt;Ints...\u0026gt;\u0026gt; { using type = std::index_sequence\u0026lt;F(Ints)...\u0026gt;; }; template\u0026lt;std::size_t F(std::size_t), typename Seq\u0026gt; using modify_sequence_t = typename modify_sequence\u0026lt;F, Seq\u0026gt;::type; 未完待续……\n","date":"2024-03-24T00:00:00Z","permalink":"https://rossqaq.github.io/article/tuple-tricks/","title":"普通的 std::tuple 技巧"},{"content":"最近因为面试要学习 Rust，突击了几天，感觉 Rust 是真的麻烦。\n但确实 Rust 很多地方是 copy 了 C++ 的，然后做出了一些改进。\n本文章是建立在我比较懂 C++ 但是不懂 Rust 的情况下写出来的，不保正内容完全正确。仅作为个人记录，为更深入的理解 Rust 做铺垫。\n堆内存、栈内存 首先要说的是我不知道 C++ 的标准里有没有规定堆内存和栈内存，但大概的实现应该和大部分网上的资料相同。至少目前这么认为应该没问题？\n以下为了方便叙述，就假设目前已知的资料是正确的。\nRust 跟 C++ 一样，在堆上使用内存都需要分配（栈内存那当然不用分配……因为已经预先分配好了，不然就不用 stack overflow 了），然后使用指针访问。\n那么所有权存在的原因是什么呢？在 Rust 中，管理 heap 数据，就是所有权存在的原因。\nRust 怎么回收内存呢？和 C++ 一样，反正不是通过 GC 回收，而是通过所有权。\nRust 在编译时会进行一系列的检查，如果违反了所有权的规则，那么就不能过编译（存在潜在的内存泄漏可能）。\n所有权 Rust 中关于所有权有三条规则：\n每一个值都有一个所有者。 每个值在任何时刻 有且只有一个所有者。 所有者离开作用域，值会被 Drop 我思考了一下，Rust 应该是把对象的生命周期和存储周期绑定在一起了？当然在 C++ 中如果你遵循 RAII 的话那大部分时刻也是这样的。\nString 在 Rust 中是存储在堆上的，以下都用 String 来作为示例（当然其他用堆存储数据的结构也同理）。\n普通的字符串使用：\n1 2 3 4 5 6 7 fn main() { let mut str = String::from(\u0026#34;Hello\u0026#34;); str.push_str(\u0026#34; World\u0026#34;); println!(\u0026#34;{str}\u0026#34;); } 根据上面的规则，你别管堆内存栈内存，离开作用域就会被释放，Rust 在 } 自动调用 drop 函数（C++ 中的 RAII）\nRust vs. C++ -\u0026gt; 移动 Rust 中对于存在于堆上的对象，默认语义是 移动。\n以下代码无法编译，因为 str 的所有权已经移动给了 str2 。\n1 2 3 4 5 6 7 8 fn main() { let str = String::from(\u0026#34;Hello World\u0026#34;); let str2 = str; println!(\u0026#34;{str}\u0026#34;); println!(\u0026#34;{str2}\u0026#34;); } 而在 C++ 中，首先，C++ 默认语义全是拷贝，如果要移动需要调用 std::move，此外，C++ 标准保证标准库组件被移动后状态为 valid （但未指定）。\n以下代码可以编译，访问 str.length() 是合法的\n1 2 3 4 5 6 7 8 int main() { std::string str{ \u0026#34;Hello World\u0026#34; }; auto str2 = std::move(str); std::cout \u0026lt;\u0026lt; str.length() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; std::cout \u0026lt;\u0026lt; str2 \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } 对于存在栈上的对象大家都一样。\nRust 这么干明显可以避免 double free 这种问题。\n当然了，不管是 Rust 还是 C++，移动都不代表浅拷贝。\nRust vs. C++ -\u0026gt; 克隆 如果真的要复制堆上的数据，在 Rust 中，需要调用 .clone() 方法，这个就创建了一个副本。\n而在 C++ 中当然直接 = 赋值默认就会选择复制构造。\n但需要注意，Rust 不允许实现 Drop trait 的同时实现 Copy trait。\n真是严格呢~\nRust vs. C++ -\u0026gt; 所有权 + 函数 根据之前的介绍，Rust 默认写值就是移动语义，那么在函数参数中自然也如此。\n以下代码并不能通过编译，str 的所有权移动给了函数 takes_ownership 的参数上，在出函数作用域时已经被释放了。\n1 2 3 4 5 6 7 8 9 10 11 fn main() { let str = String::from(\u0026#34;Hello World\u0026#34;); takes_ownership(str); println!(\u0026#34;{str}\u0026#34;); } fn takes_ownership(str: String) { println!(\u0026#34;{str}\u0026#34;); } 在 C++ 中想实现类似的效果需要：\n1 2 3 4 5 6 7 8 9 10 11 void takes_ownership(std::string\u0026amp;\u0026amp; str) { std::cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } int main() { std::string str{ \u0026#34;Hello World\u0026#34; }; takes_ownership(std::move(str)); std::cout \u0026lt;\u0026lt; str.length() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } 注意，函数参数写的是 \u0026amp;\u0026amp;，这样才是直接调用移动构造，然后在函数结尾销毁参数，然后 str 是 valid 但是未指明状态。\n而如果写普通的值类型，那么 main 中的 str 还是要析构的。\n这里我也没太明白，我感觉应该是跟解分配和释放有关。总之，\u0026amp;\u0026amp; 才是和 Rust 的语义相同。\nRust 中还能返回所有权，这样参数就不会被销毁了，即：\n1 2 3 4 5 6 7 8 9 10 11 12 fn main() { let str = String::from(\u0026#34;Hello World\u0026#34;); let str2 = takes_ownership(str); println!(\u0026#34;{str2}\u0026#34;); } fn takes_ownership(str: String) -\u0026gt; String { println!(\u0026#34;{str}\u0026#34;); str } 这里可以利用一下 rust 的 shadowing，直接让返回的变量也叫 str。当然这里 str 是不可变引用，所以得 shadowing，不能直接用 str 接返回值。\n在 C++ 里一般应该不会这么干，如果想干的话：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 std::string takes_ownership(std::string\u0026amp;\u0026amp; str) { std::cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; return str; } int main() { std::string str{ \u0026#34;Hello World\u0026#34; }; str = takes_ownership(std::move(str)); std::cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; return 0; } 返回的时候值类型就可以，会帮你选择移动的。\n引用 Rust 中，如果不需要所有权，那么可以给函数传入一个引用。\n也就是说：引用不持有所有权，创建一个引用称为 借用。\nRust vs. C++ -\u0026gt; 引用 Rust 给函数传参也需要加上 \u0026amp; 符号，代表传递引用。\n（弹幕说其实是类似于指针，Rust 在函数参数这个地方自动帮你解引用了）\n1 2 3 4 5 6 7 8 9 10 11 fn main() { let str = String::from(\u0026#34;Hello World\u0026#34;); let str_len = calculate_length(\u0026amp;str); println!(\u0026#34;{str_len}\u0026#34;); } fn calculate_length(str: \u0026amp;String) -\u0026gt; usize { str.len() } 那这个在 C++ 里就不用说了吧：\n1 2 3 4 5 6 7 8 9 10 11 12 13 size_t calculate_length(const std::string\u0026amp; str) { return str.length(); } int main() { std::string str{ \u0026#34;Hello World\u0026#34; }; auto str_len = calculate_length(str); std::cout \u0026lt;\u0026lt; str_len \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; return 0; } 如果想要在函数里修改字符串，那么在 Rust 中你需要：\n1 2 3 4 5 6 7 8 9 10 11 12 fn main() { let mut str = String::from(\u0026#34;Hello\u0026#34;); let str_len = change(\u0026amp;mut str); println!(\u0026#34;str: {str}, len: {str_len}\u0026#34;); } fn change(str: \u0026amp;mut String) -\u0026gt; usize { str.push_str(\u0026#34; World!\u0026#34;); str.len() } 如果在 C++ 中，反过来（这俩一个默认可变一个默认不可变真的是）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 size_t change(std::string\u0026amp; str) { str += \u0026#34; World!\u0026#34;; return str.length(); } int main() { std::string str{ \u0026#34;Hello\u0026#34; }; auto str_len = change(str); std::cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39; \u0026lt;\u0026lt; str_len \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; return 0; } Rust vs. C++ -\u0026gt; 可变引用 在 Rust 中，同时创建并使用两个可变引用是错误的。\n1 2 3 4 5 6 7 8 9 fn main() { let mut str = String::from(\u0026#34;Hello\u0026#34;); let str2 = \u0026amp;mut str;\t// str2 虽然没写 mut，但也是可变引用，s3 同理。 let str3 = \u0026amp;mut str; println!(\u0026#34;{str2}, {str3}\u0026#34;); } C++ 不用说了肯定可以。\n引用借用出去后，原来的引用是不能修改的（可能是防止 Rust 所说的“数据竞争”），例如：\n这个代码可以通过编译：\n1 2 3 4 5 6 7 8 9 10 11 fn main() { let mut str = String::from(\u0026#34;Hello\u0026#34;); let r = \u0026amp;mut str; r.push_str(\u0026#34;123\u0026#34;); str.push_str(\u0026#34;456\u0026#34;); println!(\u0026#34;{str}\u0026#34;); } 而这段代码不能通过编译：\n1 2 3 4 5 6 7 8 9 10 11 fn main() { let mut str = String::from(\u0026#34;Hello\u0026#34;); let r = \u0026amp;mut str; str.push_str(\u0026#34;456\u0026#34;); r.push_str(\u0026#34;123\u0026#34;); println!(\u0026#34;{str}\u0026#34;); } Rust 中，在不同作用域可以拥有多个可变引用，但不能同时拥有（类似于 lock_guard ? 正常，不然就冲突了，而在同一个大括号作用域内是不会冲突的）\n此外，在同时使用可变引用和不可变引用时也有这种规则：\n以下代码无法通过编译，其实类似于读写锁，就像写锁只能有一个，读锁可以很多，而读写又互斥。\n1 2 3 4 5 6 7 8 9 10 fn main() { let mut str = String::from(\u0026#34;Hello\u0026#34;); let r1 = \u0026amp;str; let r2 = \u0026amp;str; let r3 = \u0026amp;mut str; println!(\u0026#34;{r1} {r2} {r3}\u0026#34;); } 注意，这里如果你使用了 r1 r2 那么就不能编译，如果你没有使用，那么可以编译。\n引用的作用域是：引用声明的地方开始，到最后一次使用为止。\n编译器判断这个的能力称之为：非词法作用域生命周期，NLL。\nRust vs. C++ -\u0026gt; 悬垂引用 在 Rust 中，会阻止你使用悬垂引用，编译器确保引用永远有效。\n1 2 3 4 5 6 7 8 fn main() { let mut str = dangling(); } fn dangling() -\u0026gt; \u0026amp;String { let str = String::from(\u0026#34;dangling ref\u0026#34;); \u0026amp;str } 这里会报错，需要生命周期标记。\n如果是 C++ 中，那必然是可以返回的，你得自己避免。\nSlice Slice 也是 Rust 中的一种引用，他引用一段连续的集合，既然 Slice 也是引用，那么自然也没有所有权。\nRust vs. C++ -\u0026gt; 字符串 Slice 使用一个左闭右开的 range，当然，也可以写 \u0026amp;s[0..=4] 来给一个闭区间。\n此外，0可以省略，最后一个 idx 也可以省略，比如 \u0026amp;s[..]。\n字符串的 slice 类型叫做 \u0026amp;str，字符串常量的类型也是 \u0026amp;str\n1 2 3 4 5 fn main() { let s = String::from(\u0026#34;Hello\u0026#34;); let hello = \u0026amp;s[0..5]; } 在 C++ 中 字符串 Slice 明显是 C++17 的 std::string_view，然后字符串字面量的类型明显都是 const char[]\n1 2 3 4 5 int main() { std::string str{ \u0026#34;Hello\u0026#34; }; auto view = std::string_view{ str.begin(), str.begin() + 5 }; } 其他的结构可以用 C++20 的 std::span 以及 C++23 的 std::mdspan 来进行切片。\n而不管是 Rust 还是 C++，都可以对 Slice 字符串直接传递 String/std::string。\n","date":"2024-03-21T00:00:00Z","permalink":"https://rossqaq.github.io/article/rust-ownership/","title":"C++ vs. Rust - 所有权"},{"content":"好复杂的规则……\n什么是生命周期 Rust 每个引用都有自己的生命周期 生命周期是指：引用保持有效的作用域 大多数情况下生命周期是隐式可被推断的 当引用的生命周期可能互相关联时，需要手动指定生命周期 生命周期存在的目标就是避免悬垂引用。\n1 2 3 4 5 6 7 8 9 fn main() { let r; { let x = 5; r = \u0026amp;x; } println!(\u0026#34;{r}\u0026#34;); } 这段代码明显不能过编译，因为 r 是 x 的引用，使用 r 时，x 的生命周期已经结束了。\nrust 使用 borrow-checker 来检查所有的作用域，判断借用是否合法。\n生命周期参数 考虑这个函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 fn main() { let string1 = String::from(\u0026#34;abcd\u0026#34;); let string2 = \u0026#34;xyz\u0026#34;; let res = longest(string1.as_str(), string2); println!(\u0026#34;The longest string is {}\u0026#34;, res); } fn longest(x: \u0026amp;str, y: \u0026amp;str) -\u0026gt; \u0026amp;str { if x.len() \u0026gt; y.len() { x } else { y } } 函数很简单，但编译会报错，rust 编译器会提示你：期望一个具名的生命周期参数。\n因为函数签名体现不出借用的值的生命周期，我们得加一个生命周期参数：\n1 2 3 4 5 6 7 fn longest\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;a str) -\u0026gt; \u0026amp;\u0026#39;a str { if x.len() \u0026gt; y.len() { x } else { y } } 生命周期标注 首先注意，生命周期的标注并不能改变引用的生命周期长度。指定了泛型生命周期参数之后，函数就可以接收带有任何生命周期的引用。\n生命周期标注是用于：没描述多个引用的生命周期的关系。\n语法 生命周期参数名 ' 开头 全小写，短 基本使用 'a 生命周期标注的位置 在引用的 \u0026amp; 后 使用空格将标注和引用分开 函数签名中的生命周期标注 和泛型一样，在 \u0026lt;\u0026gt; 中声明 返回值中也要声明 例子 1 2 3 \u0026amp;i32\t\u0026amp;\u0026#39;a i32\t// 带生命周期的引用 \u0026amp;\u0026#39;a mut i32\t// 带生命周期的可变引用 1 2 3 4 5 6 7 fn longest\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;a str) -\u0026gt; \u0026amp;\u0026#39;a str { if x.len() \u0026gt; y.len() { x } else { y } } 这段代码中返回的生命周期是两个参数中较短的那个。\n深入理解生命周期 指定生命周期参数的方式依赖于函数的行为\n1 2 3 fn longest\u0026lt;\u0026#39;a\u0026gt;(x: \u0026amp;\u0026#39;a str, y: \u0026amp;str) -\u0026gt; \u0026amp;\u0026#39;a str { x } 例如这个函数只返回 x，那么就不用依赖于 y 的生命周期了，自然也不用标注\n从函数返回引用时，返回类型的生命周期参数要与其中一个参数的生命周期匹配\n如果返回的引用没有指向任何参数，那么暗示它引用的是函数内部创建的值，那明显是悬垂引用。\n结构体定义中的生命周期标注 结构体可以包括 自持有类型（i32） 引用：需要在每个引用上添加生命周期标注 1 2 3 struct ImportantExcerpt\u0026lt;\u0026#39;a\u0026gt; { part: \u0026amp;\u0026#39;a str, } 代表结构体内的引用必须比结构体的实例本身活得长。\n输入、输出生命周期 出现在函数的参数：输入生命周期\n出现在函数返回值：输出生命周期\n生命周期省略的三个规则 规则 1 应用于输入生命周期，规则 2、3 应用于输出生命周期。\n如果规则应用完仍然无法确定生命周期，那么会报错。此外，这些规则适用于 fn 定义以及 impl 块。\n每个引用类型的参数都有自己的生命周期 如果只有 1 个输入生命周期参数，那么就会把它赋给所有的输出生命周期参数 如果有多个输入生命周期参数，但其中一个是 \u0026amp;self / \u0026amp;mut self ，那么 self 的生命周期会赋给所有的输出生命周期参数。 例子 假设我们自己是编译器：\n1 fn first_word(s: \u0026amp;str) -\u0026gt; \u0026amp;str 先应用第一条规则：\n1 fn first_word\u0026lt;\u0026#39;a\u0026gt;(s: \u0026amp;\u0026#39;a str) -\u0026gt; \u0026amp;str 函数只有一个输入生命周期参数，那么应用第二条规则：\n1 fn first_word\u0026lt;\u0026#39;a\u0026gt;(s: \u0026amp;\u0026#39;a str) -\u0026gt; \u0026amp;\u0026#39;a str 这种情况下显然编译器就可以处理。\n1 fn longest(x: \u0026amp;str, y: \u0026amp;str) -\u0026gt; \u0026amp;str 应用规则 1：\n1 fn longest\u0026lt;\u0026#39;a, \u0026#39;b\u0026gt;(x: \u0026amp;\u0026#39;a str, y: \u0026amp;\u0026#39;b str) -\u0026gt; \u0026amp;str 显然有多个输入生命周期参数，那么规则2不能用，也没有 self，所以规则3也不行。\n此时编译器并不能计算出所有引用的生命周期参数，故报错。\n方法定义中的生命周期标注 在结构体上使用生命周期实现方法，语法和泛型一样。在哪声明和使用生命周期参数，取决于其是否和字段、方法的参数或者返回值有关。\nstruct 字段的生命周期名：在 impl 后声明，在 struct 后使用，生命周期也是结构体类型的一部分\nimpl 块中的方法签名中：引用必须绑定与 struct 字段引用的生命周期，或者引用是独立的。此外经常可以省略。\n静态生命周期 'static 是特殊的生命周期：持续整个程序\n默认所有字符串字面量都是静态生命周期。\n1 let s: \u0026amp;\u0026#39;static str = \u0026#34;I have a static lifetime.\u0026#34;; ","date":"2024-03-21T00:00:00Z","permalink":"https://rossqaq.github.io/article/rust-lifetime/","title":"Rust 的生命周期"},{"content":"终于让我发现了 io_uring 与协程结合的教程，后面还包括与多线程结合。让我来验证一下我的猜想究竟对不对…\n本文是系列文章：\nC++20 Coroutines and io_uring - Part 1/3\nC++20 Coroutines and io_uring - Part 2/3\nC++20 Coroutines and io_uring - Part 3/3\n的翻译与总结。文章间会使用分割线分开。\n关于作者\nI’m Pablo, a software engineer living in Munich. Please write me an email if you have feedback or have discovered an error in a post.\nPart 1/3 P1 前言 在这个系列中，我们会写使用 io_uring 和 C++20 协程的读取很多硬盘上的文件的程序。主要的目的是因为，我发现有很多关于 io_uring 和 C++20 协程的单独资料，也有讲的比较深入的，但是基本没有展示如何结合二者的。我们会揭开异步 IO 和 协程结合的谜底，就像黄油和面包一样。\n这个系列会分成三部分，P1 我们首先仅用 io_uring 来解决问题。P2 我们会重构实现，并且加入协程。P3 我们会使用多线程优化，这才能展现出协程的真正力量。\nAsync I/O ❤ Coroutines 异步 IO，跟同步 IO 相反，描述一种不阻塞当前 calling 线程的 IO 操作。跟等待操作完成不同，当前线程会立刻 release，然后执行其他操作，而此时后台正在执行你请求的 IO 操作。待一段时间后，calling 线程（或者其他的线程）可以回来并且收集请求操作的结果。这就好像你对一个 pizza guy 说：“将 margherita 放到烤箱，我去药房取药，一会回来。”\n异步 IO 可以比同步 IO 更有效率，线程不需要等待资源可用，但同时程序也会变得更加复杂。程序需要异步工作，必须记得回来取走他们点的 margherita。\n协程允许我们以同步的形式编写异步代码，如果你使用协程来从硬盘读取一个文件，它可以挂起自己然后将控制流返回给 caller，此时文件正在后台读取，等数据读取完后恢复协程，然后获取数据。所有的代码写起来就和 good-old 同步调用类似。\n结合异步 IO 和协程，允许我们编写异步程序，但并不用写繁琐的异步代码。取了二者的长处。\n目标 这个系列中，我们会写一个程序，从硬盘中读取并且 parse 几百个 wavefront OBJ 文件。\n了解读取和 parsing 的区别很重要。读取代表把文件从内存中装载到内存中。parsing 代表从内存中取数据，然后把它翻译为应用程序可以理解的结构。\nOBJ 文件使用 ASCII 编码，描述的是 3D 三角形组成的网格图形。该文件对构成三角形的网络、顶点、颜色等信息编码。parsing 一个 OBJ 意味着将 ASCII 表现形式转换为有更方便访问网格属性 API 的 C++ 对象形式。\n玩过 3dmax 这种建模软件的应该都知道 .obj 吧。不是你程序编译中间生成的目标文件。是记录 3d 图形的。\n为了 parsing obj 文件，我们使用一个三方库 tinyobjloader。它接受一个 string，然后把它 parse 成 ObjReader 对象。\n1 2 3 std::string obj_data = ...;\t// read from obj files tinyobj::ObjReader reader; reader.ParseFromString(obj_data); 我们可以使用 reader API 来访问图形的属性，例如，列出有多少个多边形：\n1 std::cout \u0026lt;\u0026lt; reader.GetShapes().size() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; 地基 首先定义一些抽象，来让我们的实现更简单。\n我们要读取文件，所以写一些 RAII 类来管理只读文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 class ReadOnlyFile { public: ReadOnlyFile(const std::string \u0026amp;file_path) : path_{file_path} { fd_ = open(file_path.c_str(), O_RDONLY); if (fd_ \u0026lt; 0) { throw std::runtime_error(\u0026#34;Fail to open file\u0026#34;); } size_ = get_file_size(fd_); if (size_ \u0026lt; 0) { throw std::runtime_error(\u0026#34;Fail to get size of file\u0026#34;); } } ReadOnlyFile(ReadOnlyFile \u0026amp;\u0026amp;other) : path_{std::exchange(other.path_, {})}, fd_{std::exchange(other.fd_, -1)}, size_{other.size()} {} ~ReadOnlyFile() { if (fd_) { close(fd_); } } int fd() const { return fd_; } off_t size() const { return get_file_size(fd_); } const std::string \u0026amp;path() const { return path_; } private: std::string path_; int fd_; off_t size_; }; 非常简单，只读模式打开文件并且析构时关闭文件。实现了一些比较笨的错误处理，以及一个移动构造，这样该类型就可以存在于 std::vector 之类的容器了。\n这里作者似乎也忘了 noexcept 了。\n另一个类型是 Result ，我们会经常使用：\n1 2 3 4 5 struct Result { tinyobj::ObjReader result; // 存储解析后的对象 int status_code{0}; // 读操作的状态 std::string file; // OBJ 的路径 }; 我们的程序最终要分析一系列的 OBJ 文件，然后返回 std::vector\u0026lt;Result\u0026gt;\n初次尝试：平凡的实现 该到正餐部分了。像往常一样，我们来实现一个最简单的版本：单线程阻塞读取\n1 2 3 4 5 6 7 Result readSynchronous(const ReadOnlyFile \u0026amp;file) { Result result{.file = file.path()}; std::vector\u0026lt;char\u0026gt; buff(file.size()); read(file.fd(), buff.data(), buff.size()); // 完成前会阻塞 readObjFromBuffer(buff, result.result); return result; } readSynchronous 接收文件，把它的内容读取到 buffer 中，之后将 buffer 中的内容解析为 obj 对象。readObjFromBuffer 包装了一个简单的实现，并且初始化 Result 的 result 成员：\n1 2 3 4 void readObjFromBuffer(const std::vector\u0026lt;char\u0026gt; \u0026amp;buff, tinyobj::ObjReader \u0026amp;reader) { auto s = std::string(buff.data(), buff.size()); reader.ParseFromString(s, std::string{}); } 可惜，tinyobjloader 不支持 std::string_view，所以我们只能拷贝一次 buffer 了。可能之后我会提 PR。\n现在我们需要做的是对每个文件调用 readSynchronous：\n1 2 3 4 5 6 7 8 std::vector\u0026lt;Result\u0026gt; trivialApproach(const std::vector\u0026lt;ReadOnlyFile\u0026gt; \u0026amp;files) { std::vector\u0026lt;Result\u0026gt; results; results.reserve(files.size()); for (const auto \u0026amp;file : files) { results.push_back(readSynchronous(file)); } return results; } 太简单了，但是非常慢慢慢慢。read 系统调用会阻塞 calling 线程，直到读取完所有的数据。我意思是 thread，只有一个线程做 IO 然后解析所有文件。我们不能在下一个文件读取完毕之前做上一个读取好的文件的解析！\n用户态和内核态的上下文切换也很费时间，每次调用 read 都要切换到内核态。如果我们读取几百个文件，就得切换几百次。\n我们可以做的更好一些。\n下一步：线程池 我知道你想说什么，并行！\n1 2 3 4 5 6 7 8 9 10 11 12 std::vector\u0026lt;Result\u0026gt; threadPool(const std::vector\u0026lt;ReadOnlyFile\u0026gt; \u0026amp;files) { std::vector\u0026lt;Result\u0026gt; result(files.size()); BS::thread_pool pool; pool.parallelize_loop(files.size(), [\u0026amp;files, \u0026amp;result](int a, int b) { for (int i = a; i \u0026lt; b; ++i) { result[i] = readSynchronous(files[i]); } }) .wait(); return result; } 这里使用了 bshoshany’s thread-pool library 来并行执行独立的循环。每个线程都执行固定次数的迭代，记为范围 [a, b)。你也可以用 openMP 之类的库，或者 std::async，思想都一样。\n补充：对于不了解这个库的人，这个函数大概就是给 size 分块，线程池里的线程执行固定数量的 IO。\n这就好多了，即使线程仍然会在 read 上阻塞，但这次文件会并行处理。代码的更改也很少，然后他还有了更多的优化机会：我们可以给每个线程分配一个 buffer，然后可以被多个文件复用。\n对于大多数程序来说这个已经很效率了，但是想象如果你是 web server 的开发者，一次监听上千个 socket。你会给每个 socket 创建一个线程吗？估计不会。你要做的是告诉操作系统：“听好，我对这些 sockets 感兴趣，当他们有可以被读取的数据时告诉我，我会继续我的工作。” 你需要的是异步 IO。\n使用 io_uring linux kernel 5.1 后推出了新的异步 IO API，io_uring。以前通常会使用 epoll, poll, select, aio 等等，它们各有各的限制和问题。io_uring 的目标是使用标准 API 给内核中的所有异步 IO 操作打开一个新的篇章。\nAPI 叫做 io_uring 因为它基于两个 buffer：submission queue（SQ） 以及 completion queue（CQ）。buffer 在内核和用户之间共享，从它们中读取/写入数据不需要任何 syscall 或者拷贝。\n中心思想很简单：用户代码编写提交给 SQ 的请求，之后把它们提交给内核。内核消耗队列中的请求，执行请求的操作，然后将结果写入 CQ。用户代码可以异步地在之后的某个时间点获取 CQ 中完成后的请求。\nio_uring 原生 API 非常复杂，所以应用程序通常会使用库 liburing（io_uring 的作者帮你封装的），它提取了很多重复的操作，为 io_uring 的使用提供了方便的工具。\n使用 liburing 解析 OBJs 我们现在使用 liburing 来完成实现\n首先先封装一个 RAII 类，初始化 io_uring 对象并且释放：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class IOUring { public: explicit IOUring(size_t queue_size) { if (auto s = io_uring_queue_init(queue_size, \u0026amp;ring_, 0); s \u0026lt; 0) { throw std::runtime_error(\u0026#34;error initializing io_uring: \u0026#34; + std::to_string(s)); } } IOUring(const IOUring \u0026amp;) = delete; IOUring \u0026amp;operator=(const IOUring \u0026amp;) = delete; IOUring(IOUring \u0026amp;\u0026amp;) = delete; IOUring \u0026amp;operator=(IOUring \u0026amp;\u0026amp;) = delete; ~IOUring() { io_uring_queue_exit(\u0026amp;ring_); } struct io_uring* get() { return \u0026amp;ring_; } private: struct io_uring ring_; }; io_uring_queue_init() 初始化 io_uring 实例，使用 queue_size 的长度（这是 SQ 和 CQ 的环形缓冲区长度）。io_uring_queue_exit() 销毁 io_uring 实例。\n这里作者应该说错了，CQ 长度默认是 SQ 的二倍。想要具体指定你可以使用 io_uring_params 传给 io_uring_init_params() 来初始化 io_uring\n现在我们尝试使用 liburing 来实现 OBJ Loader\n实现必须包含两个部分：首先我们提交读请求给 SQ，之后我们等待完成请求进入到 CQ 中再解析 buffer 中的内容。\n1 2 3 4 5 6 std::vector\u0026lt;Result\u0026gt; iouringOBJLoader(const std::vector\u0026lt;ReadOnlyFile\u0026gt;\u0026amp; files) { IOUring ring{files.size()}; auto buf = initializeBuffers(files); pushEntriesToSubmissionQueue(files, buf, uring); return readEntriesFromCompletionQueue(files, buf, uring); } 我们创建足够大的 io_uring 实例来容纳下所有的文件的请求。之后分配 buffer，每个文件一个。\npushEntriesToSubmissionQueue() 内编写 submission entries 提交给 SQ：\n1 2 3 4 5 6 7 8 9 void pushEntriesToSubmissionQueue(const std::vector\u0026lt;ReadOnlyFile\u0026gt; \u0026amp;files, const std::vector\u0026lt;std::vector\u0026lt;char\u0026gt;\u0026gt; \u0026amp;buffs, IOUring \u0026amp;uring) { for (size_t i = 0; i \u0026lt; files.size(); ++i) { struct io_uring_sqe *sqe = io_uring_get_sqe(uring.get()); io_uring_prep_read(sqe, files[i].fd(), buffs[i].data(), buffs[i].size(), 0); io_uring_sqe_set_data64(sqe, i); } } io_uring_get_sqe() 创建一个 SQ 的 entry，sqe。我们现在可以使用 io_uring_prep_read() 来设置 entry 的内容，指定内核读取 files[i].fd() 的文件给 buffer buffs[i]。\n可以通过使用 io_uring_sqe_set_data() 来给 entry 追加用户数据。kernel 不会使用这个部分的数据，只是单纯的拷贝给当前提交请求对应的 completion entry。这个很重要，可以让我们区分哪个 completion entry 对应的是哪个 submission entry。在这个情况下，我们只是单纯写文件的 index，也可以用来区分。\n在外面把所有的 SQ 都写入队列后，需要将他们提交给内核，并且等待他们出现在 CQ 中。一旦出现了 completion entry，我们就读取对应 OBJ 文件的 buffer。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 std::vector\u0026lt;Result\u0026gt; readEntriesFromCompletionQueue(const std::vector\u0026lt;ReadOnlyFile\u0026gt; \u0026amp;files, const std::vector\u0026lt;std::vector\u0026lt;char\u0026gt;\u0026gt; \u0026amp;buffs, IOUring \u0026amp;uring) { std::vector\u0026lt;Result\u0026gt; results; results.reserve(files.size()); while (results.size() \u0026lt; files.size()) { io_uring_submit_and_wait(uring.get(), 1); io_uring_cqe *cqe; unsigned head; int processed{0}; io_uring_for_each_cqe(uring.get(), head, cqe) { auto id = io_uring_cqe_get_data64(cqe); results.push_back({.status_code = cqe-\u0026gt;res, .file = files[id].path()}); if (results.back().status_code) { readObjFromBuffer(buffs[id], results.back().result); } ++processed; } io_uring_cq_advance(uring.get(), processed); } return results; } 首先我们调用 io_uring_submit_and_wait()，来提交所有的 entry 给内核，并且阻塞，直到等待第一个 completion entry 出现。\n我们获得 completion entry 后就可以处理他们了。io_uring_for_each_cqe() 是一个定义在 liburing 内的宏，其意义是对 CQ 中的所有 completion entry 执行操作。\n以下是我们需要在 completion entry 到达时执行的操作：\n获取 completion entry 对应的文件的 id。这和我们写给 submission entry 的 id 是同一个。 将 status code 写入 Result 对象，当前状态是内核执行的 read 操作。 如果读取成功，从 buffer 中解析 OBJ 文件，放入 Result 对象。 最后，我们可以释放一些空间，因为我们已经完成了一些 completion entry 的处理。我们使用 io_uring_cq_advance() ，这个函数唯一做的事情就是把 ring buffer 的头向后移动 n 个位置，使得有足够的空间来存放 entries。\np1 结束语 使用 io_uring 最大的优点就是实现的代码可以减少很多 syscall。实际上，使用 strace 可以看到 io_uring 的实现比同步代码的实现少了 512 次 syscall。这主要是因为 read 的 syscall 的减少：\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026gt; strace -c -e read -- ./build_release/couring --trivial Running trivial Processed 512 files. % time seconds usecs/call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 100.00 0.000591 1 517 read \u0026gt; strace -c -e read -- ./build_release/couring --iouring Running iouring Processed 512 files. % time seconds usecs/call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 100.00 0.000053 10 5 read 不同于对每个文件都调用 read，io_uring 的做法不会有 syscall，因为向 io_uring 的队列读写并不是 syscall，也不会有上下文切换。\n我们的 io_uring 实现仍然有问题。首先，代码比同步版本明显复杂很多，我们并不能在一个函数内完成读取和解析，而是在一个程序内将请求写入队列然后轮询。这很难扩展。\n其次，我们的程序是 CPU-bound，如下所示 (gprof)，大部分时间在解析 obj：\n1 2 3 4 5 6 7 8 % cumulative self time seconds seconds 31.25 0.05 0.05 tinyobj::tryParseDouble(char const*, char const*, double*) 18.75 0.08 0.03 tinyobj::LoadObj(tinyobj::attrib_t*, std::vector\u0026lt;tinyobj::shape_t, std::allocator\u0026lt;tinyobj::shape_t\u0026gt; \u0026gt;*, std::vector\u0026lt;tinyobj::material_t, std::allocator\u0026lt;tinyobj::material_t\u0026gt; \u0026gt;*, std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;*, std::__cxx11::basic_string\u0026lt;char, std::char_traits\u0026lt;char\u0026gt;, std::allocator\u0026lt;char\u0026gt; \u0026gt;*, std::istream*, tinyobj::MaterialReader*, bool, bool) 12.50 0.10 0.02 allDone(std::vector\u0026lt;Task, std::allocator\u0026lt;Task\u0026gt; \u0026gt; const\u0026amp;) 12.50 0.12 0.02 tinyobj::parseReal(char const**, double) 6.25 0.13 0.01 tinyobj::parseReal3(float*, float*, float*, char const**, double, double, double) ... 解析 obj 仍然单线程。处理 SQE 是内核的线程池完成，而消费 CQE 则是用户空间的单线程完成。显然我们必须并行解析。\nPart 2/3 P2 前言 这一部分我们会使用 C++20 的协程来重写第一部分的程序，读取 OBJ 之后解析。本文的目标是结合 io_uring 与协程，不懂 C++ 协程的可以自己看 Lewis Baker’s blog series。\n本博客内还有其他优秀文章的翻译。Lewiss Baker 的也很不错。\n中心思想 我们要做的很简单：实现一个协程，读取并且解析硬盘中的 OBJ 文件，底层 IO 使用 io_uring。当协程被调用时，它把请求提交给 SQ，然后暂停执行，返回控制权给 caller。一旦相应的 completion entry 完成，那么协程就恢复，OBJ 可以被解析了。\nwoc，我感觉我是天才，自己悟出来的和文章里想的是一样的。之前悟了几个月。\n1 2 3 4 5 6 7 8 9 Task parseOBJFile(IOUring\u0026amp; uring, const ReadOnlyFile\u0026amp; file) { std::vector\u0026lt;char\u0026gt; buff(file.size()); auto status = co_await ReadFileAwaitable{uring, file, buff}; // 此时 completion entry 已经准备好, // buff 内也填充了数据，可以解析了 Result result{ .status_code = 0, .file = file.path() }; readObjFromBuffer(buff, result.result); co_return result; } 这是我们的协程。看起来和普通函数很像，实际上，他确实就是按照传统的同步代码模式编写：分配缓冲，读取内容，解析 buffer，返回结果。\n协程天然就不是同步执行的：它在特定位置暂停执行并且让出控制权给 caller。例如，await 表达式：co_await ReadFileAwaitable{uring, file, buff}。这里，我们提交 SQE，并且将控制流返回给 caller。co_await 是一个运算符，需要一个 awaitable 类型，然后暂停执行。ReadFileAwaitable 就是那么一个 awaitable，它的任务是暂停写成然后注册它，准备以后唤醒。一旦协程恢复了执行，那么就从 co_await 的下一行开始执行。\n暂停执行 ReadFileAwaitable 是一个用来暂停协程的 awaitable。我们会解释发生了什么：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class ReadFileAwaitable { public: ReadFileAwaitable(IOUring\u0026amp; ring, cont ReadOnlyFile\u0026amp; file, const std::vector\u0026lt;char\u0026gt;\u0026amp; buf) { sqe_ = io_uring_get_sqe(uring.get()); io_uring_prep_read(sqe_, file.fd(), buf.data(), buf.size(), 0); } auto operator co_await() { struct Awaiter { io_uring_sqe* entry; RequestData requestData; Awaitable(io_uring_sqe* sqe) : entry{sqe} {} bool await_ready() {return false;} void await_suspend(std::coroutine_handle\u0026lt;\u0026gt; h) noexcept { requestData.handle = h; io_uring_sqe_set_data(entry, \u0026amp;requestData); } int await_resume() {return requestData.statusCode;} }; return Awaiter{sqe_}; } private: io_uring_sqe* sqe_; }; ReadFileAwaitable 创建一个 SQE 然后把它提交。我们必须在协程暂停之前提交我们的请求。\n我从来没重载过 operator co_await() 只在文档里看过，感觉还是写 await_transform() 好点。\nAwaiter 有两个成员变量：entry and requestData，entry 是一个指针，指向 SQE，我们需要他来被传递给 io_uring_sqe_set_data() 以此绑定用户数据。用户数据是任意的（void*）所以我们可以绑定我们的提交请求。用户数据会原样传递给内核，并由内核传递给 CQE，主要用来分辨不同的 CQE，将其链接到正确的 SQE。\nReadFileAwaitable 重载 operator co_await() 返回一个 awaiter：Awaiter. Awaiter 实现了标准要求的三个函数：await_ready(), await_suspend(), await_resume()。\nawait_ready() 一直返回 false。代表我们的协程永远会在 co_await ReadFileAwaitable{} 处暂停。我们也可以继承自 std::suspend_always\n现在我们实现 await_suspend()，这个函数会在协程暂停后调用，并且参数是协程句柄。这是一个很好的函数，我们可以用它将用户数据写入 SQE。但用户数据应该写啥呢？\n我们仔细想想：我们提交 SQE。会有一个对应的 CQE 在完成时进入 CQ。一旦 CQE 到达，那么我们就必须恢复我们暂停的协程。我们怎么恢复协程呢？协程句柄已经传递给我们了！我们把写成句柄写入用户数据作为提交请求！\n我真是天才，几天前就自己悟了。\n协程句柄作为成员变量，存储在 RequestData:\n1 2 3 4 struct RequestData { std::coroutine_handle\u0026lt;\u0026gt; handle; int statusCode{-1}; }; RequestData 存储协程句柄和状态码。状态码之后会被写入 Awaiter 对象，当完成请求到达时，用户数据则是指向 awaiter 对象的 requestData 数据成员的指针。\n最终，我们实现 await_resume() 。await_resume() 会在协程恢复时立刻调用，并且返回写操作的状态码。换句话说，我们可以假设 requestData.statuCode 在 await_resume() 调用时初始化。\nawait_resume() 的返回值就是整个 co_await 表达式的结果，我们可以写：\n1 2 3 4 int status = co_await ReadFileAwaitable{}; if (!status) { //... } 就像我们调用了一个普通的 read。\n恢复执行 调用 co_await ReadFileAwaitable 会让协程挂起，但我们怎么唤醒它呢？简单，我们等待 CQE，然后从中取出协程句柄即可。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 int consumeCQEntries(IOUring \u0026amp;uring) { int processed{0}; io_uring_cqe *cqe; unsigned head; // 环形缓冲区头位置，未被使用 io_uring_for_each_cqe(uring.get(), head, cqe) { auto *request_data = static_cast\u0026lt;RequestData *\u0026gt;(io_uring_cqe_get_data(cqe)); // 记得在恢复协程前设定 statusCode request_data-\u0026gt;statusCode = cqe-\u0026gt;res; request_data-\u0026gt;handle.resume(); // 这里恢复协程然后自动调用 await_resume() ++processed; } io_uring_cq_advance(uring.get(), processed); return processed; } 在恢复协程前，我们必须在 request_data 中写入 status code。request_data 是一个指向 Awaiter 对象中 reqeustData 数据成员的指针。\n我们现在写一个 consumeCQEntriesBlocking() 帮助函数，会向内核提交 SQE，然后阻塞直到至少有一个 CQE 完成。\n1 2 3 4 int consumeCQEntriesBlocking(IOUring \u0026amp;uring) { io_uring_submit_and_wait(uring.get(), 1); // CQ 为空会阻塞 return consumeCQEntries(uring); } 我们已经学会了暂停和恢复协程的机制，现在我们可以写客户端代码，来读取 OBJ 文件了。\n直观上，我们必须使用入 std::vector 来包含 parseOBJFile 返回的结果，但是 parseOBJFile 的返回值是什么？协程的返回类型是什么？它是一个 coroutine type ，这里命名为 Task。\nCoroutine Type：Task Task 是我们协程的返回类型。我们必须自己实现它，实现标准规定的 API。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 class Task { public: struct promise_type { Result result; Task get_return_object() { return Task(this); } void unhandled_exception() noexcept {} void return_value(Result result) noexcept { result = std::move(result); } std::suspend_never initial_suspend() noexcept { return {}; } std::suspend_always final_suspend() noexcept { return {}; } }; explicit Task(promise_type *promise) : handle_{HandleT::from_promise(*promise)} {} Task(Task \u0026amp;\u0026amp;other) : handle_{std::exchange(other.handle_, nullptr)} {} ~Task() { if (handle_) { handle_.destroy(); } } Result getResult() const \u0026amp; { assert(handle_.done()); return handle_.promise().result; } Result\u0026amp;\u0026amp; getResult() \u0026amp;\u0026amp; { assert(handle_.done()); return std::move(handle_.promise().result); } bool done() const { return handle_.done(); } using HandleT = std::coroutine_handle\u0026lt;promise_type\u0026gt;; HandleT handle_; }; Task 定义了 promise type，每个协程都拥有 promise 对象，其位于协程帧中。promise 对象用于传输协程的数据（或者重新抛出协程抛出的异常）。此外，promise type 有一个成员 Result result，包括了最终的解析 OBJ 文件的结果。\n1 2 3 4 5 struct Result { tinyobj::ObjReader result; // stores the actual parsed obj int status_code{0}; // the status code of the read operation std::string file; // the file the OBJ was loaded from }; result 通过内部的成员函数 return_value 初始化，当 co_return 执行时会被调用。\nTask 定义了一个成员函数 getResult() 来方便的从 promise 对象中得到返回的结果。\npromise_type 必须定义成员函数 get_return_object() 返回实际的协程对象。在我们的示例中，是 Task 实例。\nunhandled_expection() 在协程体抛异常时会被调用，我们暂未实现因为我们是 exception free （或者目标是）。initial_suspend 和 final_suspend 决定了协程的初始和最终行为，协程是否在开始和结束时暂停。\nTask 包含了协程句柄 handle_ 并且管理其生命周期：它会通过析构时调用 handle_.destroy() 来销毁协程帧。同时还定义了 done() 成员函数表明协程是否执行完毕。\nC++20 协程是 raw，代表他并不是一个完整的 cake，而是一堆 flour，eggs 和 butter。为了实现一个协程你必须写一些支持代码以及模版，自己来烤蛋糕。因为这些原因，可以使用一些库，比如 cppcoro by Lewis Baker，实现了泛型版本的 Task 类型，使用了很多有用的抽象，大量减少了模板代码。\n结合 现在我们实现顶层函数，使用协程解析 OBJ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 std::vector\u0026lt;Result\u0026gt; parseOBJFiles(const std::vector\u0026lt;ReadOnlyFile\u0026gt; \u0026amp;files) { IOUring uring{files.size()}; std::vector\u0026lt;Task\u0026gt; tasks; tasks.reserve(files.size()); for (const auto \u0026amp;file : files) { tasks.push_back(parseOBJFile(uring, file)); } while (!allDone(tasks)) { // consume all entries in the submission queue // if the queue is empty block until the next completion arrives consumeCQEntriesBlocking(uring); } return gatherResults(tasks); } 通过执行 parseOBJFile 分配了一个 vector 的 Task 协程。注意 initial_suspend() 返回的是 std::suspend_never ，代表 parseOJBFile 协程在协程开始时永远不会暂停，直到执行到了 co_await ReadFileAwaitable，协程才会暂停。\n一旦协程暂停，内核就会做它的工作，我们什么都不用做，只需要等到 CQE 完成，consumeCQEntriesBlocking 会唤醒协程，因为它们对应的 CQE 已经完成了。\nallDone 是一个简单的帮助函数，检查是否所有的协程都已经执行完毕。\n1 2 3 4 bool allDone(const std::vector\u0026lt;Task\u0026gt; \u0026amp;tasks) { return std::all_of(tasks.cbegin(), tasks.cend(), [](const auto \u0026amp;t) { return t.done(); }); } 然后协程恢复，解析 OBJ 文件，并且通过 co_return result 返回结果。\n最后我们可以从完成的协程中获取最终的结果：\n1 2 3 4 5 6 7 8 std::vector\u0026lt;Result\u0026gt; gatherResults(const std::vector\u0026lt;Task\u0026gt; \u0026amp;tasks) { std::vector\u0026lt;Result\u0026gt; results; results.reserve(tasks.size()); for (auto \u0026amp;\u0026amp;t : tasks) { results.push_back(std::move(t).getResult()); } return results; } 在函数块最后，所有的 Task 都会销毁，解分配所有的协程帧。\np2 结束语 你可能有问题：这篇文章的实现和不使用协程实现关键区别在哪？这是一个争议性的问题，有的人可能觉得我们只是像程序中加入了一些模板式的代码来实现已经实现过的功能。也没有更加效率：我们仍然是单线程串行解析。\n好在我们还没有完成所有的操作。协程的魅力之处在于其可以组合其他功能，在实现了一个基础的协程设施后，添加更多的 awaitable 和 其他协程很简单。\n在 P3 我们会扩展实现，例如使用线程池并行解析文件。这才是协程最终的魔力。\nPart 3/3 P3 前言 已经到了系列的最后一篇文章。在 P2 我们写了基于协程的程序，读取并且解析 OBJ 文件，使用协程和 io_uring。程序仍然有最后一个缺点：他是 CPU-bound。解析文件，最耗费时间的部分是算法，是在单线程上串行执行的。\n问题的根源是我们的协程在 main 线程上恢复。理想中我们希望他在其他线程上恢复，这样才可以并行解析文件。\n这正是我们这篇文章要做的。我们添加第二个 await 表达式 co_await pool.schedule()，这会让我们的协程暂停并且被线程池调度和恢复。\n1 2 3 4 5 6 7 8 9 Task parseOBJFile(IOUring \u0026amp;uring, const ReadOnlyFile \u0026amp;file, ThreadPool \u0026amp;pool) { std::vector\u0026lt;char\u0026gt; buff(file.size()); int status = co_await ReadFileAwaitable(uring, file, buff); co_await pool.schedule(); // This is now running on a worker thread Result result{.status_code = 0, .file = file.path()}; readObjFromBuffer(buff, result.result); co_return result; } 线程池 ThreadPool 实现了我们的核心思想。\nThreadPool 封装了 bshoshany Thread Pool’s object ，它的 API 很简单，你可以使用 push_task 来调度一个在线程池上跑的任务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class ThreadPool { public: auto schedule() { struct Awaiter : std::suspend_always { BS::thread_pool \u0026amp;tpool; Awaitable(BS::thread_pool \u0026amp;pool) : tpool{pool} {} void await_suspend(std::coroutine_handle\u0026lt;\u0026gt; handle) { tpool.push_task([handle, this]() { handle.resume(); }); } }; return Awaiter{pool_}; } size_t numUnfinishedTasks() const { return pool_.get_tasks_total(); } private: BS::thread_pool pool_; }; ThreadPool 定义了成员函数 schedule() ，返回一个 Awaiter 的实例。当协程 co_await Awaiter 对象时，协程会暂停（注意 Awaiter 继承自 std::suspend_always）并且在 await_suspend() 中调度在 worker 线程上恢复。\n很棒！通过简单的写 co_await pool.schedule() 我们就可以在线程池中唤醒当前协程，大大提高了我们的执行效率。并行解析 OBJ。\n多线程实现 以上。现在我们来实现顶层的函数，使用新的协程来加载和解析 OBJ 文件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 std::vector\u0026lt;Result\u0026gt; coroutinesThreadPool(const std::vector\u0026lt;ReadOnlyFile\u0026gt; \u0026amp;files) { IOUring uring{files.size()}; ThreadPool pool; std::vector\u0026lt;Task\u0026gt; tasks; tasks.reserve(files.size()); for (const auto \u0026amp;file : files) { tasks.push_back(parseOBJFile(uring, file, pool)); } io_uring_submit(uring.get()); while (pool.numUnfinishedTasks() \u0026gt; 0 || !allDone(tasks)) { // consume entries in the completion queue // return immediately if the queue is empty consumeCQEntriesNonBlocking(uring); } return gatherResults(tasks); } 我们初始化一个线程池和 io_uring 实例，然后对每个文件调用 parseOBJFile ，这会填满 SQ，之后我们使用 io_uring_sumbit() 向内核提交请求。\n一旦内核在后台读取文件，协程会在相应的 CQE 到达时被唤醒。这在函数 consumeCQEntriesNonBlocking() 中执行：\n1 2 3 4 5 6 7 int consumeCQEntriesNonBlocking(IOUring \u0026amp;uring) { io_uring_cqe *temp; if (io_uring_peek_cqe(uring.get(), \u0026amp;temp) == 0) { return consumeCQEntries(uring); } return 0; } 使用 io_uring_peek_cqe() 来查看 CQ 中是否已经有 CQE，如果为空的话则会退出。\n我们继续等待所有协程完成。因为 allDone 是线性检查，所以我们给一个短路的选项避免一直调用它、如果在线程池中有未完成的任务，那么显然我们还没有完成。\nP3 结束语 大功告成！希望你能感受到协程的 cool 了，一旦你已经有了一个协程，那么添加其他的 co_awaits 易如反掌。\n你可以在 这里 找到所有的代码。\n","date":"2024-03-09T00:00:00Z","permalink":"https://rossqaq.github.io/article/io_uring-coro/","title":"io_uring + coroutine"},{"content":"本文介绍 模版方法 模式，参考了 https://www.bilibili.com/video/BV1Yr4y157Ci\n目的 在软件构建过程中，对于某个任务，它可能拥有稳定的整体操作结构，但各个子步骤却有很多改变的需求。\n假设我们有一个库，以及一个应用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Library { public: void Step1() {} void Step3() {} void Step5() {} }; class Application { public: void Step2() {} void Step4() {} }; 这种情况下，通常 Library 的使用步骤是固定的，而要构建程序又需要 App 的步骤。如果什么都不做，每次就要都写一遍固定的 Library 步骤。而框架开发人员完全可以把开发步骤写下来。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 class Library { public: void Run() { Step1(); if(Step2()) {\t// 支持多态 -\u0026gt; 虚函数调用 Step3();\t} for (int i = 0; i \u0026lt; 4; ++i) { Step4();\t// 支持多态 -\u0026gt; 虚函数调用\t} Step5(); } virtual ~Library() {} private: void Step1() {}\t// 稳定 void Step3() {} // 稳定 void Step5() {} // 稳定 protected: virtual bool Step2() = 0; virtual bool Step4() = 0; }; class Application : public Library { public: virtual void Step2() {} virtual void Step4() {} }; int main() { Library* lib = new Application(); lib-\u0026gt;Run(); delete lib; } 这一次就可以利用多态，直接调用了。\n软件设计流程 第一种方式 Library 开发人员：\n步骤 1, 3, 5 的开发 Application 开发人员：\n步骤 2， 4 开发 程序主流程 调用关系：Application 调用 Library\n第二种方式 Library 开发人员：\n步骤 1， 3， 5的开发 程序主流程 Application 开发人员：\n步骤2， 4开发 调用关系：利用虚函数，Library 调用 Application\n对比 也就是说，第一种方法是早绑定，app 晚，lib 早，app 调用 lib。\n在面向对象语言中，有一种机制叫做晚绑定，lib 早，app 晚，但是 lib 反过来调用 app。这样叫做晚绑定。\n模板方法定义 定义一个操作中的算法的骨架（稳定），而将一些步骤**延迟（变化，也就是指定义虚函数，让子类重写虚函数）**到子类。\ntemplate method 设计模式可以使子类可以不改变（复用）一个算法的结构，即可重定义（override）该算法的某些步骤。\n模板方法最重要的点在于，必须有一个稳定的骨架。设计模式的最大意义就是在变化和稳定间寻找隔离点，将其分离，便于管理变化。\n总结 模板方法是一个非常常用、基本的模式。为很多框架提供了灵活的扩展点（继承+虚函数）。\n机制非常简洁。\n","date":"2024-03-01T00:00:00Z","permalink":"https://rossqaq.github.io/article/design_pattern_template_method/","title":"模板方法模式"},{"content":"本文介绍 桥 模式，参考了 https://www.bilibili.com/video/BV1Yr4y157Ci\n目的 由于某些类型的固有实现逻辑，使得它们具有多个变化的纬度。\n示例 1 2 3 4 5 6 7 8 9 10 11 12 class Messager { public: virtual void Login(string username, string password) = 0; virtual void SendMessage(string message) = 0; virtual void SendPicture(Image image) = 0; virtual void PlaySound() = 0; virtual void DrawShape() = 0; virtual void WriteText() = 0; virtual void Connect() = 0; virtual ~Messager() {} }; 那么我们可能会需要考虑很多平台的实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class PCMessagerBase : public Messager { public: virtual void PlaySound() {} virtual void DrawShape() {} virtual void WriteText() {} virtual void Connect() {} }; class MobileMessagerBase : public Messager { public: virtual void PlaySound() {} virtual void DrawShape() {} virtual void WriteText() {} virtual void Connect() {} }; 我们可能要推出精简版，或者完美版\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class PCMessagerLite : public PCMessagerBase { public: virtual void Login(string username, string password) { PCMessagerBase::Connect(); // ... } virtual void SendMessage(string message) { PCMessagerBase::WriteText(); // ... } virtual void SendPicture(Image image) { PCMessagerBase::DrawShape(); // ... } }; class PCMessagerPerfect : public PCMessagerBase { public: virtual void Login(string username, string password) { PCMessagerBase::PlaySound(); PCMessagerBase::Connect(); // ... } virtual void SendMessage(string message) { PCMessagerBase::PlaySound(); PCMessagerBase::WriteText(); // ... } virtual void SendPicture(Image image) { PCMessagerBase::PlaySound(); PCMessagerBase::DrawShape(); // ... } }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class MobileMessagerLite : public PCMessagerBase { public: virtual void Login(string username, string password) { MobileMessagerBase::Connect(); // ... } virtual void SendMessage(string message) { MobileMessagerBase::WriteText(); // ... } virtual void SendPicture(Image image) { MobileMessagerBase::DrawShape(); // ... } }; class MobileMessagerPerfect : public PCMessagerBase { public: virtual void Login(string username, string password) { MobileMessagerBase::PlaySound(); MobileMessagerBase::Connect(); // ... } virtual void SendMessage(string message) { MobileMessagerBase::PlaySound(); MobileMessagerBase::WriteText(); // ... } virtual void SendPicture(Image image) { MobileMessagerBase::PlaySound(); MobileMessagerBase::DrawShape(); // ... } }; 那么我使用时就需要\n1 2 3 void Process() { Messager *m = new MobileMessagerPerfect(); } 如果我们的抽象多了，那么类的数目又会增加很快。何况这些类里面重复的东西又很多。\n如果我们使用装饰器模式中的继承转为组合，会好吗？可以。\n我们可以合并 MessagerLite 类 和 MessagerPerfect 类，但会出现问题，因为两个 fooBase 的基类有问题，它是一个抽象类，因为没有全部实现基类接口，所以问题出现在 Messager 类上。参考如下代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 class Messager { public: virtual void Login(string username, string password) = 0; virtual void SendMessage(string message) = 0; virtual void SendPicture(Image image) = 0; virtual void PlaySound() = 0; virtual void DrawShape() = 0; virtual void WriteText() = 0; virtual void Connect() = 0; virtual ~Messager() {} }; class PCMessagerBase : public Messager { public: virtual void PlaySound() {} virtual void DrawShape() {} virtual void WriteText() {} virtual void Connect() {} }; class MobileMessagerBase : public Messager { public: virtual void PlaySound() {} virtual void DrawShape() {} virtual void WriteText() {} virtual void Connect() {} }; class MessagerLite { Messager* messager; public: virtual void Login(string username, string password) { messager-\u0026gt;Connect(); // ... } virtual void SendMessage(string message) { messager-\u0026gt;WriteText(); // ... } virtual void SendPicture(Image image) { messager-\u0026gt;DrawShape(); // ... } }; class MessagerPerfect { Messager* messager; // = new PCMessagerBase/MobileMessagerBase public: virtual void Login(string username, string password) { messager-\u0026gt;PlaySound(); messager-\u0026gt;Connect(); // ... } virtual void SendMessage(string message) { messager-\u0026gt;PlaySound(); messager-\u0026gt;WriteText(); // ... } virtual void SendPicture(Image image) { messager-\u0026gt;PlaySound(); messager-\u0026gt;DrawShape(); // ... } }; 我们可以把它拆开，然后再正确的继承\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 class Messager { public: virtual void Login(string username, string password) = 0; virtual void SendMessage(string message) = 0; virtual void SendPicture(Image image) = 0; virtual ~Messager() {} }; class MessagerImpl { public: virtual void PlaySound() = 0; virtual void DrawShape() = 0; virtual void WriteText() = 0; virtual void Connect() = 0; virtual ~MessagerImpl() {} }; class PCMessagerBase : public MessagerImpl { public: virtual void PlaySound() {} virtual void DrawShape() {} virtual void WriteText() {} virtual void Connect() {} }; class MobileMessagerBase : public MessagerImpl { public: virtual void PlaySound() {} virtual void DrawShape() {} virtual void WriteText() {} virtual void Connect() {} }; class MessagerLite : public Messager { MessagerImpl* messager; public: virtual void Login(string username, string password) { messagerImpl-\u0026gt;Connect(); // ... } virtual void SendMessage(string message) { messagerImpl-\u0026gt;WriteText(); // ... } virtual void SendPicture(Image image) { messagerImpl-\u0026gt;DrawShape(); // ... } }; class MessagerPerfect : public Messager { MessagerImpl* messagerImpl; // = new PCMessagerBase/MobileMessagerBase public: virtual void Login(string username, string password) { messagerImpl-\u0026gt;PlaySound(); messagerImpl-\u0026gt;Connect(); // ... } virtual void SendMessage(string message) { messagerImpl-\u0026gt;PlaySound(); messagerImpl-\u0026gt;WriteText(); // ... } virtual void SendPicture(Image image) { messagerImpl-\u0026gt;PlaySound(); messagerImpl-\u0026gt;DrawShape(); // ... } }; 之后可以再提一次：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 class Messager { protected: MessagerImpl* messagerImpl; public: virtual void Login(string username, string password) = 0; virtual void SendMessage(string message) = 0; virtual void SendPicture(Image image) = 0; virtual ~Messager() {} }; class MessagerImpl { public: virtual void PlaySound() = 0; virtual void DrawShape() = 0; virtual void WriteText() = 0; virtual void Connect() = 0; virtual ~MessagerImpl() {} }; class PCMessagerImpl : public MessagerImpl { public: virtual void PlaySound() {} virtual void DrawShape() {} virtual void WriteText() {} virtual void Connect() {} }; class MobileMessagerImpl : public MessagerImpl { public: virtual void PlaySound() {} virtual void DrawShape() {} virtual void WriteText() {} virtual void Connect() {} }; class MessagerLite : public Messager { public: virtual void Login(string username, string password) { messagerImpl-\u0026gt;Connect(); // ... } virtual void SendMessage(string message) { messagerImpl-\u0026gt;WriteText(); // ... } virtual void SendPicture(Image image) { messagerImpl-\u0026gt;DrawShape(); // ... } }; class MessagerPerfect : public Messager { public: virtual void Login(string username, string password) { messagerImpl-\u0026gt;PlaySound(); messagerImpl-\u0026gt;Connect(); // ... } virtual void SendMessage(string message) { messagerImpl-\u0026gt;PlaySound(); messagerImpl-\u0026gt;WriteText(); // ... } virtual void SendPicture(Image image) { messagerImpl-\u0026gt;PlaySound(); messagerImpl-\u0026gt;DrawShape(); // ... } }; 此外修改一下构造函数即可，委托给父类。\n1 2 MessagerImpl* imp = new PCMessagerImpl(); Messager* m = new MessagerLite(imp); 桥模式 将抽象部分（业务）与实现部分（平台实现）分离，使得它们可以独立变化。\n","date":"2024-03-01T00:00:00Z","permalink":"https://rossqaq.github.io/article/design_pattern_bridge/","title":"桥模式"},{"content":"本文介绍适配器模式，参考了 https://www.bilibili.com/video/BV1Yr4y157Ci\n适配器模式 类图 Target: 未来的接口（我们希望的接口） Adaptee：被适配者（老的接口） Adapter 继承自 Target（继承代表我遵循基类的接口规范），同时有一个组合 Adaptee（组合是支持实现的方式） Adapter 实现了 Adaptee to Target\n即：继承新接口，组合老接口。\n简单实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // 目标接口（新接口） class ITarget { public: virtual void process() = 0; }; // 遗留接口（老接口） class IAdaptee { public: virtual void foo(int data) = 0; virtual int bar() = 0; }; class OldClass : public IAdaptee { public: //.... 实现了 IAdaptee 方法的遗留类 void foo(int data) {} int bar() {} }; class Adapter : public ITarget { protected: IAdaptee* adaptee_; public: Adapter(IAdaptee* adaptee) : adaptee_(adaptee) {} virtual void process() { // 转换的过程，伪代码 // 实际可能非常复杂 int data = adaptee_-\u0026gt;bar(); adaptee_-\u0026gt;foo(data); } }; 1 2 3 4 5 6 7 8 9 #include \u0026#34;adapter.hpp\u0026#34; int main() { IAdaptee* adaptee = new OldClass(); ITarget* target = new Adapter(adaptee); target-\u0026gt;process(); } 举个例子，STL 中 dequeue 是 queue 和 stack 的适配器，把 dequeue 转换为了 stack 和 queue 要求的接口。\n强调的是一个接口转换，老接口转为目标接口。\n总结 希望复用一些现存的类，但是接口又与复用环境要求不一致的情况。我们举例的是对象适配器，组合了对象，更符合设计模式的宗旨。\n","date":"2024-03-01T00:00:00Z","permalink":"https://rossqaq.github.io/article/design_pattern_adapter/","title":"适配器模式"},{"content":"本文介绍 装饰器模式 模式，参考了 https://www.bilibili.com/video/BV1Yr4y157Ci\n实例 某些情况下可能会过度使用集成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class Stream { public: virtual char Read(int number) = 0; virtual void Seek(int pos) = 0; virtual void Write(char data) = 0; }; class FileStream : public Stream {...}; class MemoryStream : public Stream {...}; class NetworkStream : public Stream {...}; // 此时我们想向流加密 class CryptoFileStream : public FileStream { public: virtual char Read(int number) { FileStream::Read(number); // 其他加密工作 } ... }; // 想引入缓冲 class BufferedFileStream : public FileStream { public: virtual char Read(int number) { FileStream::Read(number); // buffer } ... }; 难道给每个流都派生一个类吗？如果再做 buffer 呢？如果又加密又要缓冲呢？\n我们可以使用 组合 而不是 继承\n1 2 3 4 5 6 7 8 9 class CryptoFileStream { FileStream* stream; public: virtual char Read(int number) { stream-\u0026gt;Read(number); // 其他加密工作 } ... }; 而这时，又有圣旨，如果你的类中的成员都是一些子类，那么可以不用声明它为子类了，可以利用多态，在运行时支持。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 继承的作用是完成接口的规范 // 这里很奇妙，既有基类，又有字段 class CryptoStream : public Stream { Stream* stream;\t// new FileStream(); public: CryptoStream(Stream* strm) : stream(strm) {} virtual char Read(int number) { stream-\u0026gt;Read(number); // 其他加密工作 } ... }; class BufferedStream : public Stream { Stream* stream;\t// new FileStream(); public: BufferedStream(Stream* strm) : stream(strm) {} virtual char Read(int number) { stream-\u0026gt;Read(number); // 其他缓存工作 } ... }; // 此时发现 File、Network、Memory流代码都一样，也就是说可以直接省略。 // 未来也有各种各样的 Stream 可以支持变化。 也就是说，让代码在编译时尽量复用，然后在运行时支持其他的不同特性！\n使用方法如下：\n1 2 3 4 FileStream* fs = new FileStream(); CryptoStream* cs = new CryptoStream(fs); BufferedStream* bs = new BufferedStream(fs); BufferedStream* cbs = new BufferedStream(cs); 如果你追求完美的话，可以把类中的 Stream 字段提出来，显然不能提到基类里，因为 FileStream 当然不需要 Stream 这种字段，所以再封装一层中间类 DecoratorStream，CryptoStream和BufferedStream 继承，之后委托构造。\n装饰代表扩展，什么是扩展？在已有的 Stream 上进行其他操作，这也是 装饰器模式 的含义。\n关系变化 此时的类图由本来疯狂的继承产生的树状变成了：\n组合可以更好的完成我们的目的。\n装饰器模式 某些情况下，我们可能会过度使用继承来为类实现扩展功能，继承会引入静态的特性。\n动态（使用组合）地给一个对象增加一些额外的职责。就增加功能而言，Decorator 模式比生成子类（继承）更灵活。\n通过组合而非集成，装饰器模式实现了在 运行时 动态扩展对象功能的能力，而且可以根据需要继续扩展。避免了使用继承的灵活性差。\n装饰器模式在接口上表现为 is-a Component 的继承关系，即 Decorator 继承了 Component 类的接口。\n但在实现中装饰器模式又表现为 has-a Component 的组合关系，即 Decorator 又使用了另外一个 Component 类。\n非常精妙。\nDecorator 模式为了解决：主题类在多个方向上的扩展功能。\n","date":"2024-03-01T00:00:00Z","permalink":"https://rossqaq.github.io/article/design_pattern_decorator/","title":"装饰器模式"},{"content":"The Observer Design Pattern in Cpp - Mike Shah - CppCon 2022\n可以说是最最常用的设计模式了。\n引入 以愤怒的小鸟为例，讨论游戏的 subsystem\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // pesudo code --angrybirds.cpp void BirdSlingshot() { SimulateBirdPhysics(); if(CheckCollisions()) { PlaySoundBirdNoise(); if(HitObject Pig) { UpdateScore(); PlayPigSound(); SimulateObjectPhysics(pig); } LogResult(); } } 这段代码显然逻辑嵌套什么的比较多，我们可以使用一些技巧来修复它。\n设计模式 一段好的代码应该\n灵活性 可维护性 可扩展性 设计模式基本上是一些可重用的模板，帮助我们解决一些软件工程中经常遇到的问题。\nModel, View, Controller(MVC) MVC 模型和我们即将讨论的观察者模式适应性很好。核心是将程序分为 3 个主要部分。\nModel\n模式的中心组件，是程序的动态数据结构，独立于用户接口。它直接管理数据、逻辑以及程序执行规则。\nView\n信息的表示方式，例如图表，图，或者表。可能有多个 views 用来表示相同的信息。\nController\n​\t接受输入，并且将其转换为 model 或者 view 的命令。\n观察者模式 观察者模式基础实现 观察者模式是指一个对象，称为 subject，维护了一个依赖列表，称之为 observers，当其状态改变时会自动通知 observers。通常的实现是调用其一个方法。\n其中，subject 是你想要追踪的对象，observer 是想要根据其状态做出反应的对象。\n经典的情况是，subject 和 observer 是一对多的关系。\n有时，subject 也叫做 Publisher，observer 也叫做 Subscriber\n简单的实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Subject { public: void AddObserver(Observer* observer) { observers_.push_front(observer); } void RemoveObserver(Observer* observer) { observers_.remove(observer); } void Notify() { for (auto\u0026amp; o : observers_) { o-\u0026gt;OnNotify(); } } private: std::forward_list\u0026lt;Observer*\u0026gt; observers_; }; class Observer { public: Observer(std::string name) name_(name) {} void OnNotify() { std::cout \u0026lt;\u0026lt; name_ \u0026lt;\u0026lt; \u0026#34;Hello~\u0026#34; \u0026lt;\u0026lt; std::endl; } private: std::string name_; }; 但这只是个基础的实现，并不具备什么灵活性、扩展性，也许可以维护？\n第二次尝试 现在我们将 Subject 转换为 ISubject，其作用于 IObserver\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 class ISubject { public: ISubject() {} virtual ~ISubject() {} virtual void AddObserver(IObserver* observer) { observers_.push_front(observer); } virtual void RemoveObserver(IObserver* observer) { observers_.remove(observer); } virtual void Notify() { for (auto\u0026amp; o : observers_) { o-\u0026gt;OnNotify(); } } private: std::forward_list\u0026lt;IObserver*\u0026gt; observers_; }; class SomeSubject : public ISbuject { public: }; class IObserver { public: virutal ~IObeserver() {} virtual void OnNotify() = 0; }; class Watcher : public IObserver { public: Watcher(std::string name) name_(name) {} void OnNotify() { std::cout \u0026lt;\u0026lt; name_ \u0026lt;\u0026lt; \u0026#34;Hello~\u0026#34; \u0026lt;\u0026lt; std::endl; } private: std::string name_; }; 这次比上次好一点，但仍需要更强大的灵活性。\nsubject 仍然需要 more power.\n第三次尝试 现在，我们的每一个观察者都可能是一个特殊的系统。而此时 Subject 自然也需要存储不同类型的信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 // Subject 可以处理不同类型的 messages/events/keys // 让我们的 Subject 支持不同的子系统，但是仍然解耦 class ISubject { public: virtual void AddObserver(int msg, IObserver* observer) { auto it = observers_.find(msg); if (it == observers_.end()) { observers_[msg] = ObserversLists(); } observers_[msg].push_front(observer); } virtual void NotifyAll() { for (ObserversMap::iterator it = observers_.begin(); it != observers_.end(); ++it) { for (auto\u0026amp; o : observers_[it-\u0026gt;first]) { o-\u0026gt;OnNotify(); } } } virtual void Notify(int msg) { for(auto\u0026amp; o : observers_[msg]) { o-\u0026gt;OnNotify(); } } private: // 两个 typedef，一个用于存储 observer list // 还有一个 map，int 作为 key，区别不同类型的系统 using ObserversList = std::forward_list\u0026lt;IObserver*\u0026gt;; using ObserversMap = std::map\u0026lt;int, ObserversList\u0026gt;; ObserversMap oberservers_; }; // 我们需要决定 message 的类型 class SomeSubject : public ISubjecet { public: enmu MessageTypes{PLAYSOUND, HANDLEPHYSICS, LOG};\t// 为了方便所以用了 enum 而不是 enum class } class SoundEvent : public IObserver { public: explicit SoundEvent(const std::string\u0026amp; name) : name_(name) {} void OnNotify() { std::cout \u0026lt;\u0026lt; name_ \u0026lt;\u0026lt; \u0026#34;Sound engine do...\\n\u0026#34;; } std::string GetName() const override {return name_;} private: std::string name_; }; class PhysicsEvent : public IObserver { public: explicit SoundEvent(const std::string\u0026amp; name) : name_(name) {} void OnNotify() { std::cout \u0026lt;\u0026lt; name_ \u0026lt;\u0026lt; \u0026#34;Physics engine do...\\n\u0026#34;; } std::string GetName() const override {return name_;} private: std::string name_; }; 现在就非常灵活，并且也可维护，扩展性也很好。\n观察者模式的其他 tip 一些 C++ 方面改进 智能指针 enum class 使用其他结构替代 std::forward_list 也许 observer 需要按一定权重排序（priority_queue） 也许 observer 需要常量时间查找（unordered_map） ","date":"2024-02-29T00:00:00Z","image":"https://rossqaq.github.io/article/cppcon-2022-observer/cppcon2022-cover_hu7c68731152d935aaf39331c224457d06_58010_120x120_fill_box_smart1_3.png","permalink":"https://rossqaq.github.io/article/cppcon-2022-observer/","title":"观察者模式"},{"content":"本文是文章 io_uring By Example: Part 3 - A Web Server with io_uring - Unixism 的翻译与总结。\n同样只摘录重要的部分。\n这一篇文章使用 liburing 来实现了一个 webserver，我们可以看看 io_uring 在网络编程中的应用\n简介 这一次，我们来看看 accept 是怎么作用于 io_uring 的，配合 readv/writev，你已经可以编写一个简单的 web server 了。这篇文章的代码类似于 ZeroHTTPd, 我会使用 io_uring 来实现。\nweb server 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;netinet/in.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;ctype.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;liburing.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #define SERVER_STRING \u0026#34;Server: zerohttpd/0.1\\r\\n\u0026#34; #define DEFAULT_SERVER_PORT 8000 #define QUEUE_DEPTH 256 #define READ_SZ 8192 #define EVENT_TYPE_ACCEPT 0 #define EVENT_TYPE_READ 1 #define EVENT_TYPE_WRITE 2 struct request { int event_type; int iovec_count; int client_socket; struct iovec iov[]; }; struct io_uring ring; const char *unimplemented_content = \\ \u0026#34;HTTP/1.0 400 Bad Request\\r\\n\u0026#34; \u0026#34;Content-type: text/html\\r\\n\u0026#34; \u0026#34;\\r\\n\u0026#34; \u0026#34;\u0026lt;html\u0026gt;\u0026#34; \u0026#34;\u0026lt;head\u0026gt;\u0026#34; \u0026#34;\u0026lt;title\u0026gt;ZeroHTTPd: Unimplemented\u0026lt;/title\u0026gt;\u0026#34; \u0026#34;\u0026lt;/head\u0026gt;\u0026#34; \u0026#34;\u0026lt;body\u0026gt;\u0026#34; \u0026#34;\u0026lt;h1\u0026gt;Bad Request (Unimplemented)\u0026lt;/h1\u0026gt;\u0026#34; \u0026#34;\u0026lt;p\u0026gt;Your client sent a request ZeroHTTPd did not understand and it is probably not your fault.\u0026lt;/p\u0026gt;\u0026#34; \u0026#34;\u0026lt;/body\u0026gt;\u0026#34; \u0026#34;\u0026lt;/html\u0026gt;\u0026#34;; const char *http_404_content = \\ \u0026#34;HTTP/1.0 404 Not Found\\r\\n\u0026#34; \u0026#34;Content-type: text/html\\r\\n\u0026#34; \u0026#34;\\r\\n\u0026#34; \u0026#34;\u0026lt;html\u0026gt;\u0026#34; \u0026#34;\u0026lt;head\u0026gt;\u0026#34; \u0026#34;\u0026lt;title\u0026gt;ZeroHTTPd: Not Found\u0026lt;/title\u0026gt;\u0026#34; \u0026#34;\u0026lt;/head\u0026gt;\u0026#34; \u0026#34;\u0026lt;body\u0026gt;\u0026#34; \u0026#34;\u0026lt;h1\u0026gt;Not Found (404)\u0026lt;/h1\u0026gt;\u0026#34; \u0026#34;\u0026lt;p\u0026gt;Your client is asking for an object that was not found on this server.\u0026lt;/p\u0026gt;\u0026#34; \u0026#34;\u0026lt;/body\u0026gt;\u0026#34; \u0026#34;\u0026lt;/html\u0026gt;\u0026#34;; /* * Utility function to convert a string to lower case. * */ void strtolower(char *str) { for (; *str; ++str) *str = (char)tolower(*str); } /* One function that prints the system call and the error details and then exits with error code 1. Non-zero meaning things didn\u0026#39;t go well. */ void fatal_error(const char *syscall) { perror(syscall); exit(1); } /* * Helper function for cleaner looking code. * */ void *zh_malloc(size_t size) { void *buf = malloc(size); if (!buf) { fprintf(stderr, \u0026#34;Fatal error: unable to allocate memory.\\n\u0026#34;); exit(1); } return buf; } /* * This function is responsible for setting up the main listening socket used by the * web server. * */ int setup_listening_socket(int port) { int sock; struct sockaddr_in srv_addr; sock = socket(PF_INET, SOCK_STREAM, 0); if (sock == -1) fatal_error(\u0026#34;socket()\u0026#34;); int enable = 1; if (setsockopt(sock, SOL_SOCKET, SO_REUSEADDR, \u0026amp;enable, sizeof(int)) \u0026lt; 0) fatal_error(\u0026#34;setsockopt(SO_REUSEADDR)\u0026#34;); memset(\u0026amp;srv_addr, 0, sizeof(srv_addr)); srv_addr.sin_family = AF_INET; srv_addr.sin_port = htons(port); srv_addr.sin_addr.s_addr = htonl(INADDR_ANY); /* We bind to a port and turn this socket into a listening * socket. * */ if (bind(sock, (const struct sockaddr *)\u0026amp;srv_addr, sizeof(srv_addr)) \u0026lt; 0) fatal_error(\u0026#34;bind()\u0026#34;); if (listen(sock, 10) \u0026lt; 0) fatal_error(\u0026#34;listen()\u0026#34;); return (sock); } int add_accept_request(int server_socket, struct sockaddr_in *client_addr, socklen_t *client_addr_len) { struct io_uring_sqe *sqe = io_uring_get_sqe(\u0026amp;ring); io_uring_prep_accept(sqe, server_socket, (struct sockaddr *) client_addr, client_addr_len, 0); struct request *req = malloc(sizeof(*req)); req-\u0026gt;event_type = EVENT_TYPE_ACCEPT; io_uring_sqe_set_data(sqe, req); io_uring_submit(\u0026amp;ring); return 0; } int add_read_request(int client_socket) { struct io_uring_sqe *sqe = io_uring_get_sqe(\u0026amp;ring); struct request *req = malloc(sizeof(*req) + sizeof(struct iovec)); req-\u0026gt;iov[0].iov_base = malloc(READ_SZ); req-\u0026gt;iov[0].iov_len = READ_SZ; req-\u0026gt;event_type = EVENT_TYPE_READ; req-\u0026gt;client_socket = client_socket; memset(req-\u0026gt;iov[0].iov_base, 0, READ_SZ); /* Linux kernel 5.5 has support for readv, but not for recv() or read() */ io_uring_prep_readv(sqe, client_socket, \u0026amp;req-\u0026gt;iov[0], 1, 0); io_uring_sqe_set_data(sqe, req); io_uring_submit(\u0026amp;ring); return 0; } int add_write_request(struct request *req) { struct io_uring_sqe *sqe = io_uring_get_sqe(\u0026amp;ring); req-\u0026gt;event_type = EVENT_TYPE_WRITE; io_uring_prep_writev(sqe, req-\u0026gt;client_socket, req-\u0026gt;iov, req-\u0026gt;iovec_count, 0); io_uring_sqe_set_data(sqe, req); io_uring_submit(\u0026amp;ring); return 0; } void _send_static_string_content(const char *str, int client_socket) { struct request *req = zh_malloc(sizeof(*req) + sizeof(struct iovec)); unsigned long slen = strlen(str); req-\u0026gt;iovec_count = 1; req-\u0026gt;client_socket = client_socket; req-\u0026gt;iov[0].iov_base = zh_malloc(slen); req-\u0026gt;iov[0].iov_len = slen; memcpy(req-\u0026gt;iov[0].iov_base, str, slen); add_write_request(req); } /* * When ZeroHTTPd encounters any other HTTP method other than GET or POST, this function * is used to inform the client. * */ void handle_unimplemented_method(int client_socket) { _send_static_string_content(unimplemented_content, client_socket); } /* * This function is used to send a \u0026#34;HTTP Not Found\u0026#34; code and message to the client in * case the file requested is not found. * */ void handle_http_404(int client_socket) { _send_static_string_content(http_404_content, client_socket); } /* * Once a static file is identified to be served, this function is used to read the file * and write it over the client socket using Linux\u0026#39;s sendfile() system call. This saves us * the hassle of transferring file buffers from kernel to user space and back. * */ void copy_file_contents(char *file_path, off_t file_size, struct iovec *iov) { int fd; char *buf = zh_malloc(file_size); fd = open(file_path, O_RDONLY); if (fd \u0026lt; 0) fatal_error(\u0026#34;read\u0026#34;); /* We should really check for short reads here */ int ret = read(fd, buf, file_size); if (ret \u0026lt; file_size) { fprintf(stderr, \u0026#34;Encountered a short read.\\n\u0026#34;); } close(fd); iov-\u0026gt;iov_base = buf; iov-\u0026gt;iov_len = file_size; } /* * Simple function to get the file extension of the file that we are about to serve. * */ const char *get_filename_ext(const char *filename) { const char *dot = strrchr(filename, \u0026#39;.\u0026#39;); if (!dot || dot == filename) return \u0026#34;\u0026#34;; return dot + 1; } /* * Sends the HTTP 200 OK header, the server string, for a few types of files, it can also * send the content type based on the file extension. It also sends the content length * header. Finally it send a \u0026#39;\\r\\n\u0026#39; in a line by itself signalling the end of headers * and the beginning of any content. * */ void send_headers(const char *path, off_t len, struct iovec *iov) { char small_case_path[1024]; char send_buffer[1024]; strcpy(small_case_path, path); strtolower(small_case_path); char *str = \u0026#34;HTTP/1.0 200 OK\\r\\n\u0026#34;; unsigned long slen = strlen(str); iov[0].iov_base = zh_malloc(slen); iov[0].iov_len = slen; memcpy(iov[0].iov_base, str, slen); slen = strlen(SERVER_STRING); iov[1].iov_base = zh_malloc(slen); iov[1].iov_len = slen; memcpy(iov[1].iov_base, SERVER_STRING, slen); /* * Check the file extension for certain common types of files * on web pages and send the appropriate content-type header. * Since extensions can be mixed case like JPG, jpg or Jpg, * we turn the extension into lower case before checking. * */ const char *file_ext = get_filename_ext(small_case_path); if (strcmp(\u0026#34;jpg\u0026#34;, file_ext) == 0) strcpy(send_buffer, \u0026#34;Content-Type: image/jpeg\\r\\n\u0026#34;); if (strcmp(\u0026#34;jpeg\u0026#34;, file_ext) == 0) strcpy(send_buffer, \u0026#34;Content-Type: image/jpeg\\r\\n\u0026#34;); if (strcmp(\u0026#34;png\u0026#34;, file_ext) == 0) strcpy(send_buffer, \u0026#34;Content-Type: image/png\\r\\n\u0026#34;); if (strcmp(\u0026#34;gif\u0026#34;, file_ext) == 0) strcpy(send_buffer, \u0026#34;Content-Type: image/gif\\r\\n\u0026#34;); if (strcmp(\u0026#34;htm\u0026#34;, file_ext) == 0) strcpy(send_buffer, \u0026#34;Content-Type: text/html\\r\\n\u0026#34;); if (strcmp(\u0026#34;html\u0026#34;, file_ext) == 0) strcpy(send_buffer, \u0026#34;Content-Type: text/html\\r\\n\u0026#34;); if (strcmp(\u0026#34;js\u0026#34;, file_ext) == 0) strcpy(send_buffer, \u0026#34;Content-Type: application/javascript\\r\\n\u0026#34;); if (strcmp(\u0026#34;css\u0026#34;, file_ext) == 0) strcpy(send_buffer, \u0026#34;Content-Type: text/css\\r\\n\u0026#34;); if (strcmp(\u0026#34;txt\u0026#34;, file_ext) == 0) strcpy(send_buffer, \u0026#34;Content-Type: text/plain\\r\\n\u0026#34;); slen = strlen(send_buffer); iov[2].iov_base = zh_malloc(slen); iov[2].iov_len = slen; memcpy(iov[2].iov_base, send_buffer, slen); /* Send the content-length header, which is the file size in this case. */ sprintf(send_buffer, \u0026#34;content-length: %ld\\r\\n\u0026#34;, len); slen = strlen(send_buffer); iov[3].iov_base = zh_malloc(slen); iov[3].iov_len = slen; memcpy(iov[3].iov_base, send_buffer, slen); /* * When the browser sees a \u0026#39;\\r\\n\u0026#39; sequence in a line on its own, * it understands there are no more headers. Content may follow. * */ strcpy(send_buffer, \u0026#34;\\r\\n\u0026#34;); slen = strlen(send_buffer); iov[4].iov_base = zh_malloc(slen); iov[4].iov_len = slen; memcpy(iov[4].iov_base, send_buffer, slen); } void handle_get_method(char *path, int client_socket) { char final_path[1024]; /* If a path ends in a trailing slash, the client probably wants the index file inside of that directory. */ if (path[strlen(path) - 1] == \u0026#39;/\u0026#39;) { strcpy(final_path, \u0026#34;public\u0026#34;); strcat(final_path, path); strcat(final_path, \u0026#34;index.html\u0026#34;); } else { strcpy(final_path, \u0026#34;public\u0026#34;); strcat(final_path, path); } /* The stat() system call will give you information about the file * like type (regular file, directory, etc), size, etc. */ struct stat path_stat; if (stat(final_path, \u0026amp;path_stat) == -1) { printf(\u0026#34;404 Not Found: %s (%s)\\n\u0026#34;, final_path, path); handle_http_404(client_socket); } else { /* Check if this is a normal/regular file and not a directory or something else */ if (S_ISREG(path_stat.st_mode)) { struct request *req = zh_malloc(sizeof(*req) + (sizeof(struct iovec) * 6)); req-\u0026gt;iovec_count = 6; req-\u0026gt;client_socket = client_socket; send_headers(final_path, path_stat.st_size, req-\u0026gt;iov); copy_file_contents(final_path, path_stat.st_size, \u0026amp;req-\u0026gt;iov[5]); printf(\u0026#34;200 %s %ld bytes\\n\u0026#34;, final_path, path_stat.st_size); add_write_request( req); } else { handle_http_404(client_socket); printf(\u0026#34;404 Not Found: %s\\n\u0026#34;, final_path); } } } /* * This function looks at method used and calls the appropriate handler function. * Since we only implement GET and POST methods, it calls handle_unimplemented_method() * in case both these don\u0026#39;t match. This sends an error to the client. * */ void handle_http_method(char *method_buffer, int client_socket) { char *method, *path, *saveptr; method = strtok_r(method_buffer, \u0026#34; \u0026#34;, \u0026amp;saveptr); strtolower(method); path = strtok_r(NULL, \u0026#34; \u0026#34;, \u0026amp;saveptr); if (strcmp(method, \u0026#34;get\u0026#34;) == 0) { handle_get_method(path, client_socket); } else { handle_unimplemented_method(client_socket); } } int get_line(const char *src, char *dest, int dest_sz) { for (int i = 0; i \u0026lt; dest_sz; i++) { dest[i] = src[i]; if (src[i] == \u0026#39;\\r\u0026#39; \u0026amp;\u0026amp; src[i+1] == \u0026#39;\\n\u0026#39;) { dest[i] = \u0026#39;\\0\u0026#39;; return 0; } } return 1; } int handle_client_request(struct request *req) { char http_request[1024]; /* Get the first line, which will be the request */ if(get_line(req-\u0026gt;iov[0].iov_base, http_request, sizeof(http_request))) { fprintf(stderr, \u0026#34;Malformed request\\n\u0026#34;); exit(1); } handle_http_method(http_request, req-\u0026gt;client_socket); return 0; } void server_loop(int server_socket) { struct io_uring_cqe *cqe; struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr); add_accept_request(server_socket, \u0026amp;client_addr, \u0026amp;client_addr_len); while (1) { int ret = io_uring_wait_cqe(\u0026amp;ring, \u0026amp;cqe); struct request *req = (struct request *) cqe-\u0026gt;user_data; if (ret \u0026lt; 0) fatal_error(\u0026#34;io_uring_wait_cqe\u0026#34;); if (cqe-\u0026gt;res \u0026lt; 0) { fprintf(stderr, \u0026#34;Async request failed: %s for event: %d\\n\u0026#34;, strerror(-cqe-\u0026gt;res), req-\u0026gt;event_type); exit(1); } switch (req-\u0026gt;event_type) { case EVENT_TYPE_ACCEPT: add_accept_request(server_socket, \u0026amp;client_addr, \u0026amp;client_addr_len); add_read_request(cqe-\u0026gt;res); free(req); break; case EVENT_TYPE_READ: if (!cqe-\u0026gt;res) { fprintf(stderr, \u0026#34;Empty request!\\n\u0026#34;); break; } handle_client_request(req); free(req-\u0026gt;iov[0].iov_base); free(req); break; case EVENT_TYPE_WRITE: for (int i = 0; i \u0026lt; req-\u0026gt;iovec_count; i++) { free(req-\u0026gt;iov[i].iov_base); } close(req-\u0026gt;client_socket); free(req); break; } /* Mark this request as processed */ io_uring_cqe_seen(\u0026amp;ring, cqe); } } void sigint_handler(int signo) { printf(\u0026#34;^C pressed. Shutting down.\\n\u0026#34;); io_uring_queue_exit(\u0026amp;ring); exit(0); } int main() { int server_socket = setup_listening_socket(DEFAULT_SERVER_PORT); signal(SIGINT, sigint_handler); io_uring_queue_init(QUEUE_DEPTH, \u0026amp;ring, 0); server_loop(server_socket); return 0; } 程序结构 首先，main() 调用 setup_listening_socket() 来监听一个端口。但我们不用 accept() 来监听端口，我们使用的是 io_uring 提供的。\n程序的核心自然是 server_loop() ，用来提交请求给 io_uring，并且等待 CQE 之后对他们进行处理。我们看看\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 void server_loop(int server_socket) { struct io_uring_cqe *cqe; struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr); add_accept_request(server_socket, \u0026amp;client_addr, \u0026amp;client_addr_len); while (1) { int ret = io_uring_wait_cqe(\u0026amp;ring, \u0026amp;cqe); struct request *req = (struct request *) cqe-\u0026gt;user_data; if (ret \u0026lt; 0) fatal_error(\u0026#34;io_uring_wait_cqe\u0026#34;); if (cqe-\u0026gt;res \u0026lt; 0) { fprintf(stderr, \u0026#34;Async request failed: %s for event: %d\\n\u0026#34;, strerror(-cqe-\u0026gt;res), req-\u0026gt;event_type); exit(1); } switch (req-\u0026gt;event_type) { case EVENT_TYPE_ACCEPT: add_accept_request(server_socket, \u0026amp;client_addr, \u0026amp;client_addr_len); add_read_request(cqe-\u0026gt;res); free(req); break; case EVENT_TYPE_READ: if (!cqe-\u0026gt;res) { fprintf(stderr, \u0026#34;Empty request!\\n\u0026#34;); break; } handle_client_request(req); free(req-\u0026gt;iov[0].iov_base); free(req); break; case EVENT_TYPE_WRITE: for (int i = 0; i \u0026lt; req-\u0026gt;iovec_count; i++) { free(req-\u0026gt;iov[i].iov_base); } close(req-\u0026gt;client_socket); free(req); break; } /* Mark this request as processed */ io_uring_cqe_seen(\u0026amp;ring, cqe); } } 在 while 循环中，我们提交 accept 请求，通过调用 add_accept_request()。\n1 2 3 4 5 6 7 8 9 10 11 int add_accept_request(int server_socket, struct sockaddr_in *client_addr, socklen_t *client_addr_len) { struct io_uring_sqe *sqe = io_uring_get_sqe(\u0026amp;ring); io_uring_prep_accept(sqe, server_socket, (struct sockaddr *) client_addr, client_addr_len, 0); struct request *req = malloc(sizeof(*req)); req-\u0026gt;event_type = EVENT_TYPE_ACCEPT; io_uring_sqe_set_data(sqe, req); io_uring_submit(\u0026amp;ring); return 0; } 我们先获取一个 SQE，然后准备使用 io_uring_prep_accept() 来提交 accept 请求。使用结构体 request 来跟踪我们的每一个请求。这个 req 实例包含了每个请求的从一个状态到另一个状态时的上下文。\n1 2 3 4 5 6 struct request { int event_type; int iovec_count; int client_socket; struct iovec iov[]; }; 客户端会经历三个请求，此外这个结构体可以保存足够的信息来 handle 这些请求并转移这个状态。三个请求的顺序：\nAccepted -\u0026gt; Request read -\u0026gt; Response written\n我们来看看一旦 accept 完成，在 switch 中的 completion side 会发生什么：\n1 2 3 4 5 case EVENT_TYPE_ACCEPT: add_accept_request(server_socket, \u0026amp;client_addr, \u0026amp;client_addr_len); add_read_request(cqe-\u0026gt;res); free(req); break; 我们重新提交一个 accept 请求，因为我们之前已经处理过一个了。否则我们的程序就不能再接受来自其他客户端的 accept。之后就可以调用 read 请求使用 readv 来读取客户端的 HTTP 请求。\n这里有很多要说的：我们看使用 read，但直到 kernel 5.6 才支持该函数，在撰写本文时，他是最新的稳定版本。\n使用 readv/writev 也能允许我们实现常规操作，尤其是 buffer 管理。现在我们来看 add_read_request()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 int add_read_request(int client_socket) { struct io_uring_sqe *sqe = io_uring_get_sqe(\u0026amp;ring); struct request *req = malloc(sizeof(*req) + sizeof(struct iovec)); req-\u0026gt;iov[0].iov_base = malloc(READ_SZ); req-\u0026gt;iov[0].iov_len = READ_SZ; req-\u0026gt;event_type = EVENT_TYPE_READ; req-\u0026gt;client_socket = client_socket; memset(req-\u0026gt;iov[0].iov_base, 0, READ_SZ); /* Linux kernel 5.5 has support for readv, but not for recv() or read() */ io_uring_prep_readv(sqe, client_socket, \u0026amp;req-\u0026gt;iov[0], 1, 0); io_uring_sqe_set_data(sqe, req); io_uring_submit(\u0026amp;ring); return 0; } 译者：在2024年看到这篇文章，那肯定是都支持了。官方手册里也说，使用 readv 不如 read 性能高，此外 read 还支持别的操作。这里也是把 readv 当 read 用。\n很直接，我们分配一个足够大的 buffer 来处理客户端请求，之后 io_uring_prep_readv()，对应的 handling 在 switch 语句中是：\n1 2 3 4 5 6 7 8 9 case EVENT_TYPE_READ: if (!cqe-\u0026gt;res) { fprintf(stderr, \u0026#34;Empty request!\\n\u0026#34;); break; } handle_client_request(req); free(req-\u0026gt;iov[0].iov_base); free(req); break; 这里，我们调用 handle_client_request 函数处理 HTTP 请求，如果一切正常的话，客户端正在请求一个本地的文件，这一段会处理请求\n1 2 3 4 5 6 7 struct request *req = zh_malloc(sizeof(*req) + (sizeof(struct iovec) * 6)); req-\u0026gt;iovec_count = 6; req-\u0026gt;client_socket = client_socket; set_headers(final_path, path_stat.st_size, req-\u0026gt;iov); copy_file_contents(final_path, path_stat.st_size, \u0026amp;req-\u0026gt;iov[5]); printf(\u0026#34;200 %s %ld bytes\\n\u0026#34;, final_path, path_stat.st_size); add_write_request( req); set_headers() 包括了 5 个小的 buffer，代表 5 个不同的 iovec，最后一个包含了读取的数据，最终 调用 add_write_request()\n1 2 3 4 5 6 7 8 int add_write_request(struct request *req) { struct io_uring_sqe *sqe = io_uring_get_sqe(\u0026amp;ring); req-\u0026gt;event_type = EVENT_TYPE_WRITE; io_uring_prep_writev(sqe, req-\u0026gt;client_socket, req-\u0026gt;iov, req-\u0026gt;iovec_count, 0); io_uring_sqe_set_data(sqe, req); io_uring_submit(\u0026amp;ring); return 0; } completion side:\n1 2 3 4 5 6 7 case EVENT_TYPE_WRITE: for (int i = 0; i \u0026lt; req-\u0026gt;iovec_count; i++) { free(req-\u0026gt;iov[i].iov_base); } close(req-\u0026gt;client_socket); free(req); break; 把所有的 iovec 释放，把所有的 req 释放，并且关闭 socket，这就是完整的 HTTP client 服务。\nConclusion I hope you had a good time reading this article series. I sure had a lot of fun trying io_uring out. It is still early days for io_uring. It continues to gain features and gets better at performance as the days go by. I’m confident it will very quickly be adopted by various software projects.\nSource code The full source code for all the examples is available here at Github.\nAbout me My name is Shuveb Hussain and I’m the author of this Linux-focused blog. You can follow me on Twitter where I post tech-related content mostly focusing on Linux, performance, scalability and cloud technologies.\n","date":"2024-02-26T00:00:00Z","permalink":"https://rossqaq.github.io/article/io_uring-web/","title":"io_uring P3 - 实现 webserver"},{"content":"Breaking Dependencies: Type Erasure - A Design Analysis - Klaus Iglberger - CppCon 2021\n讲解类型擦除的，更重要的是考虑其背后的设计思想。\n也是熟人，之前讲解 class design 的，而这次的类型擦除也跟那期有关。\n","date":"2024-02-23T20:00:00Z","image":"https://rossqaq.github.io/article/cppcon-2021-type-erasure/cppcon2021-cover_hu12c72e74cc107b1dec0a72d3e09dd6fc_58474_120x120_fill_box_smart1_3.png","permalink":"https://rossqaq.github.io/article/cppcon-2021-type-erasure/","title":"C++ 类型擦除的设计思想"},{"content":"Back to Basics: Type Erasure - Arthur O\u0026rsquo;Dwyer - CppCon 2019\n又是 Arthur O\u0026rsquo;Dwyer，这期演讲是 back to basics，类型擦除的具体细节。\n简介 你可能从 C# 或者 Java 中听说过 type erasure，但其他语言的类型擦除和 C++ 的完全不是一回事。\n我们讨论的最初问题是：如何写一个函数，可以接受 lambda 作为参数\n普通的做法可能是：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Shelf { template\u0026lt;typename Func\u0026gt; void for_each_book(Func f) { for (const Book\u0026amp; b : books_) f(b); } }; Shelf myshelf; myshelf.for_each_book([](auto\u0026amp;\u0026amp; book) { book.print(); }); // 这要求每个翻译单元中都有这个成员函数模板，我们可以将其改为回调形式 class Shelf { void for_each_book(CallBack f) { for (const Book\u0026amp; b : books_) f(b); } }; // CallBack 可能只是 std::funtion\u0026lt;void(const Book\u0026amp;)\u0026gt; // 现在就可以分文件了 类型擦除 concretifies 模板 模板并不是一个函数，但 type erasure 后的函数是一个真正的函数，可以被编译。\n举个例子，std::sort\nstd::sort 是一个函数模板\n可以接受任何 Copmarator 内联 必须 定义为头文件：编译慢，代码膨胀 作为对比，C-style 的 qsort 接收函数指针\n只能接受固定的 Comparator 不能被内联 可以 被定义在外部 并不是类型安全的 我们可以同时拥有二者的优点吗？\nCallable 可以被这样切分 类似于 C 中的 qsort_r\n1 2 3 void qsort_r(void *base, size_t nmemb, size_t size, int (*compar)(const void *, const void *, void *), void *cookie); 其函数签名长这样，comparator 中可以多一个参数，通过最后那个 void* arg 传入。\n我们这样想，\n不要把compar当做需要你支持 cookie 的行为，而是将他看成 cookie 本身提供的行为\nqsort_r 能做什么？传一个 compar 仅此而已。cookie 只提供了一个行为\n给出一个可调用对象\n1 2 template\u0026lt;typnemae Callable\u0026gt; void foo(Callable\u0026amp; func); 可以将其分为 它的表示 以及 它的行为\n它的表示，也就是实际内存中的 bit，只是一个函数指针和地址\n假设 foo 的参数 func 的要求是 不接受参数，return int\n那么我们可以将其分开为：\n1 2 3 4 5 void* representation = \u0026amp;callable; int (*behavior_when_called)(void*) = +[](void* r) { return (*(Callable *)r)();\t// 将 r 转换为 Callable 的类型之后调用 } assert(behavior_when_called(representation) == func()); 这样当我们调用 behavior_when_called(representation) 的效果和调用 func() 一样。\nplus lambda，众所周知 lambda 是类类型，这里需要一个函数指针，所以一元+ （正符号）可以将 lambda 转换为算术类型。\n我们开头的 类型Callable，如果我们不知道它的具体类型就无法使用。\n当我们将其分为其表示和行为时，我们擦除了他的所有关于类型的信息（size, alignment, copyability\u0026hellip;）\n考虑一个可以取反的对象，也可以使用这种方法：\n1 2 template\u0026lt;typename Negatable\u0026gt; void foo(Negatable\u0026amp; number) 假设 number 支持按位取反且返回 int，我们可以将其分开：\n1 2 3 4 5 void* representation = \u0026amp;number; int (*behavior_when_negated)(void*) = +[](void* r) { return ~(*(Negatable*)r); }; assert(behavior_when_negated(representation) == ~number); 嗯，number 也许还支持取非，\n1 2 3 4 5 6 7 8 9 void* representation = \u0026amp;number; int (*behavior_when_negated)(void*) = +[](void* r) { return ~(*(Negatable*)r); }; int (*behavior_when_notted)(void*) = +[](void* r) { return !(*(Negatable*)r); }; assert(behavior_when_negated(representation) == ~number); assert(behavior_when_notted(representation) == !number); 将表示和行为包装 C 中没有类，所以 qsort_r 中的 cookie 只能有一种 comparsion 行为，C++我们可以做的更好。\n1 2 3 4 5 6 7 struct TypeErasedNumberRef { void* representation_; int (*negated_)(void*); bool (*not)(void*); int operator~() const { return negate_(representation_); } int operator!() const { return not_(representation_); } }; 如何构造 TypeErasedNumberRef 支持任何数？\n想到：要构造，肯定要构造函数、要支持任何数，可以模板 -\u0026gt; 可以使用构造函数模板来支持任何数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 struct TypeErasedNumberRef { template\u0026lt;typename Number\u0026gt; TypeErasedNumberRef(Number\u0026amp; n) : representation_( (void*)\u0026amp;n ), negate_ ( [](void* r)-\u0026gt;int {return -(*(Number*)r); } ), not_ ( [](void* r)-\u0026gt;int {return !(*(Number*)r); } ) {} void* representation_; int (*negated_)(void*); bool (*not)(void*); int operator~() const { return negate_(representation_); } bool operator!() const { return not_(representation_); } }; int x = 42; TypeErasedNumberRef ref(x); 这些函数有不同的类型，可能也有不同行为，但是调用方法是一样的，通过 operator~, operator! 等等，是不是很神奇\n跟 C++26 的 std::function_ref 长得很像。\n所有权 那 TypeErasedNumberRef 的所有权怎么办？\n其保存源对象的地址 源对象生命期结束，引用也失效 传个右值这种明显会悬垂引用。\n可以参考 std::function_ref\n\u0026ldquo;Destructibility\u0026rdquo; 是一种能力 一些对象可以销毁，一些对象不能，这是一种行为。我们使用值语义来实现一个 TypeErasedNumber(不要引用语义)\n也就是说他要实际捕获值然后让类自己管理生命期。\n~TypeErasedNumber 用来销毁捕获的对象。\n捕获的对象可能很大，我们必须有足够空间。那么size到底是多少？\nUserType 可能很大 所以我们使用堆内存 还有其他方法，但是不在本讲座范围内 手动销毁 1 2 3 4 5 6 7 8 9 10 11 12 struct TE { void* repr_; void (*delete_)(void*); template\u0026lt;class Number\u0026gt; TE(Number n) : repr_(new Number(std::move(n))), delete_([](void* r) { delete (Number*)r; }) {} ~TE() { delete_(repr_); } }; 复制 有很多种方法，这是其一\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 struct TE { void* repr_; void (*clone_)(void*); template\u0026lt;class Number\u0026gt; TE(Number n) : repr_(new Number(std::move(n))), clone_([](void* r) { return new Number(*(Number*)r); }) {} TE(const TE\u0026amp; rhs) : repr_(rhs.clone_(rhs.repr_)), clone_(rhs.clone_) {} }; 指导：Affordances 我们的宗旨是：\n列出 Number 为了类型擦除究竟要提供什么操作 特殊成员必须要考虑到 对于每个操作，将其用 lambda 分开表示，使用固定函数签名 构造模板会通过 lambda 初始化函数指针 每个 lambda 的行为都取决于 Number，但是其签名要固定 但这样很可能导致函数指针太多，那咋办？\n举个例子\n1 2 3 4 5 6 struct TE { void* repr_; void (*doA_)(void*); void (*doB_)(void*); void (*doC_)(void*); }; 这光指针就40字节，我们可以把他结合为一个函数，给出其他参数，来决定要执行什么行为。\n1 2 3 4 struct TE { void* repr_; void (*doABC_)(int, void*); }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 #include \u0026lt;cassert\u0026gt; #include \u0026lt;utility\u0026gt; template\u0026lt;class Number\u0026gt; void *ABC(int op, void *r, void *out) { Number\u0026amp; num = *(Number *)r; switch (op) { case 0: return new Number(num); case 1: *(int*)out = -num; return nullptr; case 2: *(bool*)out = !num; return nullptr; case 3: delete \u0026amp;num; return nullptr; } __builtin_unreachable(); } struct TE { void *repr_ = nullptr; void *(*abc_)(int, void*, void*) = nullptr; template\u0026lt;class Number\u0026gt; TE(Number n) : repr_(new Number(std::move(n))), abc_(ABC\u0026lt;Number\u0026gt;) {} void *clone() const { return abc_(0, repr_, nullptr); } TE(const TE\u0026amp; rhs) : repr_(rhs.clone()), abc_(rhs.abc_) {} int operator-() const { int v; abc_(1, repr_, \u0026amp;v); return v; } bool operator!() const { bool v; abc_(2, repr_, \u0026amp;v); return v; } ~TE() { abc_(3, repr_, nullptr); } void swap(TE\u0026amp; rhs) noexcept { std::swap(repr_, rhs.repr_); std::swap(abc_, rhs.abc_); } TE(TE\u0026amp;\u0026amp; rhs) noexcept { this-\u0026gt;swap(rhs); } TE\u0026amp; operator=(TE rhs) noexcept { this-\u0026gt;swap(rhs); return *this; } }; int main() { TE one(1); TE two(2.0); assert( -one == -1 ); assert( !two == false ); } 我们还可以把行为也分开\n1 2 3 4 struct TE { void* repr_; TE_Behaviors *behave_; }; 这样的话如果其行为类似，那么就可以把行为汇集到一起，然后让所有内部类型一样的 TE 的行为指向那个全局结构。\n如果想让 TE 更小的话，这样就可以把行为也放到堆里，这样像什么呢？像是 vptr 和 vtable\n1 2 3 struct TE { ???? repr_; } 类型安全的类型擦除 C++ 中我们可以实现类型安全的类型擦除。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 #include \u0026lt;cassert\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026lt;utility\u0026gt; using std::unique_ptr; using std::make_unique; struct TEBase { virtual unique_ptr\u0026lt;TEBase\u0026gt; clone() const = 0; virtual int negate() const = 0; virtual bool not_() const = 0; virtual ~TEBase() = default; }; template\u0026lt;class Number\u0026gt; struct TED : public TEBase { Number num_; explicit TED(Number n) : num_(std::move(n)) {} unique_ptr\u0026lt;TEBase\u0026gt; clone() const override { return std::make_unique\u0026lt;TED\u0026gt;(num_); } int negate() const override { return -num_; } bool not_() const override { return !num_; } }; struct TE { unique_ptr\u0026lt;TEBase\u0026gt; p_ = nullptr; template\u0026lt;class Number\u0026gt; TE(Number n) : p_( make_unique\u0026lt;TED\u0026lt;Number\u0026gt;\u0026gt;(std::move(n)) ) {} TE(const TE\u0026amp; rhs) : p_(rhs.p_-\u0026gt;clone()) {} TE(TE\u0026amp;\u0026amp;) noexcept = default; TE\u0026amp; operator=(TE rhs) { std::swap(p_, rhs.p_); return *this; } ~TE() = default; int operator-() const { return p_-\u0026gt;negate(); } bool operator!() const { return p_-\u0026gt;not_(); } }; int main() { TE one(1); TE two(2.0); assert( -one == -1 ); assert( !two == false ); } 类型擦除可以干什么 std::function\u0026lt;S\u0026gt; 将函数签名为 S 的函数包装为提供 copying, destorying, calling 三个行为 std::any 包装所有类型并提供 copying 和 destroying function_ref\u0026lt;S\u0026gt; C++26, 函数签名为 S 的函数包装，提供 calling 行为 unique_function\u0026lt;S\u0026gt; （不知道什么时候）函数签名为 S 的函数包装，提供 destroying， calling 行为 std::any std::any\n提供复制、销毁行为 如何获取其内容？ std::any 比较有意思，不提供什么操作，那怎么访问他的值呢？std::any 还提供了一个行为，std::any_cast\u0026lt;\u0026gt; 实现了 Go Fish\n1 2 3 4 5 std::any mya = 42; int i = std::any_cast\u0026lt;int\u0026gt;(mya); mya = 3.14; double d = std::any_cast\u0026lt;double\u0026gt;(mya); int j = std::any_cast\u0026lt;int\u0026gt;(mya);\t// 类型不安全，抛出异常 std::bad_any_cast 可以简单实现一个\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 #include \u0026lt;any\u0026gt; #include \u0026lt;cassert\u0026gt; #include \u0026lt;memory\u0026gt; using std::unique_ptr; struct AnyBase { virtual unique_ptr\u0026lt;AnyBase\u0026gt; clone() const = 0; virtual void *addr() = 0;\t// 返回真实数据 virtual ~AnyBase() = default; }; template\u0026lt;class T\u0026gt; struct AnyD : public AnyBase { T value_; explicit AnyD(const T\u0026amp; t) : value_(t) {} unique_ptr\u0026lt;AnyBase\u0026gt; clone() const override { return std::make_unique\u0026lt;AnyD\u0026gt;(value_); } void *addr() override { return \u0026amp;value_; } }; struct any { unique_ptr\u0026lt;AnyBase\u0026gt; p_ = nullptr; template\u0026lt;class T\u0026gt; explicit any(const T\u0026amp; t) : p_( std::make_unique\u0026lt;AnyD\u0026lt;T\u0026gt;\u0026gt;(t) ) {} any(const any\u0026amp; rhs): p_(rhs.p_-\u0026gt;clone()) {} any(any\u0026amp;\u0026amp;) noexcept = default; any\u0026amp; operator=(any rhs) { std::swap(p_, rhs.p_); return *this; } ~any() = default; }; template\u0026lt;class T\u0026gt; T any_cast(any\u0026amp; a) { AnyBase *b = a.p_.get(); // dynamic_cast 询问现在的类型是否是用户给我的类型 // 只是你可以这么实现，并不是说标准库就是这么做的 if (auto *d = dynamic_cast\u0026lt;AnyD\u0026lt;T\u0026gt;*\u0026gt;(b)) { return *(T*)a.p_-\u0026gt;addr(); } throw std::bad_any_cast(); } int main() { any mya(42); int i = any_cast\u0026lt;int\u0026gt;(mya); assert(i == 42); try { any_cast\u0026lt;double\u0026gt;(mya); } catch (const std::bad_any_cast\u0026amp;) { return 0; } assert(false); } 还有一种方法，使用 typeid，但并不一定好用\n类型擦除可以实现什么 例如 sg14::inplace_function\u0026lt;S, Capacity\u0026gt; ,跟 std::function 不同，这个东西自己保存参数，不会在堆上分配。\nshared_ptr，的deleter 存于堆上（control blocks里），deleter 就跟 function\u0026lt;void(void*)\u0026gt; 非常类似。\n如果实现一个二元运算符呢？这个是 multiple dispatch 问题，C++基本不行。\n结论 啥是类型擦除？std::function, std::any 都是利用了类型擦除. 类型擦除可以让我们 跨 ABI 边界 传递不同类型 类型擦除自己实现不是很难 列出你要提供的操作 实现一个 vtable（手动，或者使用虚函数） 初始化每个行为（在构造模板里使用 lambda，或者继承一个类模板） 复制、销毁的提供 ","date":"2024-02-23T00:00:00Z","image":"https://rossqaq.github.io/article/cppcon-2019-type-erasure/cppcon2019-cover_hu93d2f8befaf9243db44dc194e94262d5_58262_120x120_fill_box_smart1_3.png","permalink":"https://rossqaq.github.io/article/cppcon-2019-type-erasure/","title":"C++ 类型擦除是什么？"},{"content":"C++ Weekly with Jason Turner.\nC++ Weekly - Ep 108 - Understanding emplace_back\nC++ Weekly - Ep 278 - emplace_back vs push_back\n两期的总结。\n理解 emplace_back emplace_back 代表的是原地构造，直接上代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 struct S { S() {puts(\u0026#34;S()\u0026#34;);} S(const S\u0026amp;) {puts(\u0026#34;S(const S\u0026amp;)\u0026#34;);} S(S\u0026amp;\u0026amp;) {puts(\u0026#34;S(S\u0026amp;\u0026amp;)\u0026#34;);} S\u0026amp; operator=(const S\u0026amp;) {puts(\u0026#34;S(const S\u0026amp;)=\u0026#34;); return *this;} S\u0026amp; operator=(S\u0026amp;\u0026amp;) {puts(\u0026#34;S(S\u0026amp;\u0026amp;)=\u0026#34;); return *this;} ~S() {puts(\u0026#34;~S()\u0026#34;);} }; int main() { std::vector\u0026lt;S\u0026gt; vec; vec.push_back(S{}); // S() S(S\u0026amp;\u0026amp;) ~S() ~S() // 如果使用 emplace_back vec.emplace_back(); // S() ~S() } 观察更细致一些：\n1 2 3 4 5 6 7 8 9 10 struct S { S(int) {puts(\u0026#34;S(int)\u0026#34;);} ... }; int main() { std::vector\u0026lt;S\u0026gt; vec; vec.emplace_back(5); // S(int) ~S() } emplace_back vs. push_back 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; int main() { std::vector\u0026lt;std::string\u0026gt; vec; // 如果需要构造对象，就使用 emplace_back vec.emplace_back(100, \u0026#39;c\u0026#39;); // 1. 给 string 分配空间 (resize) // 2. placement new() into new space (args...) // 如果已经有对象，那么就使用 push_back vec.push_back(std::string(100, \u0026#39;c\u0026#39;)); // 1. 在栈上创建临时对象 // 2. resize vector // 3. std::move 来移动到新的位置 // vec.emplace_back(std::string(100, \u0026#39;c\u0026#39;)); // emplace_back() 的错误用法 // 先创建临时 string // 给 string 分配空间 // placement new() （移动构造） } 此外 emplace_back 是个成员函数模板\n总之，push_back(std::move(obj)) 和 emplace_back 差不多\n如果 push_back with copy 就很慢。\n","date":"2024-02-23T00:00:00Z","permalink":"https://rossqaq.github.io/article/cppweekly-emplace-back/","title":"emplace_back vs. push_back"},{"content":"Back to Basics: Iterators in C++ - Nicolai Josuttis - CppCon 2023 - YouTube\nSilides\nCppCon 2023，一期 Back to basics，讲迭代器的。感觉应该比较有用\n循环访问数组 当我们循环访问数组时，我们最初学到的是使用 index\n1 2 3 4 5 int arr[] = {10, 20, 30, 40}; for (int i = 0; i \u0026lt; 4; ++i) { std::cout \u0026lt;\u0026lt; arr[i] \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } 当然也可以通过指针\n1 2 3 4 5 // 注意 int* p = arr+4 is ok // 但此时 *p 是 ub for (int* p = arr; p \u0026lt; arr + 4; ++p) { std::cout \u0026lt;\u0026lt; *p \u0026lt;\u0026lt;\u0026#39;\\n\u0026#39;; } 迭代器是通过指针抽象而来的，\n那么我们如何通过指针访问一个数据结构呢？比如 vector，我们如何知道地址的起始和结束？\n答：通过一些成员函数，询问 vector\n1 2 3 4 std::vector\u0026lt;int\u0026gt; v {1, 2, 3, 4, 5}; for (std::vector\u0026lt;int\u0026gt;::iterator pos = v.begin(); pos \u0026lt; v.end(); ++pos) { std::cout \u0026lt;\u0026lt; *pos \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } 对于 string，也是同理。\n当然，C++11 之后可以写 auto，就没人这么写了。\n此外，这里还有一个规则half-open range，也就是说 end() 并不是一个有效的值。\n为什么这么干呢？和前面指针的例子是同理，首先我们可以表示它，只是不能访问。此外我们没有表示空的办法，但有了这个规则就可以通过 begin() == end() 表示空。\nWhy Iterator Index Operator vs. Iterator 首先考虑 vector，对于 vector 来说\n1 2 std::vector\u0026lt;int\u0026gt; v {1, 2, 3, 4, 5}; std::cout \u0026lt;\u0026lt; vec[3]; 通过 [] 访问很简单，首先是因为我们知道其中每个元素的大小，其次 vector 是内存连续的，很容易就能计算出位置。\n那么再考虑一个不连续的容器，如 list\n1 2 std::list\u0026lt;int\u0026gt; lst{1, 2, 3, 4, 5}; std::cout \u0026lt;\u0026lt; lst[3]; 这种行为开销就大一点，因为我们并不能计算，只能挨个迭代，所以标准决定不提供这种操作。\n也就是说，二者有语义上的不同，operator [] 在语义上代表直接访问，迭代器有一种我们挨个访问的感觉。\nIterator with Generic Code 所有的标准库容器迭代器 API 都提供：\nbegin(), end() 来生成迭代器 支持运算符 ++, !=, *, \u0026hellip; 所以这更方便我们写泛型代码，不管是什么数据结构都可以使用统一的接口访问容器元素。如果在 C++20 中，就可以写：\n1 2 3 4 5 void printElems(const auto\u0026amp; coll) { for (const auto\u0026amp; elem : coll) { std::cout \u0026lt;\u0026lt; elem \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } } auto 和 cbegin(), cend() 为什么会有 const 迭代器？他们不是为了 make ur life hard，是为了让你在编译器找到bug。\n为了让 auto 支持只读迭代器，我们有： const_iterator -\u0026gt; 即，迭代器访问的对象是 const 的，代表我们不想更改元素，也可以检测我们是否意外更改了元素。 cbegin(), cend(), crbegin(), crend() 不同种类的迭代器 随机访问（Random Access）迭代器\n可以直接访问另外一个位置。=,*, ++, ==, !=, \u0026ndash;, +=, -=, \u0026lt;, \u0026lt;=, \u0026hellip;[], -\nvector, array, deque, raw arrays, strings\n双向（Bidirectional）迭代器\n可以前向也可以后向迭代\n=, *, ++, ==, !=, \u0026ndash;\nlist, 关联容器 (set map \u0026hellip;)\n前向（Forward）迭代器\n只能前向迭代\n=, *, ++, ==, !=\nforward_list, unordered_map\n输入（Input）迭代器\n只能读一次元素\nistream_iterator\u0026lt;\u0026gt;\n注意只有随机迭代器才能 +=\nC++20 后，引入了 连续（Contiguous）range/迭代器\n跟随机访问迭代器一样，同样可以直接访问其他位置\n可能是裸指针， range 提供 std::ranges::data()\nvector, array, raw arrays, strings（与随机迭代器不同的是，没有 deque）\n迭代器和算法 算法提供了相同的迭代器 API，迭代器在这里作为容器和算法之间的粘合剂。\n处理 half-open 范围内的元素 使用迭代器接口 泛型 迭代器的坑 vector 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; int main() { std::vector\u0026lt;int\u0026gt; coll{1, 2, 3, 5, 8, 9, 11, 13, 17}; for (int elem : coll) { std::cout \u0026lt;\u0026lt; elem \u0026lt;\u0026lt; \u0026#39; \u0026#39;; } auto pos8 = std::find(coll.begin(), coll.end(), 8); if (pos8 != coll.end()) { std::cout \u0026lt;\u0026lt; \u0026#34;8 found\\n\u0026#34;; *pos8 *= 2; } coll.push_back(15); // 假设这里重新分配了内存，那么显然再对 pos8 访问就会 ub } transform with 4 args std::transform 做的就是读取一个范围内的数据，然后做变换，最后写入。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \u0026lt;iostream\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; int square(int val) { return val * val; } void foo() { std::list\u0026lt;int\u0026gt; src; std::vector\u0026lt;int\u0026gt; dest; // 覆盖，而不是插入 // 条件：dest.size() \u0026gt;= src.size()，否则是 ub std::transform(src.begin(), src.end(), dest.begin(), \u0026amp;square); } 输出迭代器\n指向一个元素，且不知道范围在何处结束\n类似于原始指针\n必须有元素被覆盖（需要 resize， not reacllocate）\n还有一种特殊的迭代器\nInserters 这种迭代器知道迭代的对象的信息 Insert 而不是覆盖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u0026lt;iostream\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;algorithm\u0026gt; int square(int val) { return val * val; } void foo() { std::list\u0026lt;int\u0026gt; src {1, 2, 3, 4, 5, 6}; std::vector\u0026lt;int\u0026gt; dest; std::transform(src.begin(), src.end(), dest.begin(), \u0026amp;square);\t// error std::vector\u0026lt;int\u0026gt; d2; std::transform(src.begin(), src.end(), std::back_inserter(d2), \u0026amp;square); //ok，会调用 push_back } remove 1 2 3 4 5 6 7 8 9 10 int main() { std::list\u0026lt;int\u0026gt; coll{6, 5, 4, 3, 2, 1, 1, 2, 3, 4, 5, 6}; // remove all elements with value 3 std::remove(coll.begin(), coll.end(), 3); // 会输出什么呢？ // 6, 5, 4, 2, 1, 1, 2, 4, 5, 6, 5, 6 // 3 确实没了，但是元素的个数是一样多的 } Removing 算法 不会 remove\n相反，它们会替换应该被 removed 的值，并且返回一个新的 end\n原因是迭代器是操作元素的，而不是操作容器的\n迭代器只能读、写以及移动\n所以正确的做法是，获取 std::remove 返回的 new end，然后无视剩下的值。但这样非常 C++98/11\n如果是 C++20，则可以\n1 2 3 4 5 6 7 8 9 10 int main() { std::list\u0026lt;int\u0026gt; coll{6, 5, 4, 3, 2, 1, 1, 2, 3, 4, 5, 6}; // remove all elements with value 3 auto new_end = std::remove(coll.begin(), coll.end(), 3); for (int elem : std::ranges::subrange(coll.begin(), new_end)) { std::cout \u0026lt;\u0026lt; elem \u0026lt;\u0026lt; \u0026#39; \u0026#39;; } } 如何理解range 呢？可以看之前的文章，总之 就是两个指针之间的 view，只是指向原来的数据，并不做 copy\n当然，既然有了 20，那就有更好的方式了\n1 2 3 4 5 6 7 8 9 10 int main() { std::list\u0026lt;int\u0026gt; coll{6, 5, 4, 3, 2, 1, 1, 2, 3, 4, 5, 6}; auto not3 = [](const auto\u0026amp; elem) { return elem != 3; }; for (int elem : coll | std::views::filter(\u0026amp;not3)) { std::cout \u0026lt;\u0026lt; elem \u0026lt;\u0026lt; \u0026#39; \u0026#39;; } } 对于 range，有一个重要的特性，那就是其 cache begin()\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 void print(const auto\u0026amp; elem) { for (const auto i : elem) { std::cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#39; \u0026#39;; } std::cout \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } int main() { std::vector\u0026lt;int\u0026gt; coll {1, 4, 7, 10}; print(coll); // 1 4 7 10 auto is_even = [] (auto\u0026amp;\u0026amp; i) { return i % 2 == 0; } auto coll_even = coll | std::views::filter(\u0026amp;is_even); // 增加偶数 for (int\u0026amp; i : coll_even) { i += 1; } print(coll); // 1 5 7 11 for (int\u0026amp; i : coll_even) { i += 1; } print(coll); // 1 6 7 11 // 注意，后面的11此时不是偶数，但是 range 会 cache begin()，刚才的begin 是 这个位置，他还是增加了。 // 如果修改后的值不符合谓词，那么就是 ub } 总结 迭代器\nC++ 中关键的角色，是 ranges 和算法的粘合剂 纯粹的抽象，任何表现像是迭代器的就是迭代器 有不同的种类，其有不同的能力 总体来说，他们不知道表示的范围，不知道哪里是结束，不能 insert/remove 使用迭代器时，注意 range 要有效，不要把指向不同 range 的迭代器作比较 ","date":"2024-02-20T00:00:00Z","image":"https://rossqaq.github.io/cppcon2023-cover.png","permalink":"https://rossqaq.github.io/article/cppcon-2023-iterator/","title":"C++ 中的迭代器"},{"content":"Introduction to C++ Coroutines Through a Thread Scheduling Demonstration\n这个视频简单介绍了协程，并且有 compiler view，可以方便的看出协程的行为，之后实现了一个简单的调度器，很有学习价值。\n协程的基础使用方法已经在文章 Writing custom C++20 coroutine systems 中介绍的足够详细，所以视频中关于协程基础的用法我会选择性翻译或者直接略过。\n也就是说，本文假设你已经了解了协程的基础知识，例如 Promise，Awaitable 等等\n重点摘录后半部分对于调度的讲述内容。\nWhy coroutine 视频中举了一个例子，实际上这一部分也可以参考隔壁微软 C# 的异步文档，道理是一样的。\n协程非常有用，如果你需要异步计算（例如GPU，TPU）或者做异步I/O\n没有协程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 void cpu_work() { cpu_matmul(matA, matB...); } void gpu_work() { cudaStream_t stream; cudaStreamCreate(stream); gpu_matmul\u0026lt;\u0026lt;\u0026lt;8, 256, 0\u0026gt;\u0026gt;\u0026gt;(matA, matB, ...); cudaStreamSynchronize(stream);\t// 这里同步，意味着需要等待 gpu 计算的结果 cudaStreamDestroy(stream); } // 实际上 CPU(假设CPU只有一个线程) 和 GPU 是独立的，所以完全没必要顺序执行。 int main() { cpu_work(); gpu_work(); // 或者 gpu_work(); cpu_work(); } 使用协程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 void cpu_work() { cpu_matmul(matA, matB...); } Coro gpu_work() { cudaStream_t stream; cudaStreamCreate(stream); gpu_matmul\u0026lt;\u0026lt;\u0026lt;8, 256, 0\u0026gt;\u0026gt;\u0026gt;(matA, matB, ...); while (cudaStreamQuery(stream) != cudaSuccess) { co_await std::suspend_always{}; } cudaStreamDestroy(stream); } int main() { auto coro = gpu_work(); cpu_work(); while (!coro.done()) { coro.resume(); } } Coroutine/Promise Compiler\u0026rsquo;s View 1 2 3 4 5 6 7 8 9 Coro gpu_work() { cudaStream_t stream; cudaStreamCreate(stream); gpu_matmul\u0026lt;\u0026lt;\u0026lt;8, 256, 0\u0026gt;\u0026gt;\u0026gt;(matA, matB, ...); while (cudaStreamQuery(stream) != cudaSuccess) { co_await std::suspend_always{}; } cudaStreamDestroy(stream); } ↓ Complier View\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Coro gpu_work() { Coro::promise_type p(); Coro coro_obj = p.get_return_object(); try { co_await p.initial_suspend(); cudaStream_t stream; cudaStreamCreate(stream); gpu_matmul\u0026lt;\u0026lt;\u0026lt;8, 256, 0\u0026gt;\u0026gt;\u0026gt;(matA, matB, ...); while (cudaStreamQuery(stream) != cudaSuccess) { co_await std::suspend_always{}; } cudaStreamDestroy(stream); } catch (...) { p.unhandled_exception(); } co_await p.final_suspend(); } 这就是 promise 和 coroutine 的行为。\n对于 co_await std::suspend_always{}; in Compiler View:\n1 2 3 4 5 6 7 // compiler transform auto\u0026amp;\u0026amp; awaiter = std::suspend_always{}; if (!awaiter.await_ready()) { awaiter.await_suspend(std::coroutine_handle\u0026lt;\u0026gt;...); // \u0026lt;suspend/resume\u0026gt; 协程在这里选择性的暂停 } awaiter.await_resume(); 总而言之一句话：\nPromise 控制协程的行为：initial_suspend(), final_suspend(), exception handling\u0026hellip;\nAwaitable 控制暂停点的行为\nCoroutine Handle coroutine handle 就像是指向协程的指针，你可以通过它访问 promise\n而 std::coroutine_handle\u0026lt;\u0026gt; 则是类型擦除版本，它可以代表所有协程，但也代表了你不能用它访问 promise\nCoroutine Tasks 以及 Scheduler APIs 接下来举个例子，来编写一个调度器\n单线程调度器 在编写调度器之前，我们先看看想要调度什么样的协程\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 Task TaskA(Scheduler\u0026amp; sch) { std::cout \u0026lt;\u0026lt; \u0026#34;Hello from TaskA\\n\u0026#34;; co_await sch.suspend(); std::cout \u0026lt;\u0026lt; \u0026#34;Executing the TaskA\\n\u0026#34;; co_await sch.suspend(); std::cout \u0026lt;\u0026lt; \u0026#34;TaskA finished.\\n\u0026#34;; } Task TaskB(Scheduler\u0026amp; sch) { std::cout \u0026lt;\u0026lt; \u0026#34;Hello from TaskB\\n\u0026#34;; co_await sch.suspend(); std::cout \u0026lt;\u0026lt; \u0026#34;Executing the TaskB\\n\u0026#34;; co_await sch.suspend(); std::cout \u0026lt;\u0026lt; \u0026#34;TaskB finished.\\n\u0026#34;; } // emplace: emplace a coroutine handle(task) // schedule: 调度所有 emplaced task // get_handle: 获取 coroutine handle int main() { Scheduler sch; sch.emplace(TaskA(sch).get_handle()); sch.emplace(TaskB(sch).get_handle()); std::cout \u0026lt;\u0026lt; \u0026#34;Start scheduling...\\n\u0026#34;; sch.schedule(); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 struct Task { struct promise_type { std::suspend_always initial_suspend() {return {};} std::suspend_always final_suspend() noexcept {return {};} Task get_return_object() { return std::coroutine_handle\u0026lt;promise_type\u0026gt;::from_promise(*this); } void return_void() {} void unhandled_exception() {} }; Task(std::coroutine_handle\u0026lt;promise_type\u0026gt; handle) : handle(handle) {} auto get_handle() {return handle;} std::coroutine_handle\u0026lt;promise_type\u0026gt; handle; }; 由于 initial_suspend 是 std::suspend_always ，所以在 emplace 后，只会创建协程，而并不执行。\nfinal_suspend 这里返回什么要思考一下，例如返回 suspend_never 就会很容易 ub\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class Scheduler { std::queue\u0026lt;std::coroutine_handle\u0026lt;\u0026gt;\u0026gt; tasks_; public: void emplace(std::coroutine_handle\u0026lt;\u0026gt; task) { tasks_.push(task); } void schedule() { while(!tasks_.empty()) { auto task = tasks_.front(); tasks_.pop(); task.resume(); if (!task.done()) { tasks_.push(task); } } } auto suspend() { return std::syspend_always{}; } }; 如果使用队列的话，结果会是：\n1 2 3 4 5 6 7 Start scheduling... Hello from TaskA Hello from TaskB Executing the TaskA Executing the TaskB TaskA finished TaskB finished 如果把 scheduler 的队列换成栈呢？变成了类似普通的函数\n1 2 3 4 5 6 7 Start scheduling... Hello from TaskB Executing the TaskB TaskB finished Hello from TaskA Executing the TaskA TaskA finished 多线程调度器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 Task TaskA(Scheduler\u0026amp; sch) { std::cout \u0026lt;\u0026lt; \u0026#34;Hello from TaskA\\n\u0026#34;; co_await sch.suspend(); std::cout \u0026lt;\u0026lt; \u0026#34;Executing the TaskA\\n\u0026#34;; co_await sch.suspend(); std::cout \u0026lt;\u0026lt; \u0026#34;TaskA finished.\\n\u0026#34;; } Task TaskB(Scheduler\u0026amp; sch) { std::cout \u0026lt;\u0026lt; \u0026#34;Hello from TaskB\\n\u0026#34;; co_await sch.suspend(); std::cout \u0026lt;\u0026lt; \u0026#34;Executing the TaskB\\n\u0026#34;; co_await sch.suspend(); std::cout \u0026lt;\u0026lt; \u0026#34;TaskB finished.\\n\u0026#34;; } // emplace: emplace a coroutine handle(task) // schedule: 调度所有 emplaced task // get_handle: 获取 coroutine handle int main() { Scheduler sch; sch.emplace(TaskA(sch).get_handle()); sch.emplace(TaskB(sch).get_handle()); std::cout \u0026lt;\u0026lt; \u0026#34;Start scheduling...\\n\u0026#34;; sch.schedule(); sch.wait(); } 执行的代码大多数没有任何区别，区别在于 Scheduler 的实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 class Scheduler { public: Scheduler(size_t num_threads); void emplace(std::coroutine_handle\u0026lt;\u0026gt; task); auto suspend(); void schedule(); void wait(); private: void enqueue(std::coroutine_handle\u0026lt;\u0026gt; task);\t// 插入任务准备执行 void process(std::coroutine_handle\u0026lt;\u0026gt; task);\t// 恢复任务 std::vector \u0026lt;std::coroutine_handle\u0026lt;\u0026gt;\u0026gt; tasks_;\t// 存储所有的任务 std::queue\u0026lt;std::coroutine_handle\u0026lt;\u0026gt;\u0026gt; pending_tasks_;\t// 存储可以被恢复的任务 std::vector\u0026lt;std::thread\u0026gt; workers_;\t// 存储所有线程 std::mutex mtx_; std::condition_variable cv_;\t// block/unblock 现成 bool stop_{false};\t// 让所有线程返回 std::atomic\u0026lt;size_t\u0026gt; finished_{};\t// 记录完成的任务 }; Scheduler::Scheduler(size_t num_threads) { workers_.reserve(num_threads); for (size_t t = 0; t \u0026lt; num_threads; ++t) { workers_.emplace_back([this]() { while(true) { // 这里跟普通的调度器唯一的区别就是，std::function\u0026lt;void()\u0026gt; 变成了 std::coroutine_handle\u0026lt;\u0026gt; std::coroutine_handle\u0026lt;\u0026gt; task; { std::unique_lock lock(mtx_); // 如果谓词为 true，那么就不阻塞。 cv_.wait(lock, [this]{ return stop_ || (!pending_tasks_.empty()); }); } // 先检查 stop_，如果其为真，那意味着所有的任务执行完毕。 if (stop_) return; task = pending_tasks.front(); pending_tasks.pop(); if (task) { process_(task); } } }); } } // 恢复任务 // 如果任务没有完成，就把它添加到 等待队列 // 如果任务完成，就增加 finished_，并检查是否所有任务已经完成 void Scheduler::process_(std::coroutine_handle\u0026lt;\u0026gt; task) { task.resume(); if (!task.done()) { enqueue(task); } else { if (finished.fetch_add(1) + 1 == tasks_.size()) { std::unique_lock lock(mtx_); stop_ = true; } cv_.notify_all(); } } void Scheduler::enqueue(std::coroutine_handle\u0026lt;\u0026gt; task) { { std::unique_lock lock(mtx_); pending_tasks_.push(task); } cv_.notify_one(); } void Scheduler::emplace(std::coroutine_handle\u0026lt;\u0026gt; task) { tasks_.emplace_back(task); } void Scheduler::schedule() { for (auto task : tasks_) { enqueue(task); } } void Scheduler::wait() { for(auto\u0026amp; w : workers_) { w.join(); } } 代码实现还可以，不是特别难。\n接下来的部分是 CPU-GPU 的调度器，这个比较难，对我个人来说也不涉及，所以暂时不翻译。\n","date":"2024-02-16T00:00:00Z","permalink":"https://rossqaq.github.io/article/coro-schedule/","title":"C++ 协程，以及其调度"},{"content":"本文是文章 io_uring by example: Part 2 – Queuing multiple requests 的翻译与总结。\n同样只摘录重要的部分。\n这一篇文章使用 liburing 来构造类似于 cp 命令的程序，但区别于 P1，由于 P1 的重点在于理解 io_uring 本身，所以并没有用上很多特性。\n简介 在 P1 中，我们构建了一个 cat 程序。但我们的例子中，一次只提交了一个 request。而 io_uring 的使命就是减少 syscall 的次数，办法是让用户向队列中一次尽可能多地提交 request，然后内核可以一次性全部处理，就不用用户对每个 io request 都调用一次 syscall了。\n这一部分，我们实现一个复制文件的程序。它一次尽可能多地提交请求（在队列长度限制内）。To give credit where it is due, this is heavily based on a program from the fio package.\ncp_liburing 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 #include \u0026lt;asm-generic/errno-base.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; #include \u0026lt;sys/ioctl.h\u0026gt; #include \u0026lt;liburing.h\u0026gt; #define QD 2 #define BS (16 * 1024) static int infd, outfd; struct io_data { int read; off_t first_offset, offset; size_t first_len; struct iovec iov; }; static int setup_context(unsigned entries, struct io_uring* ring) { int ret; ret = io_uring_queue_init(entries, ring, 0); if (ret \u0026lt; 0) { fprintf(stderr, \u0026#34;queue_init: %s\\n\u0026#34;, strerror(-ret)); return -1; } return 0; } static int get_file_size(int fd, off_t* size) { struct stat st; if (fstat(fd, \u0026amp;st) \u0026lt; 0 ) return -1; if(S_ISREG(st.st_mode)) { *size = st.st_size; return 0; } else if (S_ISBLK(st.st_mode)) { unsigned long long bytes; if (ioctl(fd, BLKGETSIZE64, \u0026amp;bytes) != 0) return -1; *size = bytes; return 0; } return -1; } static void queue_prepped(struct io_uring* ring, struct io_data* data) { struct io_uring_sqe* sqe; sqe = io_uring_get_sqe(ring); assert(sqe); if (data-\u0026gt;read) { io_uring_prep_readv(sqe, infd, \u0026amp;data-\u0026gt;iov, 1, data-\u0026gt;offset); } else { io_uring_prep_writev(sqe, outfd, \u0026amp;data-\u0026gt;iov, 1, data-\u0026gt;offset); } io_uring_sqe_set_data(sqe, data); } static int queue_read(struct io_uring* ring, off_t size, off_t offset) { struct io_uring_sqe* sqe; struct io_data* data; data = malloc(size + sizeof(*data)); if (!data) { return -1; } sqe = io_uring_get_sqe(ring); if (!sqe) { free(data); return 1; } data-\u0026gt;read = 1; data-\u0026gt;offset = data-\u0026gt;first_offset = offset; data-\u0026gt;iov.iov_base = data + 1; data-\u0026gt;iov.iov_len = size; data-\u0026gt;first_len = size; io_uring_prep_readv(sqe, infd, \u0026amp;data-\u0026gt;iov, 1, offset); io_uring_sqe_set_data(sqe, data); return 0; } static void queue_write(struct io_uring* ring, struct io_data* data) { data-\u0026gt;read = 0; data-\u0026gt;offset = data-\u0026gt;first_offset; data-\u0026gt;iov.iov_base = data + 1; data-\u0026gt;iov.iov_len = data-\u0026gt;first_len; queue_prepped(ring, data); io_uring_submit(ring); } int copy_file(struct io_uring* ring, off_t insize) { unsigned long reads, writes; struct io_uring_cqe* cqe; off_t write_left, offset; int ret; write_left = insize; writes = reads = offset = 0; while (insize || write_left) { int had_reads, got_comp; /* 尽可能多地提交读操作 */ while (insize) { off_t this_size = insize; if (reads + writes \u0026gt;= QD) { break; } if (this_size \u0026gt; BS) { this_size = BS; } else if (!this_size) { break; } if (queue_read(ring, this_size, offset)) { break; } insize -= this_size; offset += this_size; reads++; } if (had_reads != reads) { ret = io_uring_submit(ring); if (ret \u0026lt; 0) { fprintf(stderr, \u0026#34;io_uring_submit: %s\\n\u0026#34;, strerror(-ret)); break; } } /* 此时队列已经满了，我们需要找到至少一个 completion */ got_comp = 0; while (write_left) { struct io_data* data; if (!got_comp) { ret = io_uring_wait_cqe(ring, \u0026amp;cqe); got_comp = 1; } else { ret = io_uring_peek_cqe(ring, \u0026amp;cqe); if (ret == -EAGAIN) { cqe = NULL; ret = 0; } } if (ret \u0026lt; 0) { fprintf(stderr, \u0026#34;io_uring_peek_cqe: %s\\n\u0026#34;, strerror(-ret)); return 1; } if (!cqe) { break; } data = io_uring_cqe_get_data(cqe); if (cqe-\u0026gt;res \u0026lt; 0) { if (cqe-\u0026gt;res == -EAGAIN) { queue_prepped(ring, data); io_uring_cqe_seen(ring, cqe); continue; } fprintf(stderr, \u0026#34;cqe failed: %s\\n\u0026#34;, strerror(-cqe-\u0026gt;res)); return 1; } else if (cqe-\u0026gt;res != data-\u0026gt;iov.iov_len) { /* short read/write; adjust and requeue */ // ? 没看懂 data-\u0026gt;iov.iov_base += cqe-\u0026gt;res; data-\u0026gt;iov.iov_len -= cqe-\u0026gt;res; queue_prepped(ring, data); io_uring_cqe_seen(ring, cqe); continue; } /** * 完成。如果写，不需要做什么了，如果读，就提交对应的写 */ if (data-\u0026gt;read) { queue_write(ring, data); write_left -= data-\u0026gt;first_len; reads--; writes++; } else { free(data); writes--; } io_uring_cqe_seen(ring, cqe); } } return 0; } int main(int argc, char *argv[]) { struct io_uring ring; off_t insize; int ret; if (argc \u0026lt; 3) { printf(\u0026#34;Usage: %s \u0026lt;infile\u0026gt; \u0026lt;outfile\u0026gt;\\n\u0026#34;, argv[0]); return 1; } infd = open(argv[1], O_RDONLY); if (infd \u0026lt; 0) { perror(\u0026#34;open infile\u0026#34;); return 1; } outfd = open(argv[2], O_WRONLY | O_CREAT | O_TRUNC, 0644); if (outfd \u0026lt; 0) { perror(\u0026#34;open outfile\u0026#34;); return 1; } if (setup_context(QD, \u0026amp;ring)) { return 1; } if (get_file_size(infd, \u0026amp;insize)) { return 1; } ret = copy_file(\u0026amp;ring, insize); close(infd); close(outfd); io_uring_queue_exit(\u0026amp;ring); return ret; } 程序结构 该程序和普通的 cp 一样。\n程序的核心是 copy_file() 函数。这里，我们外层的 while 循环内包含了两个 while 循环。\n外层的 while 循环保证源文件中的字节都被拷贝了，第一个嵌套的 while 循环的任务是尽可能多的创建 readv 请求，实际上，它会创建队列长度允许的数量的请求。\n一旦队列满了，我们就来到第二个 while 循环。这个循环获取 SQE 并且提交写文件的请求，现在 data 已经读完了。\n有很多跟踪状态的变量，看起来有一些迷惑。但一个异步 copying 的程序能有多难呢？\n意思是不想解释了让读者自己看。还行，多看几遍基本能理解整体逻辑。学习 io_uring 还是为了网络编程，所以这里我就大概只理清了逻辑。\n下一步？ 现在我们知道了如何一次性多的使用 io_uring 提交请求。下一次我们进行一些网络编程。我们会简单的建一个 web server，从头开始使用 io_uring 完成所有 IO。\nAbout me My name is Shuveb Hussain and I’m the author of this Linux-focused blog. You can follow me on Twitter where I post tech-related content mostly focusing on Linux, performance, scalability and cloud technologies.\n","date":"2024-02-16T00:00:00Z","permalink":"https://rossqaq.github.io/article/io_uring-cp/","title":"io_uring P2 - 实现 cp"},{"content":"Lecture: Return Value Optimization: Harder Than It Looks - Arthur O\u0026rsquo;Dwyer - CppCon 2018\nSlides PDF\nC++17 开始标准强制要求复制消除，这也是 C++17 最重要的特性之一。\n来看看 返回值优化，即 RVO 吧。\n主讲依然是 Arthur O\u0026rsquo;Dwyer。\nreturn slot 对于 x86，单纯返回个 int 会存放在 %eax 中。\n那么如果我们返回一个比较大的对象呢？例如一个结构体，总不能把结构体塞到 %eax\n这时 caller 会提前分配好 stack 空间供其调用的函数的返回值填充，这也就是所谓的 \u0026ldquo;return slot\u0026rdquo;\n可能遇到的情况是，你需要将返回值 move 到 return slot\n例如下面的情况，在你调用函数之前并不知道该返回哪个，只能在返回的时候进行判断再“移动”（在返回时将其复制 到 return slot）\n1 2 3 4 5 6 7 8 9 10 struct Fruit { int data[5]; Fruit(Fruit\u0026amp;\u0026amp;) }; Fruit apples_and_oranges(bool condition) { Fruit x = ...; Fruit y = ...; return std::move(condition ? x : y); } 但如果他是一个只返回 x 的 nothing_but_apples() ：\n1 2 3 4 5 6 7 8 struct Fruit { int data[5]; }; Fruit nothing_but_apples() { Fruit x = ...; return x; } 那么标准允许将 x 与 return slot 整合，现在我们就完全不需要拷贝了。\n复制消除 在 C++17 之后，复制消除在一些场合下是强制的。以前的标准并不强制。\n当然，也有复制消除不能应用的场景，例如之前的 apples_and_oranges()，我们并不知道要返回哪个对象。\n自然，也有一些其他的情景，比如以下的例子\n返回值是参数的情况 1 2 3 Fruit apples_to_apples(int i, Fruit x, int j) { return x; } 这种情况，x 自然被分配在一个位置，而 caller 自然也给 return slot 分配了另外一个位置，这种情况下自然不能消除复制，因为我们没有实际 x 的位置。\n返回值是全局变量 1 2 3 4 static Fruit x; Fruit apples_to_apples() { return x; } 现在 x 是全局变量，显然更不能复制消除了。\n切片为基类 举个例子，榴莲也是水果，所以是 Is-A 的关系\n1 2 3 4 5 6 7 8 struct Durian : Fruit { double smell; } Fruit slapchop() { Durian x = ...; return x; } 上面的情形中，我们创建了一个 Durian，但返回的是 Fruit，二者占用的内存大小并不相同。\n如果把榴莲返回的话，就会被 slice。\n这种情况下自然不能复制消除，我们不能在先分配的 return slot 中直接分配 x，因为 x 比 return slot 大（return slot 是按照 Fruit 的大小分配的）。\nRules of thumb for RVO 以下是两条常见的 RVO 规则：\nUnnamed RVO (URVO) : 返回 xvalue/prvalue 会触发复制消除；（常见的例如函数调用是纯右值，临时对象是亡值） Named RVO (NRVO) : 除了我们上面举的例子，假设 x 是 local 具名变量，那么返回时也会触发复制消除。 如果没有发生 复制消除的话，那么编译器会 隐式 选择移动 实际上似乎标准中提到的 RVO 指的是 URVO，保证的也是 URVO。可以自行参考 Copy elision\n此外，类成员变量 不是 隐式可移动对象，想想也很正常，不然调用个成员函数直接就把数据清空了。\n关于 隐式移动：\n返回一个不会触发 RVO 的具名 local 变量，编译器重载决议会自动将 x 当成 亡值 处理\n1 2 3 std::string identity(std::string x) { return x;\t// 自动触发移动，不会被复制 } 因为 C++11 的隐式移动，你写 return std::move(x) 是纯负优化，因为会强制编译器移动它，编译器就没法触发 NRVO 了。\n其他 后面还有一堆看起来非常复杂的内容和规则，因为时间不够还跳过了一部分。\n总结起来就是，为了避免切片，以及可以重载决议到 move\n1 2 3 4 std::unique_ptr\u0026lt;ConfigManager\u0026gt; create() { auto p = std::make_unique\u0026lt;ConfigManagerImpl\u0026gt;(); return p; } 对于这种类型，一定要多实现 explicit ctor(typename\u0026amp;\u0026amp;) 的版本\n标准库的这些组件都是这么做的。\n还有一些额外内容，建议有能力的看原视频。\n","date":"2024-02-16T00:00:00Z","image":"https://rossqaq.github.io/article/cppcon-2018-rvo/cppcon2018-cover_hudd6b3ea997d6103f1599388b87fbea47_60224_120x120_fill_box_smart1_3.png","permalink":"https://rossqaq.github.io/article/cppcon-2018-rvo/","title":"返回值优化"},{"content":"本文是文章 io_uring by example: Part 1 – Introduction 的翻译与总结。\n原文比较长，故只摘录重要部分。\n学习 Linux 新异步 I/O API io_uring 的使用，以及与传统同步 API 的异同，并接触更高级更方便的 liburing 库。\n一切都从实现一个 cat 程序开始。\n介绍 Linux 原生提供了同步I/O 和 异步 I/O（aio） 两种 API，同步 IO 就是熟悉的阻塞 IO，而异步 IO 的 aio 则只能支持直接 IO，buffered IO 并不能异步，这就是问题所在。\nio_uring 的诞生就是为了解决 Linux 内核没有异步 IO 的问题。\nio_uring 不仅提供了优雅的 kernel/user 接口，还提供了一些提高性能的方式（特殊的 polling mode）来避免数据跨越 kernel/user 空间时的系统调用。\nio_uring 提供了更高级封装后的 liburing，隐藏了很多实现细节，但如果不理解底层 api 只用 liburing 那有什么意思呢？后面的例子都会使用 liburing，但我们先从底层的 API 开始实现。\n普通的 cat 我们实现一个简单的 cat 指令， 通过使用 syscall readv()，它是阻塞同步 I/O 方式。你需要熟悉一下 readv 是怎么工作的。readv 称之为 vectored I/O。\nread 和 write 的参数是 fd， buffer，长度；而 readv 和 writev 的参数是 fd，指向 struct iovec 的结构体指针。\niovec 结构体如下：\n1 2 3 4 struct iovec { void* iov_base; size_t iov_len; }; 对比常规的 read/write 有什么区别呢？readv/writev 的使用更加符合直觉，你可以填充结构体的多个数据成员然后一次 syscall 读完；此外 readv/writev 是原子的。\n我们的 cat 例子中，我们会使用 readv 读取文件然后打印到控制台。我们会一个 chunk 一个 chunk 的读取，每个都会使用 iovec 指向。readv 会在完成时阻塞，假设没有错误，struct iovec 指向一系列的存储 file 内容的 buffer。之后再打印。很简单。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 #include \u0026lt;bits/types/struct_iovec.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;sys/uio.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; #include \u0026lt;linux/fs.h\u0026gt; #include \u0026lt;sys/ioctl.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #define BLOCK_SZ 4096 /** * 返回传入的 fd 大小。可以处理常规文件和硬件驱动。 */ off_t get_file_size(int fd) { struct stat st; if (fstat(fd, \u0026amp;st) \u0026lt; 0) { perror(\u0026#34;fstat\u0026#34;); return -1; } if (S_ISBLK(st.st_mode)) { unsigned long long bytes; if (ioctl(fd, BLKGETSIZE64, \u0026amp;bytes) != 0) { perror(\u0026#34;ioctl\u0026#34;); return -1; } return bytes; } else if (S_ISREG(st.st_mode)) { return st.st_size; } return -1; } /** * 向 stdout 输出长度为 len 的字符串。 * 我们使用 buffered 输出提高效率。 * 因此我们需要一个一个的输出字符。 */ void output_to_console(char* buf, int len) { while (len--) { fputc(*buf++, stdout); } } int read_and_print_file(char* file_name) { struct iovec* iovecs; int fd = open(file_name, O_RDONLY); if (fd \u0026lt; 0) { perror(\u0026#34;open\u0026#34;); return 1; } off_t file_sz = get_file_size(fd); off_t bytes_remaining = file_sz; int blocks = (int) file_sz / BLOCK_SZ; if (file_sz % BLOCK_SZ) blocks++; iovecs = malloc(sizeof(struct iovec) * blocks); int cur_blk = 0; /** * 对于我们要读的文件，先分配足够的空间存放数据。 * 每个块都被描述为一个 iovec 结构， * 被传递给 readv 作为 iovecs 数组的一部分 */ while (bytes_remaining) { off_t bytes_to_read = bytes_remaining; if (bytes_to_read \u0026gt; BLOCK_SZ) { bytes_to_read = BLOCK_SZ; } void *buf; if (posix_memalign(\u0026amp;buf, BLOCK_SZ, BLOCK_SZ)) { perror(\u0026#34;posix_memalign\u0026#34;); return 1; } iovecs[cur_blk].iov_base = buf; iovecs[cur_blk].iov_len = bytes_to_read; cur_blk++; bytes_remaining -= bytes_to_read; } /** * readv() 调用会阻塞，直到 iovecs 读满。 * 当他返回时，我们就可以访问读取的数据了 */ int ret = readv(fd, iovecs, blocks); if (ret \u0026lt; 0) { perror(\u0026#34;readv\u0026#34;); return 1; } for (int i = 0; i \u0026lt; blocks; ++i) { output_to_console(iovecs[i].iov_base, iovecs[i].iov_len); } return 0; } int main(int argc, char *argv[]) { if (argc \u0026lt; 2) { fprintf(stderr, \u0026#34;Usage: %s \u0026lt;filename1\u0026gt; [\u0026lt;filename2\u0026gt;...]\\n\u0026#34;, argv[0]); return 1; } /** * 对于每个传入的文件都调用 read_and_print_file() 函数 */ for (int i = 1; i \u0026lt; argc; ++i) { if (read_and_print_file(argv[i])) { fprintf(stderr, \u0026#34;Error reading file\\n\u0026#34;); return 1; } } return 0; } 以上代码很简单，之后我们会把他和 io_uring 的版本对比。\n它的核心在于一个循环先计算我们要读的文件需要多少块 blocks 来存储数据。分配所有 iovec 的内存。之后迭代，分配 block-sized 内存来存储实际的数据，最后调用 readv。就像我们之前说的，readv 是同步的，意味着在完成前会一直阻塞。当它返回时，数据已经读取好了。我们就可以输出到控制台了。\nCat uring 我们赶紧来实现 io_uring 的版本，在 io_uring 中使用的操作会是 readv。\nio_uring 接口 io_uring 接口很简单。有一个 submission queue 和一个 completion queue。\n在 submission queue 中，你提交你想要执行的操作信息。\n例如，对于这个程序，我们想要使用 readv() 读取文件，所以我们布置一个描述它的 submission queue request 作为 submission queue entry（SQE）的一部分。因为它是队列，所以你可以放置多个请求，只要队列的长度允许（你可以自己定义）即可。执行的操作可以是 reads, writes 等等。之后我们调用 io_uring_enter() syscall 来告诉内核，我们向 submission queue 添加了一个操作。\n内核完成请求后，会将结果放置在 completion queue 作为 CQE，或者说 a completion queue entry one for each corresponding SQE. (? 实在没看懂这句怎么翻译)\nCQEs 可以在用户态下访问。\n精明的读者会发现，这个接口会先装满队列再使用一次 syscall 而不是对于每个 IO 请求都调用一次 syscall，已经提升了效率。为更高的效率，io_uring 提供一种内核持续轮询（polls）的模式来检测是否有提交项，而不需要调用 io_uring_enter() 来通知内核。\n在做这些之前，你需要 setup 队列，也就是拥有固定长度的环形缓冲区。你可以使用 io_uring_setup() 来完成。我们要做的工作是通过向环形缓冲区中添加 submission queue entries 并且从从 completion queue 环形缓冲区中读取 completion queue entries。这就是 io_uring 的设计总览。\nCompletion Queue Entry 现在我们脑子里已经知道他是怎么工作的了，我们来看看实现细节。跟 submission queue entry (SQE) 比起来，completion queue entry (CQE) 非常简单。SQE 是你用来提交请求的结构体，你要把他提交给环形缓冲区。CQE 是内核对于每个添加到 submission queue 的 SQE 结构体的响应结构体。他包括了你通过 SQE 实例请求的操作的结果。\n1 2 3 4 5 struct io_uring_cqe { __u64 user_data; /* sqe-\u0026gt;user_data submission passed back */ __s32 res; /* result code for this event */ __u32 flags; }; user_data field 是按原样从 SQE 传递到 CQE 实例的内容。假设你传递了一堆操作给 submission queue，它们的完成顺序与到达 completion queue 的顺序是不重要的。因为底层的 IO 速度可能不同。总之，CQEs 可以以任何顺序进入 completion queue ，只要它们完成了，那么就会立刻进入 completion queue。那么如何识别 SQE 对应的 CQE 呢？之后会有详细解释。\nCQE 很简单，因为它只关心它的 syscall 的返回值，存储在 res 字段中。例如，如果你提交一个 读 操作，那么完成后，他就会包含读取的字节数。如果有错误，它就会包含 -errno。就像 read() 本身的行为一样。\nOrdering 虽然 CQEs 确实不是按顺序返回，但你也可以强制其按 SQE 的顺序返回，具体看 canonical io_uring reference\nSubmission Queue Entry submission queue 更加复杂，因为他要保证兼容如今 linux 能做的所有 IO 操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 struct io_uring_sqe { __u8 opcode; /* type of operation for this sqe */ __u8 flags; /* IOSQE_ flags */ __u16 ioprio; /* ioprio for the request */ __s32 fd; /* file descriptor to do IO on */ __u64 off; /* offset into file */ __u64 addr; /* pointer to buffer or iovecs */ __u32 len; /* buffer size or number of iovecs */ union { __kernel_rwf_t rw_flags; __u32 fsync_flags; __u16 poll_events; __u32 sync_range_flags; __u32 msg_flags; }; __u64 user_data; /* data to be passed back at completion time */ union { __u16 buf_index; /* index into fixed buffers, if used */ __u64 __pad2[3]; }; }; 结构体看上去很复杂，但实际上常用的不多。我们通过 cat 和使用 readv() 来理解他。\nopcode 指定 I/O 操作，我们的情况中，readv() 使用 IORING_OP_READV\nfd，文件描述符\naddr，指向我们定义的 iovecs 结构，存储了我们为了 I/O 分配的 buffer 和长度\n最后 len 是 iovecs 数组的大小\n现在感觉不是很难了，我们可以一次入队多个 SQEs 然后一次 syscall 全部解决。\nio_uring 版本的 cat 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; #include \u0026lt;sys/ioctl.h\u0026gt; #include \u0026lt;sys/syscall.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #include \u0026lt;sys/uio.h\u0026gt; #include \u0026lt;linux/fs.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;string.h\u0026gt; /* If your compilation fails because the header file below is missing, * your kernel is probably too old to support io_uring. * */ #include \u0026lt;linux/io_uring.h\u0026gt; #define QUEUE_DEPTH 1 #define BLOCK_SZ 1024 /* This is x86 specific */ #define read_barrier() __asm__ __volatile__(\u0026#34;\u0026#34;:::\u0026#34;memory\u0026#34;) #define write_barrier() __asm__ __volatile__(\u0026#34;\u0026#34;:::\u0026#34;memory\u0026#34;) struct app_io_sq_ring { unsigned *head; unsigned *tail; unsigned *ring_mask; unsigned *ring_entries; unsigned *flags; unsigned *array; }; struct app_io_cq_ring { unsigned *head; unsigned *tail; unsigned *ring_mask; unsigned *ring_entries; struct io_uring_cqe *cqes; }; struct submitter { int ring_fd; struct app_io_sq_ring sq_ring; struct io_uring_sqe *sqes; struct app_io_cq_ring cq_ring; }; struct file_info { off_t file_sz; struct iovec iovecs[]; /* Referred by readv/writev */ }; /* * This code is written in the days when io_uring-related system calls are not * part of standard C libraries. So, we roll our own system call wrapper * functions. * */ int io_uring_setup(unsigned entries, struct io_uring_params *p) { return (int) syscall(__NR_io_uring_setup, entries, p); } int io_uring_enter(int ring_fd, unsigned int to_submit, unsigned int min_complete, unsigned int flags) { return (int) syscall(__NR_io_uring_enter, ring_fd, to_submit, min_complete, flags, NULL, 0); } /* * Returns the size of the file whose open file descriptor is passed in. * Properly handles regular file and block devices as well. Pretty. * */ off_t get_file_size(int fd) { struct stat st; if(fstat(fd, \u0026amp;st) \u0026lt; 0) { perror(\u0026#34;fstat\u0026#34;); return -1; } if (S_ISBLK(st.st_mode)) { unsigned long long bytes; if (ioctl(fd, BLKGETSIZE64, \u0026amp;bytes) != 0) { perror(\u0026#34;ioctl\u0026#34;); return -1; } return bytes; } else if (S_ISREG(st.st_mode)) return st.st_size; return -1; } /* * io_uring requires a lot of setup which looks pretty hairy, but isn\u0026#39;t all * that difficult to understand. Because of all this boilerplate code, * io_uring\u0026#39;s author has created liburing, which is relatively easy to use. * However, you should take your time and understand this code. It is always * good to know how it all works underneath. Apart from bragging rights, * it does offer you a certain strange geeky peace. * */ int app_setup_uring(struct submitter *s) { struct app_io_sq_ring *sring = \u0026amp;s-\u0026gt;sq_ring; struct app_io_cq_ring *cring = \u0026amp;s-\u0026gt;cq_ring; struct io_uring_params p; void *sq_ptr, *cq_ptr; /* * We need to pass in the io_uring_params structure to the io_uring_setup() * call zeroed out. We could set any flags if we need to, but for this * example, we don\u0026#39;t. * */ memset(\u0026amp;p, 0, sizeof(p)); s-\u0026gt;ring_fd = io_uring_setup(QUEUE_DEPTH, \u0026amp;p); if (s-\u0026gt;ring_fd \u0026lt; 0) { perror(\u0026#34;io_uring_setup\u0026#34;); return 1; } /* * io_uring communication happens via 2 shared kernel-user space ring buffers, * which can be jointly mapped with a single mmap() call in recent kernels. * While the completion queue is directly manipulated, the submission queue * has an indirection array in between. We map that in as well. * */ int sring_sz = p.sq_off.array + p.sq_entries * sizeof(unsigned); int cring_sz = p.cq_off.cqes + p.cq_entries * sizeof(struct io_uring_cqe); /* In kernel version 5.4 and above, it is possible to map the submission and * completion buffers with a single mmap() call. Rather than check for kernel * versions, the recommended way is to just check the features field of the * io_uring_params structure, which is a bit mask. If the * IORING_FEAT_SINGLE_MMAP is set, then we can do away with the second mmap() * call to map the completion ring. * */ if (p.features \u0026amp; IORING_FEAT_SINGLE_MMAP) { if (cring_sz \u0026gt; sring_sz) { sring_sz = cring_sz; } cring_sz = sring_sz; } /* Map in the submission and completion queue ring buffers. * Older kernels only map in the submission queue, though. * */ sq_ptr = mmap(0, sring_sz, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE, s-\u0026gt;ring_fd, IORING_OFF_SQ_RING); if (sq_ptr == MAP_FAILED) { perror(\u0026#34;mmap\u0026#34;); return 1; } if (p.features \u0026amp; IORING_FEAT_SINGLE_MMAP) { cq_ptr = sq_ptr; } else { /* Map in the completion queue ring buffer in older kernels separately */ cq_ptr = mmap(0, cring_sz, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE, s-\u0026gt;ring_fd, IORING_OFF_CQ_RING); if (cq_ptr == MAP_FAILED) { perror(\u0026#34;mmap\u0026#34;); return 1; } } /* Save useful fields in a global app_io_sq_ring struct for later * easy reference */ sring-\u0026gt;head = sq_ptr + p.sq_off.head; sring-\u0026gt;tail = sq_ptr + p.sq_off.tail; sring-\u0026gt;ring_mask = sq_ptr + p.sq_off.ring_mask; sring-\u0026gt;ring_entries = sq_ptr + p.sq_off.ring_entries; sring-\u0026gt;flags = sq_ptr + p.sq_off.flags; sring-\u0026gt;array = sq_ptr + p.sq_off.array; /* Map in the submission queue entries array */ s-\u0026gt;sqes = mmap(0, p.sq_entries * sizeof(struct io_uring_sqe), PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE, s-\u0026gt;ring_fd, IORING_OFF_SQES); if (s-\u0026gt;sqes == MAP_FAILED) { perror(\u0026#34;mmap\u0026#34;); return 1; } /* Save useful fields in a global app_io_cq_ring struct for later * easy reference */ cring-\u0026gt;head = cq_ptr + p.cq_off.head; cring-\u0026gt;tail = cq_ptr + p.cq_off.tail; cring-\u0026gt;ring_mask = cq_ptr + p.cq_off.ring_mask; cring-\u0026gt;ring_entries = cq_ptr + p.cq_off.ring_entries; cring-\u0026gt;cqes = cq_ptr + p.cq_off.cqes; return 0; } /* * Output a string of characters of len length to stdout. * We use buffered output here to be efficient, * since we need to output character-by-character. * */ void output_to_console(char *buf, int len) { while (len--) { fputc(*buf++, stdout); } } /* * Read from completion queue. * In this function, we read completion events from the completion queue, get * the data buffer that will have the file data and print it to the console. * */ void read_from_cq(struct submitter *s) { struct file_info *fi; struct app_io_cq_ring *cring = \u0026amp;s-\u0026gt;cq_ring; struct io_uring_cqe *cqe; unsigned head, reaped = 0; head = *cring-\u0026gt;head; do { read_barrier(); /* * Remember, this is a ring buffer. If head == tail, it means that the * buffer is empty. * */ if (head == *cring-\u0026gt;tail) break; /* Get the entry */ cqe = \u0026amp;cring-\u0026gt;cqes[head \u0026amp; *s-\u0026gt;cq_ring.ring_mask]; fi = (struct file_info*) cqe-\u0026gt;user_data; if (cqe-\u0026gt;res \u0026lt; 0) fprintf(stderr, \u0026#34;Error: %s\\n\u0026#34;, strerror(abs(cqe-\u0026gt;res))); int blocks = (int) fi-\u0026gt;file_sz / BLOCK_SZ; if (fi-\u0026gt;file_sz % BLOCK_SZ) blocks++; for (int i = 0; i \u0026lt; blocks; i++) output_to_console(fi-\u0026gt;iovecs[i].iov_base, fi-\u0026gt;iovecs[i].iov_len); head++; } while (1); *cring-\u0026gt;head = head; write_barrier(); } /* * Submit to submission queue. * In this function, we submit requests to the submission queue. You can submit * many types of requests. Ours is going to be the readv() request, which we * specify via IORING_OP_READV. * * */ int submit_to_sq(char *file_path, struct submitter *s) { struct file_info *fi; int file_fd = open(file_path, O_RDONLY); if (file_fd \u0026lt; 0 ) { perror(\u0026#34;open\u0026#34;); return 1; } struct app_io_sq_ring *sring = \u0026amp;s-\u0026gt;sq_ring; unsigned index = 0, current_block = 0, tail = 0, next_tail = 0; off_t file_sz = get_file_size(file_fd); if (file_sz \u0026lt; 0) return 1; off_t bytes_remaining = file_sz; int blocks = (int) file_sz / BLOCK_SZ; if (file_sz % BLOCK_SZ) blocks++; fi = malloc(sizeof(*fi) + sizeof(struct iovec) * blocks); if (!fi) { fprintf(stderr, \u0026#34;Unable to allocate memory\\n\u0026#34;); return 1; } fi-\u0026gt;file_sz = file_sz; /* * For each block of the file we need to read, we allocate an iovec struct * which is indexed into the iovecs array. This array is passed in as part * of the submission. If you don\u0026#39;t understand this, then you need to look * up how the readv() and writev() system calls work. * */ while (bytes_remaining) { off_t bytes_to_read = bytes_remaining; if (bytes_to_read \u0026gt; BLOCK_SZ) bytes_to_read = BLOCK_SZ; fi-\u0026gt;iovecs[current_block].iov_len = bytes_to_read; void *buf; if( posix_memalign(\u0026amp;buf, BLOCK_SZ, BLOCK_SZ)) { perror(\u0026#34;posix_memalign\u0026#34;); return 1; } fi-\u0026gt;iovecs[current_block].iov_base = buf; current_block++; bytes_remaining -= bytes_to_read; } /* Add our submission queue entry to the tail of the SQE ring buffer */ next_tail = tail = *sring-\u0026gt;tail; next_tail++; read_barrier(); index = tail \u0026amp; *s-\u0026gt;sq_ring.ring_mask; struct io_uring_sqe *sqe = \u0026amp;s-\u0026gt;sqes[index]; sqe-\u0026gt;fd = file_fd; sqe-\u0026gt;flags = 0; sqe-\u0026gt;opcode = IORING_OP_READV; sqe-\u0026gt;addr = (unsigned long) fi-\u0026gt;iovecs; sqe-\u0026gt;len = blocks; sqe-\u0026gt;off = 0; sqe-\u0026gt;user_data = (unsigned long long) fi; sring-\u0026gt;array[index] = index; tail = next_tail; /* Update the tail so the kernel can see it. */ if(*sring-\u0026gt;tail != tail) { *sring-\u0026gt;tail = tail; write_barrier(); } /* * Tell the kernel we have submitted events with the io_uring_enter() system * call. We also pass in the IOURING_ENTER_GETEVENTS flag which causes the * io_uring_enter() call to wait until min_complete events (the 3rd param) * complete. * */ int ret = io_uring_enter(s-\u0026gt;ring_fd, 1,1, IORING_ENTER_GETEVENTS); if(ret \u0026lt; 0) { perror(\u0026#34;io_uring_enter\u0026#34;); return 1; } return 0; } int main(int argc, char *argv[]) { struct submitter *s; if (argc \u0026lt; 2) { fprintf(stderr, \u0026#34;Usage: %s \u0026lt;filename\u0026gt;\\n\u0026#34;, argv[0]); return 1; } s = malloc(sizeof(*s)); if (!s) { perror(\u0026#34;malloc\u0026#34;); return 1; } memset(s, 0, sizeof(*s)); if(app_setup_uring(s)) { fprintf(stderr, \u0026#34;Unable to setup uring!\\n\u0026#34;); return 1; } for (int i = 1; i \u0026lt; argc; i++) { if(submit_to_sq(argv[i], s)) { fprintf(stderr, \u0026#34;Error reading file\\n\u0026#34;); return 1; } read_from_cq(s); } return 0; } 有点过于高深了，就不自己手敲了。简单翻译一下。\nThe initial setup 从 main() 开始，我们调用 app_setup_uring() ，为我们做一些使用 io_uring 的必要准备。首先调用 syscall io_uring_setup() 并提供我们需要的队列长度和 io_uring_params 的实例，全部设置为 0. 调用返回时，内核将会向这个结构体中填充值，io_uring_params 长得像\n1 2 3 4 5 6 7 8 9 10 struct io_uring_params { __u32 sq_entries; __u32 cq_entries; __u32 flags; __u32 sq_thread_cpu; __u32 sq_thread_idle; __u32 resv[5]; struct io_sqring_offsets sq_off; struct io_cqring_offsets cq_off; }; 你唯一能指定的只有 flags 字段，但在这里，我们并不想传递什么。同时，这个例子里我们串行处理请求，不使用任何并行 I/O，因为这个例子的目的主要是理解 io_uring。我们设置队列长度为1.\nio_uring_setup() 的返回值是 文件描述符 fd，其他的 io_uring_param 结构会被之后使用 mmap() 来映射到用户态的两个环形缓冲，以及一个 SQEs 数组。我们现在关注 mmap() 的部分\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 /* 映射到 SQ 和 CQ 的缓冲区中。 * 旧版内核可能只能映射 SQ。 * */ sq_ptr = mmap(0, sring_sz, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE, s-\u0026gt;ring_fd, IORING_OFF_SQ_RING); if (sq_ptr == MAP_FAILED) { perror(\u0026#34;mmap\u0026#34;); return 1; } if (p.features \u0026amp; IORING_FEAT_SINGLE_MMAP) { cq_ptr = sq_ptr; } else { /* 在旧版内核中再手动映射 CQ */ cq_ptr = mmap(0, cring_sz, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE, s-\u0026gt;ring_fd, IORING_OFF_CQ_RING); if (cq_ptr == MAP_FAILED) { perror(\u0026#34;mmap\u0026#34;); return 1; } } /* 映射 SQEs 数组 */ s-\u0026gt;sqes = mmap(0, p.sq_entries * sizeof(struct io_uring_sqe), PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE, s-\u0026gt;ring_fd, IORING_OFF_SQES); 我们保存 app_io_sq_ring 和 app_io_cq_ring 的重要信息方便以后进行引用。我们分别将两个环形缓冲区映射为 submission 和 completion，你可能会奇怪第二个 mmap 是干什么的？completion queue 环是直接索引 CQEs 数组，而 submission queue 环有一个间接的数组。submission 的环形缓冲保存的是进入按顺序保存了 SQEs 索引的数组的索引。\n这对于一些将提交请求嵌入到内部数据结构的程序比较有用，这种设计允许他们一次提交多个项目，同时允许他们使用 io_uring 更简单。\n注意：5.4 内核以及以上一次 mmap 就能映射 submission 和 completion 队列。\n了解 shared ring buffer 常规的编程中，我们习惯用很清晰的接口来处理用户态和内核态：system call。然而，syscall 具有比较大的开销，所以一些像 io_uring 的高性能接口就想要尽可能避免它们。io_uring 允许我们 batch 许多 IO 请求，然后通过一次调用 io_uring_enter() 解决问题，甚至可以使用 polling mode，都不需要调用 io_uring_enter()。\n在用户空间中读取或者更新 shared ring buffer 时，有一点需要注意，当读取时，你看到的是最新的数据；在更新后，你正在 flushing 或者说 syncing 写入，这样内核才能看到你的更新。这是因为编译器和CPU 都可以重排序 读写指令。如果发生在同一个CPU上，这个一般不是问题，但对于 io_uring 这种需要在用户态和内核态切换上下文的情况，有可能在不同 CPU 上运行。你需要在读之前确保之前的写入可见。或者，当你在 SQE 中写入信息并更新到 submission ring buffer 尾部后，确保你对数据的写入发生在插入他被插入之前。\n如果写入没有被排序，那么内核可能只看到尾部更新，读取 SQE 时里面的数据却不正确。在 polling mode 下，这个就真的是个问题了。这是因为 CPUs 和编译器对于读写操作的重排有利于优化。\n读取 CQE 先说 completion side，因为比较简单。这里是必须要讨论的，因为要考虑内存序的问题。对于 completion events，内核向缓冲区添加 CQEs 并且更新其尾部，我们在用户空间内读的是头部。就像任何的环形缓冲一样，如果 head 和 tail 相等，那就意味着缓冲区为空。我们看一下下面的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 unsigned head; head = cqring-\u0026gt;head; read_barrier(); /* ensure previous writes are visible */ if (head != cqring-\u0026gt;tail) { /* There is data available in the ring buffer */ struct io_uring_cqe *cqe; unsigned index; index = head \u0026amp; (cqring-\u0026gt;mask); cqe = \u0026amp;cqring-\u0026gt;cqes[index]; /* process completed cqe here */ ... /* we\u0026#39;ve now consumed this entry */ head++; } cqring-\u0026gt;head = head; write_barrier(); 为了获取头部的索引，应用程序需要 mask 头和缓冲区大小的mask。记住，上面的任何一行都可能在上下文切换后运行。所以，在比较之前，我们需要 read_barrier，这样如果内核更新了尾部，我们可以在 if 中读取到他。一旦我们获取了 CQE 并对他进行处理，我们就要更新头来让内核知道我们从缓冲区中消费了一个 entry。最终的 write_barrier 保证了我们的更新可见。\n提交 提交与读取 completion 相反。我们向缓冲区尾部添加 entry，内核从头部读取。\n1 2 3 4 5 6 7 8 9 10 11 12 13 struct io_uring_sqe *sqe; unsigned tail, index; tail = sqring-\u0026gt;tail; index = tail \u0026amp; (*sqring-\u0026gt;ring_mask); sqe = \u0026amp;sqring→sqes[index]; /* this function call fills in the SQE details for this IO request */ app_init_io(sqe); /* fill the SQE index into the SQ ring array */ sqring-\u0026gt;array[index] = index; tail++; write_barrier(); sqring-\u0026gt;tail = tail; write_barrier(); 在上面的代码中，app_init_io() 会填充提交信息的细节。在 tail 更新前，我们需要 write_barrier 来保证之前的写排序在我们提交之前。之后我们更新尾部，还要调用 write_barrier 来保证更新可见。We’re lining up our ducks here.\n这部分看不懂可以自行了解下 CPU 指令重排，以及内存序。在 C++ 中即 std::memory_order。\nCat liburing 代码实现 可以看出，使用 io_uring 来构建一个读取文件的程序似乎不是很简单。甚至比普通的同步代码量还要多。但如果你分析了 cat_uring 代码，你可能会看出那些代码大部分都是模板。我们都需要了解底层 io_uring 的 API 来便于我们理解细节，但如果你要在你的程序中使用 io_uring，还是应该使用 liburing ，也就是其封装版。\n我们现在来看看 liburing 的版本跟 cat_uring 有多相似\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; #include \u0026lt;sys/ioctl.h\u0026gt; #include \u0026lt;liburing.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #define QUEUE_DEPTH 1 #define BLOCK_SZ 1024 struct file_info { off_t file_sz; struct iovec iovecs[]; }; /** * 返回传入的 fd 大小。可以处理常规文件和硬件驱动。 */ off_t get_file_size(int fd) { struct stat st; if (fstat(fd, \u0026amp;st) \u0026lt; 0) { perror(\u0026#34;fstat\u0026#34;); return -1; } if (S_ISBLK(st.st_mode)) { unsigned long long bytes; if (ioctl(fd, BLKGETSIZE64, \u0026amp;bytes) != 0) { perror(\u0026#34;ioctl\u0026#34;); return -1; } return bytes; } else if (S_ISREG(st.st_mode)) { return st.st_size; } return -1; } /** * 向 stdout 输出长度为 len 的字符串。 * 我们使用 buffered 输出提高效率。 * 因此我们需要一个一个的输出字符。 */ void output_to_console(char* buf, int len) { while (len--) { fputc(*buf++, stdout); } } /** * 等待 completion 可用，从 readv 中获取数据并且打印 * */ int get_completion_and_print(struct io_uring* ring) { struct io_uring_cqe* cqe; int ret = io_uring_wait_cqe(ring, \u0026amp;cqe); if (ret \u0026lt; 0) { perror(\u0026#34;io_uring_wait_cqe\u0026#34;); return 1; } if (cqe-\u0026gt;res \u0026lt; 0) { fprintf(stderr, \u0026#34;Async readv failed.\\n\u0026#34;); return 1; } struct file_info* fi = io_uring_cqe_get_data(cqe); int blks = (int) fi-\u0026gt;file_sz / BLOCK_SZ; if (fi-\u0026gt;file_sz % BLOCK_SZ) blks++; for (int i = 0; i \u0026lt; blks; ++i) { output_to_console(fi-\u0026gt;iovecs[i].iov_base, fi-\u0026gt;iovecs[i].iov_len); } io_uring_cqe_seen(ring, cqe); return 0; } /** * 通过 liburing 来提交 readv 请求 * */ int submit_read_request(char* file_path, struct io_uring* ring) { int file_fd = open(file_path, O_RDONLY); if (file_fd \u0026lt; 0) { perror(\u0026#34;open\u0026#34;); return 1; } off_t file_sz = get_file_size(file_fd); off_t bytes_reamining = file_sz; off_t offset = 0; int current_block = 0; int blks = (int) file_sz / BLOCK_SZ; if (file_sz % BLOCK_SZ) blks++; struct file_info* fi = malloc(sizeof(*fi) + (sizeof(struct iovec) * blks)); /** * 对于每个 block 我们都需要读，分配一个 iovec struct， * 代表 iovecs array 的索引。 * 该 array 也会作为传入 submission 的一部分。 * 如果你不理解这个的话，你需要了解一下 readv() writev() 是怎么工作的。 */ while (bytes_reamining) { off_t bytes_to_read = bytes_reamining; if (bytes_to_read \u0026gt; BLOCK_SZ) { bytes_to_read = BLOCK_SZ; } offset += bytes_to_read; fi-\u0026gt;iovecs[current_block].iov_len = bytes_to_read; void* buf; if (posix_memalign(\u0026amp;buf, BLOCK_SZ, BLOCK_SZ)) { perror(\u0026#34;posix_memalign\u0026#34;); return 1; } fi-\u0026gt;iovecs[current_block].iov_base = buf; current_block++; bytes_reamining -= bytes_to_read; } fi-\u0026gt;file_sz = file_sz; /* 获取 SQE */ struct io_uring_sqe* sqe = io_uring_get_sqe(ring); /* 设置 readv 操作 */ io_uring_prep_readv(sqe, file_fd, fi-\u0026gt;iovecs, blks, 0); /* 设置 user data */ io_uring_sqe_set_data(sqe, fi); /* 最终，提交 */ io_uring_submit(ring); return 0; } int main(int argc, char* argv[]) { struct io_uring ring; if (argc \u0026lt; 2) { fprintf(stderr, \u0026#34;Usage: %s [file name] \u0026lt;[file name] ...\u0026gt;\\n\u0026#34;, argv[0]); return 1; } /* 初始化 io_uring */ io_uring_queue_init(QUEUE_DEPTH, \u0026amp;ring, 0); for (int i = 1; i \u0026lt; argc; ++i) { int ret = submit_read_request(argv[i], \u0026amp;ring); if (ret) { fprintf(stderr, \u0026#34;Error reading file: %s\\n\u0026#34;, argv[i]); return 1; } get_completion_and_print(\u0026amp;ring); } /* 调用清理函数 */ io_uring_queue_exit(\u0026amp;ring); return 0; } 对比一下他们的行数：\n常规 cat：120行 io_uring 原生：360行 liburing：160 行 我们来针对关键部分逻辑快速过一下代码：\n首先我们初始化 io_uring\n1 io_uring_queue_init(QUEUE_DEPTH, \u0026amp;ring, 0); 在函数 submit_read_request() 中，我们获得 SQE，并且准备一个 readv 请求之后再提交\n1 2 3 4 5 6 7 8 /* Get an SQE */ struct io_uring_sqe *sqe = io_uring_get_sqe(ring); /* Setup a readv operation */ io_uring_prep_readv(sqe, file_fd, fi-\u0026gt;iovecs, blocks, 0); /* Set user data */ io_uring_sqe_set_data(sqe, fi); /* Finally, submit the request */ io_uring_submit(ring); 等待 completion event，并且获取我们之前提交的请求返回的用户数据：\n1 2 3 struct io_uring_cqe *cqe; int ret = io_uring_wait_cqe(ring, \u0026amp;cqe); struct file_info *fi = io_uring_cqe_get_data(cqe); 对比原生 API 实在是太简单了。\n译者的总结 流程：\n初始化 io_uring -\u0026gt;\n提交请求 -\u0026gt;\n初始化 SQE 指明 io_uring 对该 SQE 的操作 指明 io_uring 存储结果的位置（user data） 提交该 ring 的请求 获取 completion\n声明 CQE, 等待该 CQE 被操作完成 从 CQE 中获取信息 将该 CQE 标记为已被消费 步骤 函数API 初始化 io_uring int io_uring_queue_init(unsigned entries, struct io_uring *ring, unsigned flags); 初始化 SQE struct io_uring_sqe *io_uring_get_sqe(struct io_uring *ring); 指明 io_uring 对该 SQE 的操作 io_uring_prep_action_name 指明 io_uring 存储结果的位置 void io_uring_sqe_set_data(struct io_uring_sqe *sqe, void *user_data); 提交该 ring 的请求 int io_uring_submit(struct io_uring *ring); 声明 CQE, 等待该 CQE 被操作完成 int io_uring_wait_cqe(struct io_uring *ring, struct io_uring_cqe **cqe_ptr); 从 CQE 中获取信息 void *io_uring_cqe_get_data(struct io_uring_cqe *cqe); 将该 CQE 标记为已被消费 void io_uring_cqe_seen(struct io_uring *ring, struct io_uring_cqe *cqe); 参考资料：\nArch 手册\n异步编程的麻烦 如果你只需要编写每小时处理几千甚至几百请求的程序，那你完全无需考虑异步 IO。使用线程池为基础的架构已经足够了\nthread-pool based architectures will serve you just fine\n但如果你需要每小时处理百万请求，你可能需要关注一下异步编程。异步编程通过将 I/O 在一个线程上执行而避免了操作系统的线程/进程上下文切换开销。读这里了解更多，了解不同的程序是如何构建 web server的。\n常规文件的麻烦 linux 上的异步编程，特别是 sockets 使用的是 select(), poll(), epoll()。这些方法对于 socket 比较有效，对于常规文件没什么效果。如果你构建一个 web server 或者是 caching server，那么处理许多跟并发、存储速度有关的常规文件请求，访问文件会阻塞并且降低你服务器的速度。为了解决这个问题，libuv 使用了分开了处理文件 I/O 和其他事情的线程。\n正如其文档中所说：\nUnlike network I/O, there are no platform-specific file I/O primitives libuv could rely on, so the current approach is to run blocking file I/O operations in a thread pool.\nlibuv currently uses a global thread pool on which all loops can queue work. 3 types of operations are currently run on this pool:\n– File system operations\n– DNS functions (getaddrinfo and getnameinfo)\n– User specified code via uv_queue_work()\n有了 io_uring，所有的操作，不管是发生在 socket 还是常规文件，都有了统一的解决方案。不需要用户再想其他的技巧来解决这些问题了。读 this 了解更多异步 IO 和文件 IO 的关系。\n下一步？ 第一部分文章，我们简单看了如何构建一个和 Unix 系 cat 命令相同的程序，使用了三种方法：同步，io_uring 原生 API，liburing。然而，我们在这里限制了一次只处理一个请求。我们的实现同时可以读取许多文件，但是提交到 io_uring 后，我们等待其就绪，最后再将下一个文件移入处理。我们故意这么设计，好让我们抓住 io_uring 工作的重点。但 io_uring 真正的一次处理多个请求的威力，我们会在下一篇文章中再写。我们会编写一个复制文件的程序，让 io_uring 一次性接受多个请求，一个文件一个 block。\n原作者信息 My name is Shuveb Hussain and I’m the author of this Linux-focused blog. You can follow me on Twitter where I post tech-related content mostly focusing on Linux, performance, scalability and cloud technologies.\n","date":"2024-02-15T00:00:00Z","permalink":"https://rossqaq.github.io/article/io_uring-cat/","title":"io_uring P1 - 实现 cat"},{"content":"Back to Basics: Designing Classes (part 1 of 2) - Klaus Iglberger- CppCon 2021\nBack to Basics: Designing Classes (part 2 of 2) - Klaus Iglberger- CppCon 2021\n一期 Back to Basics，讲解类的设计，分了 2 期，这里就合在一起了。\nP1 主要是设计类时的问题，P2 是如何设计一个类\nThe Challenge of Class Design 设计类的难点在于：Change。\n软件工程必须要接受频繁的更改，那么什么会导致 Change 呢？\n依赖 Dependencies 所以如果你是一个软件设计师，那么你需要遵循：\n设计容易更改的类 设计容易扩展的类 这是宗旨，不光是设计类，所有跟代码有关的东西都要遵循。\nDesign Guidelines 花费一些时间，给所有的实体起一个好的名字 标准库就有很多例子，比如：\n1 2 template \u0026lt;class T, std::size_t N\u0026gt;\t// \u0026lt;- 这里的 N 改为 size 明显就会更好 struct array; 或者 std::vector 的命名，以前由于某些原因 vector 就称之为 vector，但是现在来看，vector 是线性代数的概念，我们并不能一眼看出 vector 是容器还是数值数组之类。\n再例如，容器中的 empty() 方法，我们无法知道他是 action or query。\n所以命名很重要。\nDesign for Change and Extension 实际例子 - Shape 举个无聊的例子，设计图形类，一般会选择设计一个图形基类，然后再继承他：\n1 2 3 4 5 6 7 8 class Shape { public: virtual draw() = 0; }; class Circle : public Shape {...}; class Square : public Shape {...}; 问题在于，这样实现就导致你的代码多了一层依赖，如果你之后想更改你的代码，比如从 openGL 更改为其他 API，就会变得很困难。\n那么比较 naive 的解决方法是，\n从 Circle 类再派生一些类出来实现，例如 OpenGLCircle , MetalCircle，自然每一个都要实现。\n那么，如果现在 Shape 中再多一个方法呢？\n1 2 3 4 5 class Shape { public: virtual draw() = 0; virtual serialize() = 0; }; 那可能对于每个派生出的类又要实现两个类，例如 OpenGLLittleEndianSquare, OpenGLBigEndianSqurae\n你发现你的继承越来越复杂了，虽然你发现序列化的实现都是相似的，但你就是很难修改。\n如果你使用这种 naive 方式解决，就会发生：\n太多派生类 越来越难命名 更深的继承层次 相同实现的代码越来越多 几乎无法扩展 我们需要：\n不要把所有东西都塞到一个类中，分开关键部分 如果使用面向对象编程，请你合适的使用 设计容易更改的类 设计容易扩展的类 Resist the urge to put everything into one class. Separate concerns. If you use OO programming, use it properly. Design classes for easy change. Design classes for easy extensions. 解决问题 Inheritance is Rarely the Answer. Delegate to Services: Has-A Trumps Is-A.\n​\t—— Andrew Hunt, David Thomas, The Pragmatic Programmer\n解决之道在于设计的原则\nSingle-Responsibility Principle Open-Closed Principle Don\u0026rsquo;t Repeat Yourself 单一责任原则 SPR 通俗的解释是：任何东西都应该只做一件事。\nKlaus Iglberger 的解释是：SPR 建议关键点以隔离、简化变更\nThe Single-Responsibility Principle advices to separate concerns to isolate and simplify change.\n开闭原则 OCP 开闭原则建议选择通过类型和操作来简化扩展的设计。\nThe Open-Closed Principle advices to prefer design that simplifies the extension by types or operations.\nopen for extensions but close for modification\n不要重复原则 DRY 减少重复以此减少变更。\nThe DRY Principle advices to reduce duplication in order to simplify change.\n推荐去看 GoF 的 23 种设计模式的书籍。\n使用 Strategy 模式解决问题 策略模式通常是对算法的封装，将算法和类解耦。\nCircle 拥有 DrawStrategy\n如果转化为代码，大概会是：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 class Shape { public: Shape() = default; virtual ~Shape() = default; virtual void draw(...) const = 0; virtual void serialize(...) const = 0; }; class Circle; class DrawCircleStrategy { public: virtual ~DrawCircleStrategy() {} virtual void draw(const Circle\u0026amp; circle, ...) const = 0; }; class Circle : public Shape { public: // 使用 unique ptr 保证所有权 // 这里 strategy 也是依赖注入 Circle(double r, std::unique_ptr\u0026lt;DrawCircleStrategy\u0026gt; strategy) : radius(r), ..., drawing{std::move(strategy)} {} double getRadius() const noexcept; void draw(...) const override { drawing-\u0026gt;draw(this, ...); } void serialize(...) const override; private: double radius; std::unique_ptr\u0026lt;DrawCircleStrategy\u0026gt; drawing; }; // Square 等同理 // 之后再使用 OpenGLDrawStrategy 等继承 DrawCircleStrategy int main() { using Shapes = std::vector\u0026lt;std::unique_ptr\u0026lt;Shape\u0026gt;\u0026gt;; Shapes shapes; shapes.emplace_back( std::make_unique\u0026lt;Circle\u0026gt;( 2.0, std::make_unique\u0026lt;OpenGLCircleStrategy\u0026gt;() ) ); ... drawAllShapes(shapes); } 通过策略模式，我们满足：\n解耦实现细节（SRP） 提供简单更改的机会 提供简单扩展的集合（OCP） 减少副本（DRY） 限制了继承深度 容易维护 你可能会说：这是90年代的东西，不是现代 C++。\n确实，但是核心思想是不变的，例如你可以把 unique_ptr 直接换成 std::function，然后直接调用\n当然，也可以通过模板参数来实现。\n例子2 - 模板方法模式 ","date":"2024-02-14T00:00:00Z","image":"https://rossqaq.github.io/article/cppcon-2021-bcls/cppcon2021-cover_hu12c72e74cc107b1dec0a72d3e09dd6fc_58474_120x120_fill_box_smart1_3.png","permalink":"https://rossqaq.github.io/article/cppcon-2021-bcls/","title":"C++ Class Design"},{"content":"C++ 模板实参推导 大致总结一下 C++ 的模板实参推导规则，专注于重点。\nC++ 本身有一堆复杂的规则，但我只挑我目前理解中常用的。本节内容只记录 函数模板 推导规则。C++17 后支持 类模板 参数推导，当然，只在构造时才能推导。\n首先关于实参推导，标准的描述是：\n为了实例化一个函数模板需要知晓每个模板实参，但并非每个模板实参都必须予以指定。编译器会尽可能从函数实参推导缺失的模板实参。\n从函数推导的规则：\n模板实参推导试图确定模板实参（类型模板形参 Ti 的类型，模板模板形参 TTi 的模板，和非类型模板形参 Ii 的值），它们在经过以下列出的调整之后可以代换到各个函数形参 P 中，以产生推导的类型 A，它与函数实参 A 类型相同。\n如果有多个形参，那么分别推导每一对 P/A，然后合并各个推导的模板实参。如果推导失败，或任何一对 P/A 或有歧义，或如果不同对推导出的模板实参不同，或如果还遗留有任何模板实参既没有被推导也没有被显式指定，那么编译失败。\n注意 P/A是一对，对不上也会编译失败。\n意思是说，对于：\n1 2 3 4 5 6 template \u0026lt;typename T\u0026gt; T max(T, T); max(1.0, 2);\t// 推导失败，编译器不知道要的是 int 还是 double max\u0026lt;double\u0026gt;(1.0, 2);\t// ok，显式指定 // 注：这里的模板参数是 P，调用函数传递的参数是 A 基本上推导是符合直觉的，但会做出以下处理：\n若 P 不是引用类型，那么若 A 是数组类型、函数类型，都会退化为相应指针；如果 A 有 cv 限定符，也会忽略（意思就是对 A 使用 std::decay_t。 题外话，所有进行按值传递函数实参时都会进行这种转换 ） 如果 P 有cv 限定，推导时会忽略顶层 cv 限定符 若 P 是引用类型，那么用 P 引用的类型推导 如果 P 是万能引用，且对应函数调用实参是左值，那么 A 的左值引用类型会用于 A 的位置进行推导。（std::forward 的基础） 其次，必须要知道什么时候进行推导，什么时候不推导，即 不推导语境\n（常见的比如 std::forward，就是个明显的不推导语境）\n下列情况下，用来组成 P的类型、模板和非类型值不会参与模板实参推导，而改为使用可以在别处推导出或显式指定的模板实参。如果模板形参只在不推导语境使用且没有被显式指定，那么模板实参推导失败。\n也就是说，这种情况下要么已经推导过了，要么要进行指定，否则会推导失败。\n作用域解析运算符 :: 左侧的所有内容（最常见的情况）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // in C++20 template\u0026lt;typename T\u0026gt; void bad(std::vector\u0026lt;T\u0026gt; x, T value = 1); template\u0026lt;typename T\u0026gt; void good(std::vector\u0026lt;T\u0026gt; x, std::type_identity\u0026lt;T\u0026gt;::type value = 1); std::vector\u0026lt;std::complex\u0026lt;double\u0026gt;\u0026gt; x; bad(x, 1.2); // P1/A1: T = std::complex\u0026lt;double\u0026gt; // P2/A2: T = double // 推导失败 good(x, 1.2); // 成功，后者不是推导语境，使用的是前者推导出的 T，即 std::complex\u0026lt;double\u0026gt; decltype 内的表达式\n非类型模板实参或数组边界，子表达式引用一个模板形参\n形参 P，其实参 A 是花括号初始化器列表，但 P 不是 std::initializer_list ，到他的引用，或者到数组的引用（C++17）\n也比较常见，这个loser_list 纯纯的坑\n1 2 3 4 5 6 7 8 9 10 11 template\u0026lt;class T\u0026gt; void g1(std::vector\u0026lt;T\u0026gt;); template\u0026lt;class T\u0026gt; void g2(std::vector\u0026lt;T\u0026gt;, T x); g1({1, 2, 3}); // P = std::vector\u0026lt;T\u0026gt;，A = {1, 2, 3}：T 在不推导语境中 // 错误：T 没有被显式指定或从另一对 P/A 推导出 g2({1, 2, 3}, 10); // P1 = std::vector\u0026lt;T\u0026gt;，A1 = {1, 2, 3}：T 在不推导语境中 // P2 = T，A2 = int：推导出 T = int 参考资料 模板实参推导\n","date":"2024-02-13T00:00:00Z","permalink":"https://rossqaq.github.io/article/template-arg-deduction/","title":"模板参数推导"},{"content":"教程原文\n函数模板 使用函数模板 函数模板使用时才会实例化（隐式实例化） 函数模板参数推导规则 函数模板参数推导规则、无法推导的情况 ADL 对于函数模板调用时的影响 万能引用、引用折叠，特殊推导规则 函数模板默认实参 可以给模板类型实参默认值，既然是类型，那么默认值也要类型\n（func\u0026lt;\u0026gt;() 代表使用默认值）\n推导时，P/A 对无法推导（例如3P 2A对不上的情况）下的处理\n默认实参？部分指明？通过 decltype 三目表达式配合 decay_t 获取 common_type？\n后置返回值类型配合 decltype\n对于 C++20，甚至可以使用简写函数模板。注意 auto 和 decltype 的推导规则\n非类型模板实参 模板参数接收值或者对象，而不是类型\n1 2 3 4 template \u0026lt;std::size_t N = 10\u0026gt; void func() { std::cout \u0026lt;\u0026lt; N \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } func\u0026lt;5\u0026gt;(); 重载函数模板 函数模板与普通函数都能重载，重载决议规则非常复杂。\n一般而言，会优先选择非模板的函数。（毕竟隐式实例化也有开销）\n可变参数模板 C 语言的可变参数，最常见的例子就是 printf ，参见。\nC++ 中若想使用可变参数，则必须使用模板。\n形参包\n如何实现支持任何类型，任何参数的调用？\n类型形参包：存类型\n函数形参包：存参数\n如何使用？形参包展开\n什么是模式？（[形参包名]\u0026hellip; 中的形参包名是模式，其会被展开为 0 或多个逗号分隔的模式实例）\n举个例子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 template\u0026lt;typename... Args\u0026gt; void print(const Args\u0026amp;... args) { int _[] { (std::cout \u0026lt;\u0026lt; args \u0026lt;\u0026lt; \u0026#39; \u0026#39;, 0)... }; } // (std::cout \u0026lt;\u0026lt; arg0 \u0026lt;\u0026lt; \u0026#39; \u0026#39;, 0), (std::cout \u0026lt;\u0026lt; arg1 \u0026lt;\u0026lt; \u0026#39; \u0026#39;, 0), (std::cout \u0026lt;\u0026lt; arg2 \u0026lt;\u0026lt; \u0026#39; \u0026#39;, 0) 会展开成这种形式 // // (std::cout \u0026lt;\u0026lt; args \u0026lt;\u0026lt; \u0026#39; \u0026#39;, 0) 是模式 // 逗号表达式，从左往右顺序执行。 // , 0，会返回0 然后初始化数组，数组没啥用，只是用于写成这个形式，因为 {} 可以进行包展开。 template\u0026lt;typename T, std::size_t N, typename... Args\u0026gt; void f(const T(\u0026amp;array)[N], Args... index) { print(array[index]...);\t// 模式 array[index] } // const T(\u0026amp;array)[N] 数组引用 // 内建数组，其 size 是他类型的一部分，所以可以被推导 // const char (\u0026amp;)[5], const int\u0026amp;, const double\u0026amp; // const char (\u0026amp;)[5] -\u0026gt; const char* print(\u0026#34;luse\u0026#34;, 1, 1.2); int array[10] {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}; f(array, 1, 3, 5); 那么如何写一个函数 sum，支持任何类型，任意参数调用\n1 2 3 4 5 6 7 8 9 template \u0026lt;typename... Args, typename RT = std::common_type_t\u0026lt;Args...\u0026gt;\u0026gt; RT sum(const Args\u0026amp;... args) { RT _[] { args... }; RT n{}; for (int i = 0; i \u0026lt; sizeof...(Args); ++i) { n += _[i]; } return n; } 模板分文件 显然不可能（当然显式实例化除外）\n类模板 初始类模板 类模板不是类，实例化类模板才能生成类。\n函数模板中形参列表可以写的类模板都能写。\nC++17 后，CTAD 可以根据传入的参数推导类模板\n用户定义推导指引 1 2 3 template_name(deduced_type) -\u0026gt; template_name\u0026lt;the type you want\u0026gt;; // e.g. Test(int) -\u0026gt; Test\u0026lt;size_t\u0026gt;; 比较复杂的：\n1 2 3 4 5 6 7 template \u0026lt;typename Ty, std::size_t size\u0026gt; struct array { Ty arr[size]; }; template \u0026lt;typename T, typename... Args\u0026gt; array(T t, Args...) -\u0026gt; array\u0026lt;T, sizeof...(Args) + 1\u0026gt;; 类模板有默认实参的模板形参 1 2 3 4 5 6 7 8 9 template \u0026lt;typename T = int\u0026gt; struct X {}; struct Test { X x;\t// C++17 也不行，类中的不允许省略 \u0026lt;\u0026gt; }; X x; // C++17 ok X\u0026lt;\u0026gt; x; // before C++17 应用很多，例如 vector，string 等等，分配器。\n模板模板形参 如果想要模板参数接受一个类模板怎么办？\n1 2 3 4 5 6 7 8 template\u0026lt;typename T\u0026gt; struct X {}; // before C++17 template\u0026lt;template\u0026lt;typename T\u0026gt; class C\u0026gt; template\u0026lt;template\u0026lt;typename T\u0026gt; typename C\u0026gt; struct Test {}; Test\u0026lt;X\u0026gt;arr; template \u0026lt;typename T\u0026gt; typename C 是模板模板形参语法\ntypename C 是模板模板形参，可以自定义\n模板模板形参包也可以\n1 2 3 template\u0026lt;template\u0026lt;typename T\u0026gt; class... Args\u0026gt; test\u0026lt;X, Y, Z\u0026gt; t; 1 2 3 4 5 template \u0026lt;std::size_t\u0026gt; struct Y{}; template \u0026lt;template\u0026lt;std::size_t\u0026gt; class T\u0026gt; struct X{}; 1 2 3 4 5 6 7 template \u0026lt;typename... Args\u0026gt; struct Y{}; template \u0026lt;template\u0026lt;typename... Args\u0026gt; class T\u0026gt; struct X{}; X\u0026lt;Y\u0026gt; t; 基本就是，要接受什么，就复制其模板声明，之后再声明一个 T\n成员函数模板 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // 模板类和函数 template\u0026lt;typename T\u0026gt; struct X { void f(T arg) {} }; X\u0026lt;int\u0026gt; x; x.f(123); // 模板类和模板函数 template\u0026lt;typename T\u0026gt; struct X { template\u0026lt;typename... Args\u0026gt; void f(Args\u0026amp;\u0026amp;... args) {} }; X\u0026lt;int, double, float\u0026gt; x; x.f(1, 2, 3); // 普通类和模板函数 struct X { template\u0026lt;typename... Args\u0026gt; void f(Args\u0026amp;\u0026amp;... args) {} }; X x; x.f(1, 2, 3); 可变参数类模板 1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026lt;iostream\u0026gt; #include \u0026lt;tuple\u0026gt; template\u0026lt;typename... Args\u0026gt; struct X { X(Args... args) : value{ args... } {} std::tuple\u0026lt;Args...\u0026gt; value; }; int main() { X x{ 1, 2.1, \u0026#34;2\u0026#34;, \u0026#39;3\u0026#39; }; std::cout \u0026lt;\u0026lt; std::get\u0026lt;2\u0026gt;(x.value); } 可以使用 cpp insights 辅助。\n变量模板 初识变量模板 1 2 template \u0026lt;typename T\u0026gt; T v; 跟函数模板、类模板同理，变量模板也不是变量，实例化之后是全局变量。自然也可以 cv 修饰等等。\n变量模板默认实参与非类型模板实参 跟函数、类同理。\n可变参数变量模板 1 2 3 4 5 6 7 8 9 template \u0026lt;typename... Args\u0026gt; size_t N = sizeof...(Args); template \u0026lt;std::size_t... value\u0026gt; constexpr std::size_t array[] {value...}; for (const auto\u0026amp; i : array\u0026lt;1, 2, 3, 4, 5\u0026gt;) { std::cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#39; \u0026#39;; } 类静态数据成员模板 首先说类的普通静态成员\n1 2 3 4 struct X { static int n;\t// 声明，没有定义 }; int X::n;\t// 类外定义，当然也可以给初始值 1 2 3 4 5 6 struct X { static const int n = 10;\t// 不是定义，还是声明 }; // 这种情况能用是因为 // 读取编译时常量，不是 ODR 调用，没有违反 ODR // 如果要单一使用，就必须要定义 1 2 3 struct X { static inline int n = 10;\t// C++17, 定义，可以 ODR 使用 }; 1 2 3 4 struct X { static constexpr int n = 10;\t// C++17, 定义 }; // static constexpr 自带 inline 属性，所以可以 ODR 使用 来看看类的静态变量模板\n1 2 3 4 5 6 struct limits { template\u0026lt;typename T\u0026gt; static const T min;\t// 声明 }; template\u0026lt;typename T\u0026gt; const T limits::min = {};\t// 静态数据成员模板定义 模板全特化 函数模板全特化 特化，对某些类型进行定制的操作\n1 2 3 4 5 6 7 8 9 template\u0026lt;typename T,typename T2\u0026gt; auto f(const T\u0026amp; a, const T2\u0026amp; b) { return a + b; } template\u0026lt;\u0026gt; auto f\u0026lt;double, int\u0026gt;(const double\u0026amp; a, const int\u0026amp; b) { return a - b; } 类模板全特化 实现个 std::is_void\n1 2 3 4 5 6 7 8 9 template\u0026lt;typename T\u0026gt; struct is_void { static constexpr bool value {false}; }; template\u0026lt;\u0026gt; struct is_void\u0026lt;void\u0026gt; { static constexpr bool value {true}; } C++17 还引入了 _v 版本\n使用的是变量模板\n1 2 template\u0026lt;typename T\u0026gt; constexpr bool is_void_v = is_void\u0026lt;T\u0026gt;::value; 注意不同实例化的模板类之间没有任何关系，他们是互相独立的\n1 2 3 4 5 6 7 template \u0026lt;typename T\u0026gt; struct X {}; template\u0026lt;\u0026gt; struct X\u0026lt;int\u0026gt; { void f() {} }; 变量模板全特化 没什么好说。\n模板全特化细节 特化必须在发生隐式实例化之前，在使用到其的翻译单元中声明\n只有声明没有定义的模板特化可以像其他不完整类型一样使用（例如使用到他的指针或引用\n函数模板和变量模板的显式特化是否为 inline/constexpr/constinit/consteval 只与特化自身有关。主模版的声明是否带有对应说明符对其没有影响。模板声明中出现的属性在它的显式特化中也没有效果。\n特化的成员与总结 1 2 3 4 5 6 7 template\u0026lt;typename T\u0026gt; struct A { struct B {}; template\u0026lt;typename U\u0026gt; struct C {}; }; 特化后类内成名，类外定义：\n1 2 3 4 5 6 7 8 9 template\u0026lt;\u0026gt; struct A\u0026lt;void\u0026gt; { void f(); }; void A\u0026lt;void\u0026gt;::f() {} A\u0026lt;void\u0026gt; a; a.f(); 特化 A\u0026lt;char\u0026gt; 情况下的 B 成员类\n1 2 3 4 5 6 7 8 9 template\u0026lt;\u0026gt; struct A\u0026lt;char\u0026gt;::B { void f(); }; void A\u0026lt;char\u0026gt;::B::f() {} A\u0026lt;char\u0026gt;::B b_c; b_c.f(); 特化成员类模板 A\u0026lt;int\u0026gt; C 的定义\n1 2 3 4 5 6 7 8 9 10 11 12 template\u0026lt;\u0026gt; template\u0026lt;typename U\u0026gt; struct A\u0026lt;int\u0026gt;::C { void f(); }; template\u0026lt;\u0026gt; template\u0026lt;typename U\u0026gt; void A\u0026lt;int\u0026gt;::C\u0026lt;U\u0026gt;::f() {} A\u0026lt;int\u0026gt;::C\u0026lt;void\u0026gt; c_v; c_v.f(); 特化普通类的成员函数模板\n1 2 3 4 5 6 7 8 9 10 struct X { template\u0026lt;typename T\u0026gt; void f(T) {} template\u0026lt;\u0026gt; void f\u0026lt;int\u0026gt;(int) {}\t// 可以类内直接特化 }; template\u0026lt;\u0026gt; void X::f\u0026lt;double\u0026gt;(double) {}\t// 类外特化 特化类模板的成员函数模板\n1 2 3 4 5 6 7 8 9 template\u0026lt;typename T\u0026gt; struct X { template\u0026lt;typename U\u0026gt; void f(U) {} }; template\u0026lt;\u0026gt; template\u0026lt;\u0026gt; void X\u0026lt;int\u0026gt;::f\u0026lt;char\u0026gt;(char) {} 模板偏特化 对有共同一类特征的类模板、变量模板进行定制行为（函数模板不能偏特化）\n变量模板偏特化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 template\u0026lt;typename T\u0026gt; const char* s = \u0026#34;?\u0026#34;; template\u0026lt;typename T\u0026gt; const char* s\u0026lt;T*\u0026gt; = \u0026#34;pointer\u0026#34;;\t// 对指针这一类类型特化 template\u0026lt;typename T\u0026gt; const char* S\u0026lt;T[]\u0026gt; = \u0026#34;array\u0026#34;;\t// 针对 T[] 进行偏特化，而不是数组类型 // T[] 和 T[N] 肯定不是一个类型 template\u0026lt;typename T, typename T2\u0026gt; const char* s = \u0026#34;?\u0026#34;; template\u0026lt;typename T2\u0026gt; const char* s\u0026lt;int, T2\u0026gt; = \u0026#34; T == int \u0026#34;; 类模板偏特化 1 2 3 4 5 6 7 8 9 10 11 12 template\u0026lt;typename T, typename T2\u0026gt; struct X { void f() const {} }; template\u0026lt;typename T\u0026gt; struct X\u0026lt;void, T\u0026gt; { void g() const; } template\u0026lt;typename T\u0026gt; void X\u0026lt;void, T\u0026gt;::g() const {}\t// 不建议写到类外 1 2 3 4 5 6 7 8 9 10 11 template\u0026lt;typename T, std::size_t N\u0026gt; struct X { template\u0026lt;typename U, typename V\u0026gt; struct Y{}; }; template\u0026lt;\u0026gt; template\u0026lt;typename V\u0026gt; struct X\u0026lt;int, 5\u0026gt;::Y\u0026lt;int, V\u0026gt; { void f() const {} } 实现 is_same_v 1 2 3 4 5 6 7 8 9 10 11 12 13 template\u0026lt;class, class\u0026gt; struct is_same { static constexpr bool value{ false }; }; template\u0026lt;class Ty\u0026gt; struct is_same\u0026lt;Ty, Ty\u0026gt; { static constexpr bool value{ true }; }; // 变量模板 template \u0026lt;class T, class T2\u0026gt; constexpr bool is_same_v = is_same\u0026lt;T, T2\u0026gt;::value; 当然也可以用变量模板直接写\n1 2 3 4 5 template \u0026lt;class, class\u0026gt; constexpr bool is_same_v = false; template \u0026lt;class Ty\u0026gt; constexpr bool is_same_v\u0026lt;Ty, Ty\u0026gt; = true; 函数模板显式实例化解决分文件问题 函数模板 1 2 3 4 5 6 template\u0026lt;typename T\u0026gt; void f(T) { std::cout \u0026lt;\u0026lt; typeid(T).name() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } template void f(int);\t// 编译器会实例化 f\u0026lt;int\u0026gt;(int) 之后就可以把模板放在头文件，在cpp文件内显式实例化，然后其他 cpp 引入头文件就可以使用了。\n类模板 类的完整定义不包含成员函数的完整定义，所以可以创建对象，但是不能调用成员函数。\n需要显式实例化成员函数\n1 2 3 4 5 6 template\u0026lt;typename T\u0026gt; struct X { void f(); }; template void X\u0026lt;int\u0026gt;::f(); 折叠表达式 一元 C++17 引入折叠表达式，更方便进行形参包展开\n之前在新参包中的写法非常愚蠢，在C++17之后就可以使用折叠表达式了。\n折叠表达式是左折叠还是右折叠，取决于 ... 的位置\n1 2 3 4 5 6 7 template\u0026lt;typename... Args\u0026gt; void print(const Args\u0026amp;... args) { ((std::cout \u0026lt;\u0026lt; args \u0026lt;\u0026lt; \u0026#39; \u0026#39;), ...); } // 一元 右折叠 -\u0026gt; (E 运算符 ...) : E-\u0026gt; (std::cout \u0026lt;\u0026lt; args \u0026lt;\u0026lt; \u0026#39; \u0026#39;)；运算符-\u0026gt; , // 剩下点和括号就不说了，括号是折叠表达式语法的一部分 // 展开为 (E1 运算符 (... 运算符 (EN-1 运算符 EN))) 1 2 3 4 5 6 template\u0026lt;typename... Args\u0026gt; void print(const Args\u0026amp;... args) { (..., (std::cout \u0026lt;\u0026lt; args \u0026lt;\u0026lt; \u0026#39; \u0026#39;)); } // 一元 左折叠 // (... 运算符 E) -\u0026gt; (((E1 运算符 E2) 运算符 ...) 运算符 EN) 那打印顺序会变吗？不会！因为逗号从左到右执行，不管左折叠还是右折叠都不影响。当然其他运算符会有一些区别。\n1 2 3 4 5 6 7 8 9 10 11 12 template\u0026lt;int... I\u0026gt; constexpr int v_r = (I - ...);\t// 一元右折叠 template\u0026lt;int... I\u0026gt; constexpr int v_l = (... - I);\t// 一元左折叠 int main() { std::cout \u0026lt;\u0026lt; v_r\u0026lt;4, 5, 6\u0026gt; \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; std::cout \u0026lt;\u0026lt; v_l\u0026lt;4, 5, 6\u0026gt; \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } // v_r (4-(5-6)) = 5 // v_l ((4-5)-6) = -7 大部分会求值的表达式会影响结果。\n二元 二元会长成: 运算符 \u0026hellip; 运算符\n二元左折叠 (\u0026hellip; 在形参包左边)\n(I 运算符 ... 运算符 E)，I 是初值表达式\n1 2 3 4 5 template\u0026lt;typename... Args\u0026gt; void print(Args\u0026amp;\u0026amp;... args) { (std::cout \u0026lt;\u0026lt; ... \u0026lt;\u0026lt; args); } // 这样写，在打印的情况下会比较抽象。 I：std::cout\n运算符: \u0026laquo; .. \u0026laquo;\nE: args\n展开形式和一元的很像 ((((I 运算符 E1) 运算符 E2) 运算符 ...) 运算符 EN)，只不过多了一个 I，右折叠同理，最后多了 I\n1 2 3 4 5 6 7 8 9 10 template\u0026lt;int... I\u0026gt; constexpr int v_r = (I + ... + 10);\t//二元右折叠 template\u0026lt;int... I\u0026gt; constexpr int v_l = (10 + ... + I); int main() { std::cout \u0026lt;\u0026lt; v_r\u0026lt;1, 2, 3, 4\u0026gt; \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; std::cout \u0026lt;\u0026lt; v_l\u0026lt;1, 2, 3, 4\u0026gt; \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } 结果显然都是 20\nv_r: (1+(2+(3+(4+10))))\nv_l: ((((10+1)+2)+3)+4)\n初值无论如何都是第一个计算。\n待决名 在模板（类模板和函数模板）定义中，某些构造的含义可以在不同的实例化间有所不同。特别是，类型和表达式可能会取决于类型模板形参的类型和非类型模板形参的值。\ntypename 消除待决名歧义 1 2 3 4 5 6 7 8 9 10 11 template\u0026lt;typename T\u0026gt; const T::type\u0026amp; f(const T\u0026amp;) { return 0; } struct X { using type = int; }; X x; f(x); 无法编译，因为编译器认为 T::type 是标识符，我们需要加上 typename 提示编译器他是类型\n1 2 template\u0026lt;typename T\u0026gt; const typename T::type\u0026amp; f(const T\u0026amp;) {...} 在模板（包括别名模版）的声明或定义中，不是当前实例化的成员且取决于某个模板形参的名字 不会被认为是类型，除非使用关键词 typename 或它已经被设立为类型名（例如用 typedef 声明或通过用作基类名）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 int p = 1; template\u0026lt;typename T\u0026gt; void foo(const std::vector\u0026lt;T\u0026gt;\u0026amp; v){ // std::vector\u0026lt;T\u0026gt;::const_iterator 是待决名， typename std::vector\u0026lt;T\u0026gt;::const_iterator it = v.begin(); // 下列内容因为没有 \u0026#39;typename\u0026#39; 而会被解析成 // 类型待决的成员变量 \u0026#39;const_iterator\u0026#39; 和某变量 \u0026#39;p\u0026#39; 的乘法。 // 因为在此处有一个可见的全局 \u0026#39;p\u0026#39;，所以此模板定义能编译。 std::vector\u0026lt;T\u0026gt;::const_iterator* p; typedef typename std::vector\u0026lt;T\u0026gt;::const_iterator iter_t; iter_t* p2; // iter_t 是待决名，但已知它是类型名 } int main(){ std::vector\u0026lt;int\u0026gt;v; foo(v); // 实例化失败 } template 消除歧义符 模板定义中 不是当前实例化的成员 的待决名 同样不被认为是模板名，除非使用消歧义关键词 template，或它已被设立为模板名\n1 2 3 4 5 6 7 8 9 10 11 12 template\u0026lt;typename T\u0026gt; struct S { template\u0026lt;typename U\u0026gt; void foo() {} }; template\u0026lt;typename T\u0026gt; void bar() { S\u0026lt;T\u0026gt; s; s.foo\u0026lt;T\u0026gt;(); // s.template foo\u0026lt;T\u0026gt;(); } template 的使用比 typename 少，并且 template 只能用于 ::、-\u0026gt;、. 三个运算符 *之后*。\n非待决名绑定规则 非待决名在模版定义点查找并绑定，即使模板实例化点有更好的匹配，也保持此绑定。\n待决与非待决查找规则 有限名字查找？ 无限名字查找？ 对于在模板的定义中所使用的非待决名，当检查该模板的定义时将进行无限定的名字查找。在这个位置与声明之间的绑定并不会受到在实例化点可见的声明的影响。而对于在模板定义中所使用的待决名，它的查找会推迟到得知它的模板实参之时。此时，ADL 将同时在模板的定义语境和在模板的实例化语境中检查可见的具有外部连接的 (C++11 前)函数声明，而非 ADL 的查找只会检查在模板的定义语境中可见的具有外部连接的 (C++11 前)函数声明。（换句话说，在模板定义之后添加新的函数声明，除非通过 ADL 否则仍是不可见的。）如果在 ADL 查找所检查的命名空间中，在某个别的翻译单元中声明了一个具有外部连接的更好的匹配声明，或者如果当同样检查这些翻译单元时其查找会导致歧义，那么行为未定义。无论哪种情况，如果某个基类取决于某个模板形参，那么无限定名字查找不会检查它的作用域（在定义点和实例化点都不会）。\n很长，但是看我们加粗的就够：\n非待决名：检查该模板的定义时将进行无限定的名字查找 待决名：它的查找会推迟到得知它的模板实参之时 这个故事告诉我们，this加不加是真的有区别的（this依赖模板参数是待决名）\nSFINAE SFINAE? “代换失败不是错误” (Substitution Failure Is Not An Error)\n在函数模板的重载决议1中会应用此规则：当模板形参在替换成显式指定的类型或推导出的类型失败时，从重载集中丢弃这个特化，而非导致编译失败。\n此特性被用于模板元编程。\n1 2 3 4 template\u0026lt;typename T, typename T2 = typename T::type\u0026gt; void f(int) { std::puts(\u0026#34;int\u0026#34;); } f\u0026lt;int\u0026gt;(5); 会报错：未找到匹配的重载函数\n因为这里显然 int::type 非良构（不符合语法），代换失败，会丢弃特化，但又没有找到其他重载函数。\n1 2 template\u0026lt;typename T\u0026gt; void f(double) { std::puts(\u0026#34;double\u0026#34;); } 这里会选择到 double 版本。\n可以用 typename + decltype 写条件，即可对传入的类型做出要求，比如 operator+ 等等\n对模板形参会进行两次代换（推导前指定，推导后）\n代换失败与硬错误 只有在函数类型或其模板形参类型或其 explicit 说明符 (C++20 起)的 立即语境 中的类型与表达式中的失败，才是 SFINAE 错误。\n**如果对代换后的类型/表达式的 求值导致副作用，例如实例化某模板特化、生成某隐式定义的成员函数等，那么这些副作用中的错误都被当做 硬错误 **。\nSFINAE 可以影响重载决议。\n尤其注意，进行实例化是硬错误。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 template\u0026lt;typename T\u0026gt; struct B { using type = typename T::type; }; template\u0026lt;typename T\u0026gt; void foo(double) { std::puts(\u0026#34;SFINAE\u0026#34;); } template\u0026lt; class T, class U = typename T::type,\t// 如果T 没有 type，就代换失败，如果没有这一行会因为下一行的 B\u0026lt;T\u0026gt; 硬错误编译失败 class V = typename B\u0026lt;T\u0026gt;::type\t// 这里就是实例化 \u0026gt; void foo(int) { std::puts(\u0026#34;SFINAE T::type, B\u0026lt;T\u0026gt;::type\u0026#34;); } int main() { foo\u0026lt;void\u0026gt;(1); } SFINAE 基础示例 需要写一个 add，要求其类型支持 operator+\n1 2 3 4 5 6 7 8 9 10 11 // 自然可以这里写 decltype，但是这样比较蛋疼 template\u0026lt;typename T, typename = decltype(T{} + T{}) \u0026gt; auto add(const T\u0026amp; a, const T\u0026amp; b) { return a + b; } // 使用 C++11 后置返回类型，此时知道 a 和 b 的类型 template\u0026lt;typename T\u0026gt; auto add(const T\u0026amp; a, const T\u0026amp; b) -\u0026gt; decltype(a + b) { return a + b; } 多用 SFINAE 等约束才能有更友好的报错和编译速度。\nstd::enable_if 如何要求模板提供的类型？\n第一个参数接受一个返回 bool 值的表达式\n1 2 3 4 5 6 7 8 template\u0026lt;bool B, class T = void\u0026gt; struct enable_if {}; template\u0026lt;class T\u0026gt; // 类模板偏特化 struct enable_if\u0026lt;true, T\u0026gt; { typedef T type; }; // 只有 B 为 true，才有 type，即 ::type 才合法 template\u0026lt; bool B, class T = void \u0026gt; using enable_if_t = typename enable_if\u0026lt;B,T\u0026gt;::type; // C++14 引入 这是一个模板类，在 C++11 引入，它的用法很简单，就是第一个模板参数为 true，此模板类就有 type，不然就没有，以此进行 SFINAE。\n为 false，那么会因为 SFINAE 不选择 true 的那个模板，从而错误。\nC++11，要求提供类型为 int，17之后就可以写的很简单了\n这里第二个typename 纯粹用来做 SFINAE，所以没有名字也无所谓\n1 2 3 4 5 template\u0026lt;typename T, typename = typename std::enable_if\u0026lt;std::is_same\u0026lt;T, int\u0026gt;::value\u0026gt;::type\u0026gt;\t//C++11 void f(T) {} template\u0026lt;typename T, typename = std::enable_if_t\u0026lt;std::is_same_v\u0026lt;T, int\u0026gt;\u0026gt;\u0026gt;\t//C++17 void f(T) {} 再例如 array，之前推导指引时候写过的，升级版本\n1 2 template \u0026lt;class Type, class... Args\u0026gt; array(Type, Args...) -\u0026gt; array\u0026lt;std::enable_if_t\u0026lt;(std::is_same_v\u0026lt;Type, Args\u0026gt; \u0026amp;\u0026amp; ...), Type\u0026gt;, sizeof...(Args) + 1\u0026gt;; (std::is_same_v\u0026lt;Type, Args\u0026gt; \u0026amp;\u0026amp; ...) 做 std::enable_if 的第一个模板实参，这里是一个一元右折叠，使用了 \u0026amp;\u0026amp; 运算符，也就是必须 std::is_same_v 全部为 true，才会是 true。简单的说就是要求类型形参包 Args 中的每一个类型全部都是一样的，不然就是替换失败。\nstd::void_t 1 2 template\u0026lt;class...\u0026gt; using void_t = void; 用此元函数检测 SFINAE 语境中的非良构类型\nvoid_t 防止你写一堆模版参数，这样你就可以写在一起只写一个 typename 了\n需求：函数模板 add，需要传入的对象支持 operator+，有别名 type，成员value f\n1 2 3 4 5 template\u0026lt;typename T, typename = std::void_t\u0026lt;decltype(T{} + T{}), typename T::type, decltype(\u0026amp;T::value), decltype(\u0026amp;T::f) \u0026gt;\u0026gt; auto add(const T\u0026amp; a, const T\u0026amp; b) { return a + b; } std::declval 在上面的 SFINAE 中，decltype(T{}+T{}) 要求 T 能默认构造，显然不正确，我们要的是operator+\n我们需要使用 std::declval\n1 decltype(std::declval\u0026lt;T\u0026gt;() + std::declval\u0026lt;T\u0026gt;()); 此时就没有问题了。\n1 2 template\u0026lt;class T\u0026gt; typename std::add_rvalue_reference\u0026lt;T\u0026gt;::type declval() noexcept; 这个函数特殊，只能用于不求值语境，不要求 T 有定义\n偏特化中的 SFINAE 在确定一个类或变量 (C++14 起)模板的特化是由部分特化还是主模板生成的时候也会出现推导与替换。在这种确定期间，部分特化的替换失败不会被当作硬错误，而是像函数模板一样*代换失败不是错误*，只是忽略这个部分特化。\n约束与概念 前言 C++20 的约束与概念，再也不用写蛋疼的 SFINAE\n约束与概念 类模板，函数模板，以及非模板函数（通常是类模板的成员），可以与一项约束（constraint）相关联，它指定了对模板实参的一些要求，这些要求可以被用于选择最恰当的函数重载和模板特化。\n这种要求的具名集合被称为概念（concept）。每个概念都是一个谓词，它在编译时求值，并在将之用作约束时成为模板接口的一部分。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 还是add，要求传入的对象支持 operator+ // 定义概念，概念是模板 // 概念，要求约束表达式成立 template\u0026lt;typename T\u0026gt; concept Add = requires(T a) { a + a; }; // 使用概念 template\u0026lt;Add T\u0026gt; auto add(const T\u0026amp; a, const T\u0026amp; b) { return a + b; } // 自然也可以 constexpr bool v = Add\u0026lt;int\u0026gt;; //true 概念定义, 约束表达式只要求在编译期求值，返回 bool 即可\n1 2 template \u0026lt; 模板形参列表 \u0026gt; concept 概念名 属性 (可选) = 约束表达式; 简写函数模板与标准概念库 简写函数模板：\n1 2 3 decltype(auto) max(const auto\u0026amp; a, const auto\u0026amp; b) { return a \u0026gt; b ? a : b; } 如果约束传入的对象怎么写？我们可以使用标准库设置，位于 concepts\n1 2 3 4 #include \u0026lt;concepts\u0026gt; decltype(auto) max(const std::integral auto\u0026amp; a, const std::integral auto\u0026amp; b) { return a \u0026gt; b ? a : b; } **此外，概念可以在所有使用 auto 的前面使用。**当然也可以要求个普通变量。\n变量模板、类模板都同理。\nrequires 子句 requires 只要求编译期求值的表达式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 template\u0026lt;typename T\u0026gt; concept Add = requires(T a) { a + a; }; template\u0026lt;typename T\u0026gt; requires add\u0026lt;T\u0026gt; void f(T) {} template\u0026lt;typename T\u0026gt; requires(sizeof(T) \u0026gt;= 4) void g(T) {} // 甚至可以 template\u0026lt;typename T\u0026gt; requires requires(T a) { a + a; } void h(T) {} // 第一个是 requires 子句，为 true 才会选择这个模板 // 第二个是 requires 表达式，恰好编译器求值 约束 - 合取析取 约束是逻辑操作和操作数的序列，它指定了对模板实参的要求。它们可以在 requires 表达式（见下文）中出现，也可以直接作为概念的主体。\n有三种类型的约束：\n合取（conjunction）(\u0026amp;\u0026amp;) 析取（disjunction） (||) requires 表达式 产生描述约束的 bool 类型的纯右值表达式。\n注意，requires 表达式 和 requires 子句，没关系。\n1 2 requires { 要求序列 } requires ( 形参列表 (可选) ) { 要求序列 } requires 表达式可以检测表达式是否合法，语句不合法会返回 false，而不会认为程序非脸狗\n1 2 3 4 5 6 7 8 template\u0026lt;typename T\u0026gt; void f(T) { constexpr bool v = requires { typename T::type;};\t// 待决名，不加 typename 会认为他是变量 } int main() { f(1); // v 此时为 false } 简单要求 简单要求是任何不以关键词 requires 开始的表达式语句。它断言该表达式是有效的。表达式是不求值的操作数；只检查语言的正确性。\n例如前文的 Add 概念的 requires 表达式\n1 2 3 4 5 template\u0026lt;typename T, typename U\u0026gt; concept Swappable = requires(T\u0026amp;\u0026amp; t, U\u0026amp;\u0026amp; u) { swap(std::forward\u0026lt;T\u0026gt;(t), std::forward\u0026lt;U\u0026gt;(u)); swap(std::forward\u0026lt;U\u0026gt;(u), std::forward\u0026lt;T\u0026gt;(t)); } 类型要求 类型要求是关键词 typename 后面接一个可以被限定的类型名称。该要求是，所指名的类型是有效的。\n可以用来验证：\n某个指名的嵌套类型是否存在。(typename T::type) 某个类模板特化是否指名了某个类型。(typename S\u0026lt;T\u0026gt;) 某个别名模板特化是否指名了某个类型。(using) 复合要求 1 { 表达式 } noexcept(可选) 返回类型要求 (可选) ; 返回类型要求：-\u0026gt; 类型约束（概念 concept）\n并断言所指名表达式的属性。替换和语义约束检查按以下顺序进行：\n模板实参 (若存在) 被替换到 表达式 中； 如果使用了noexcept，表达式 一定不能潜在抛出； 如果返回类型要求存在，则： 模板实参被替换到返回类型要求 中； decltype((表达式)) 必须满足类型约束 蕴含的约束。否则，被包含的 requires 表达式是 false。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 template\u0026lt;typename T\u0026gt; concept C2 = requires(T x) { // 首先 *x 得合法 // 类型要合法，这里要有嵌套类型 // 并且 *x 的结果必须可以转换为 T::inner {*x}-\u0026gt;std::convertible_to\u0026lt;typename T::inner\u0026gt;; // 表达式 x + 1 必须合法 // 并且 std::same_as\u0026lt;decltype((x + 1)), int\u0026gt; 必须满足 // 即, (x + 1) 必须为 int 类型的纯右值 // std::same_as 是个概念 {x + 1} -\u0026gt; std::same_as\u0026lt;int\u0026gt;; // 表达式 x * 1 必须合法 // 并且 它的结果必须可以转换为 T {x * 1} -\u0026gt; std::convertible_to\u0026lt;T\u0026gt;; // 复合：\u0026#34;x.~T()\u0026#34; 是不会抛出异常的合法表达式 { x.~T() } noexcept; } 嵌套要求 嵌套要求具有如下形式\n1 requires 约束表达式 ; 就是在 requires 里再写一个 requires\n1 2 3 4 5 6 7 8 9 template\u0026lt;typename T\u0026gt; concept C3 = requires(T a, std::size_t n) { requires std::is_same_v\u0026lt;T*, decltype(\u0026amp;a)\u0026gt;; // 要求 is_same_v 求值为 true requires std::same_as\u0026lt;T*, decltype(new T[n])\u0026gt;; // 要求 same_as 求值为 true requires requires{ a + a; }; // 要求 requires{ a + a; } 求值为 true requires sizeof(a) \u0026gt; 4; // 要求 sizeof(a) \u0026gt; 4 求值为 true }; std::cout \u0026lt;\u0026lt; std::boolalpha \u0026lt;\u0026lt; C3\u0026lt;int\u0026gt; \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // false std::cout \u0026lt;\u0026lt; std::boolalpha \u0026lt;\u0026lt; C3\u0026lt;double\u0026gt; \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // true 在上面示例中 requires requires{ a + a; } 其实是更加麻烦的写法，目的只是为了展示 requires 表达式是编译期产生 bool 值的表达式，所以有可能会有两个 requires连用的情况；我们完全可以直接改成 a + a，效果完全一样。\n这里用 std::is_same_v 和 std::same_as 其实毫无区别，因为它们都是编译时求值，返回 bool 值的表达式。\n总结 总之记住：\n可以连用 requires requires 的情况，都是因为第一个 requires 期待一个可以编译期产生 bool 值的表达式；而 requires 表达式就是产生描述约束的 bool 类型的纯右值表达式。\n","date":"2024-02-12T09:00:00Z","permalink":"https://rossqaq.github.io/article/modern-cxx-template/","title":"现代 C++ 模板应该学习什么？"},{"content":"本文是文章 Why you should use io_uring for network I/O 的翻译。\n一起来从头认识 linux 最新的 io_uring\nio_uring 是 linux 的异步 I/O 接口，对网络编程可能很有用。对于文件 IO 来说十分好用，但对于网络 IO 可能只能享受到一小部分收益，因为已经有非阻塞 I/O 的 API了。收益可能是因为：\n在上下文切换频繁的服务器中，减少系统调用次数 对文件和网络 I/O 提供统一 API io_uring 需要比较新的 linux 版本。\nio_uring 是什么 io_uring 是 linux 内核的异步 IO 接口，io_uring 是位于共享内存中的一对环形缓冲区，其是一对环形的介于内核和用户之间的队列。\nSubmission Queue (SQ): 用户进程使用 SQ 来向内核发送异步 I/O 请求。 Completion Queue (CQ): 内核会将异步 IO 的结果通过 CQ 来返回给用户。 这个接口允许应用程序从传统的 readiness-based IO 模型变成新的 completion-based 模型，文件和网络IO共享统一的 API。\n系统调用 API linux 内核为 io_uring 提供了 3 个 syscall api：\nio_uring_setup : 准备一个 context 来执行异步 IO\nio_uring_register : 注册异步 IO 的文件或者用户 buffer\nio_uring_enter: 调用 and/or 完成异步 IO\n前两个 syscall 用于创建 io_uring 实例，并选择是否让 io_uring 使用提前准备好的 buffer 来执行操作。只有 io_uring_enter 需要在提交和消费队列时被调用。io_uring_enter 的开销可以通过许多 IO 操作摊销。对于很繁忙的服务器，你可以通过开启 SQ 的 busy-polling 来避免多次调用 io_uring_enter ，代价是内核线程消耗 CPU。\nliburing liburing 提供了一个方便的使用 io_uring 的方式，隐藏了复杂的细节并且提供了函数来准备所有类型 IO 操作的 submission。\n用户进程创建 io_uring:\n1 2 struct io_uring ring; io_uring_queue_init(QUEUE_DEPTH, \u0026amp;ring, 0); 之后向 SQ 提交操作：\n1 2 3 4 struct io_uring_sqe *sqe = io_uring_get_sqe(\u0026amp;ring); io_uring_prep_readv(sqe, client_socket, iov, 1, 0); io_uring_sqe_set_data(sqe, user_data); io_uring_submit(\u0026amp;ring); 进程等待 completion：\n1 2 struct io_uring_cqe *cqe; int ret = io_uring_wait_cqe(\u0026amp;ring, \u0026amp;cqe); 使用返回内容：\n1 2 3 4 5 6 7 user_data = io_uring_cqe_get_data(cqe); if (cqe-\u0026gt;res \u0026lt; 0) { // handle error; } else { // response } io_uring_cqe_seen(\u0026amp;ring, cqe); 优先推荐通过使用 liburing API 来使用 io_uring，liburing 拥有 io_uring 最新版本的所有特性，并且兼容老版本的 kernel。\n使用 io_uring 进行网络 I/O 我们通过编写一个简单的 echo server 来尝试使用 io_uring。然后我们就可以看到如何最少化系统调用来完成高并发。\n简单的 echo server 经典的例子会像：\n1 2 3 4 5 6 7 8 9 10 client_fd = accept(listen_fd, \u0026amp;client_addr, \u0026amp;client_addr_len); for (;;) { numRead = read(client_fd, buf, BUF_SIZE); if (numRead \u0026lt;= 0) break; if (write(client_fd, buf, numRead) != numRead) { // handle error } } close(client_fd); 服务器必须使用多线程或者使用非阻塞 I/O 来支持并发请求，不管他什么形式，每有一个客户端服务器都必须至少 5 个系统调用，accept, read, write, read 检测 EOF，close\n使用 io_uring 的版本的异步服务器一次提交一个操作请求并且在下次提交时等待 completion。io_uring 版本的服务器伪代码大概如下（省略样板和错误处理）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 add_accept_request(listen_socket, \u0026amp;client_addr, \u0026amp;client_addr_len); io_uring_submit(\u0026amp;ring); while (1) { int ret = io_uring_wait_cqe(\u0026amp;ring, \u0026amp;cqe); struct reqeust *req = (struct reqeust*) cqe-\u0026gt;user_data; switch(req-\u0026gt;type) { case ACCEPT: add_accept_request(listen_socket, \u0026amp;client_addr, \u0026amp;client_addr_len); add_read_request(cqe-\u0026gt;res); io_uring_submit(\u0026amp;ring); break; case READ: if (cqe-\u0026gt;res \u0026lt;= 0) { add_close_request(req); } else { add_write_request(req); } io_uring_submit(\u0026amp;ring); break; case WRITE: add_read_request(req-\u0026gt;socket); io_uring_submit(\u0026amp;ring); break; case CLOSE: free_request(req); break; DEFAULT: fprintf(stderr, \u0026#34;Unexpected req type %d\\n\u0026#34;, req-\u0026gt;type); break; } io_uring_cqe_seen(\u0026amp;ring, cqe); } 在这个 io_uring 的示例中，服务器需要至少 4 个系统调用。唯一省略的是通过一次性提交 read 和新 accept 请求。可以通过以下的 strace 输出来查看服务器收到 1000 个客户端请求：\n1 2 3 4 5 6 % time seconds usecs/call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 99.99 0.445109 111 4001 io_uring_enter 0.01 0.000063 63 1 brk ------ ----------- ----------- --------- --------- ---------------- 100.00 0.445172 111 4002 total 组合提交 在 echo 服务器中，因为我们必须在写之前完成读所以限制了我们串联 IO 操作的机会。我们可以链接 accept 和 read，通过使用 io_uring 的 fixed file 特性，但我们已经一次性一起提交了 read 请求和 new accept 请求，所以可能不会有多少收益。\n我们可以在同一时间提交互相不依赖的操作，所以我们可以 combine 写之后读的提交。这会将 syscall 减少到 3次。\n1 2 3 4 5 6 % time seconds usecs/call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 99.93 0.438697 146 3001 io_uring_enter 0.07 0.000325 325 1 brk ------ ----------- ----------- --------- --------- ---------------- 100.00 0.439022 146 3002 total Draning the completion queue 如果我们在调用 io_uring_submit 前解决了所有已经进入队列的 completions，那么就可以一次性一起提交更多的操作。我们可以通过使用 io_uring_wait_cqe 来等待 work，之后调用 io_uring_peek_cqe 来检查是否 completion queue 还有空间容纳未被处理的操作。这避免了忙循环中 completion queue 为空时的自旋等待，并且会尽快消耗 completion queue。\n主循环的伪代码类似于：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 while (1) { int submissions = 0; int ret = io_uring_wait_cqe(\u0026amp;ring, \u0026amp;cqe); while (1) { struct request *req = (struct request *) cqe-\u0026gt;user_data; switch (req-\u0026gt;type) { case ACCEPT: add_accept_request(listen_socket, \u0026amp;client_addr, \u0026amp;client_addr_len); add_read_request(cqe-\u0026gt;res); submissions += 2; break; case READ: if (cqe-\u0026gt;res \u0026lt;= 0) { add_close_request(req); submissions += 1; } else { add_write_request(req); add_read_request(req-\u0026gt;socket); submissions += 2; } break; case WRITE: break; case CLOSE: free_request(req); break; default: fprintf(stderr, \u0026#34;Unexpected req type %d\\n\u0026#34;, req-\u0026gt;type); break; } io_uring_cqe_seen(\u0026amp;ring, cqe); if (io_uring_sq_space_left(\u0026amp;ring) \u0026lt; MAX_SQE_PER_LOOP) { break; // the submission queue is full } ret = io_uring_peek_cqe(\u0026amp;ring, \u0026amp;cqe); if (ret == -EAGAIN) { break; // no remaining work in completion queue } } if (submissions \u0026gt; 0) { io_uring_submit(\u0026amp;ring); } } 这样即可有极大的提升：\n1 2 3 4 5 6 % time seconds usecs/call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 99.91 0.324226 4104 79 io_uring_enter 0.09 0.000286 286 1 brk ------ ----------- ----------- --------- --------- ---------------- 100.00 0.324512 4056 80 total 提升显著，一次 syscall 可以处理多于 12 个的客户端请求，或者每次 syscall 平均多余 60次 IO ops。随着服务器越来越忙，比率也会提高，可以通过日志证明：\n1 2 3 4 5 6 7 % time seconds usecs/call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 68.86 0.225228 42 5308 286 write 31.13 0.101831 4427 23 io_uring_enter 0.00 0.000009 9 1 brk ------ ----------- ----------- --------- --------- ---------------- 100.00 0.327068 61 5332 286 total 这表明当服务器有更多工作要做时， io_uring 操作有更多时间完成，所以一次 syscall 可以提交的 work 更多。echo server 可以通过仅仅 23 个 syscall 就完成 1000个 echo 请求或者 5000 个 socket I/O.\n需要注意的是，随着提交 work 数量的增加，io_uring_enter 的调用时间消耗也会增加，到某个节点时可能需要限制提交的批处理大小或者开启内核的 submission queue polling。\n网络 I/O 的收益 io_uring 对于网络 IO 的效果则是更现代更容易使用的异步 API 以及统一的文件与网络 IO 语义。\n潜在的收益是减少 syscall 次数，这可以在小的syscall操作占比高以及频繁切换上下文的场景下获得比较高的收益。\n可以通过在发送 io_uring 请求前向内核预先注册资源来避免在服务器上基类昂贵的操作。可以注册 file slots 和 buffers 来避免每次 IO 操作的查找和引用计数成本。\n注册 file slots，称为 fixed files，也可以实现在 read 和 write 中链接 accept，而不用再在用户态绕一圈。submission queue entry（SQE）需要指定 fixed file slot 来存储之后 SQE 需要在 IO 中引用的 accept 的返回值。\n限制 理论上，操作可以通过使用 IOSQE_IO_LINK 标记来链在一起。然而对于读写，没有机制可以强制读操作的返回值作为参数输入到写操作中。这限制了某些语义顺序，例如：写后读，写后关闭，以及 accept 后的读或写。\n另外一个需要考虑的是 io_uring 是仍在开发中的 linux kernel 特性，某些特性可能以后会优化。\nio_uring 现在是 Linux 限定 API，所以将他移植进例如 libuv 这种库中很难。\n最新特性 io_uring 的最新特性是 multi-shot accept, 5.19 后的内核支持，以及 multi-shot receive，6.0后的内核支持。multi-shot accept 允许一个应用程序发出单个 accept SQE，当内核收到新的请求时会一直post CQE。Multi-shot 也会在每次新数据可用时post CQE。\n结论 io_uring API 是一个函数式异步 IO API，为文件和网络 IO 提供统一的接口。他有潜力成为更好的网络 IO 的基础，并为混合网络和文件 IO 的应用程序提供更大优势。\n著名的异步 IO 库，例如 libuv 是多平台的，适配 Linux 特供 API 比较困难，当一个库中加入 io_uring，不管是文件 IO 还是网络 IO ，都会从 io_uring 的异步 completion 模型中获得收益。\n网络相关 IO 开发和优化会持续进行。现在是时候使用 io_uring 了。\n其他推荐资料 原生的 Linux 异步文件操作，io_uring 尝鲜体验\nWelcome to Lord of the io_uring — Lord of the io_uring documentation (unixism.net)\n","date":"2024-02-12T00:00:00Z","permalink":"https://rossqaq.github.io/article/io_uring-intro/","title":"你为什么应该使用 io_uring"},{"content":"编写你自己的 C++20 协程系统 本文翻译自 Writing custom C++20 coroutine systems\n目前 5.2 generator 部分尚未翻译，其余已经烤制完毕。\n介绍 在 2023 年，我给使用过 C++ 旧版本的人做了一个三天的 C++20 新特性介绍讲座。\n其中的一个新特性那就是 built-in language 支持的协程。我个人非常期待讲那个部分，因为我已经把协程当做我的代码风格一部分了。我甚至花费了大量精力通过使用 C 的预处理来实现写成，PuTTY 在它的 SSH 协议实现中也大量使用了该技术。另外一个我的程序，spigot（交互式计算器）也在 C++ 中用了类似的技术。\n所以我非常期待使用 C++ 的原生协程，至少 我需要知道是否可以将使用预处理器版本的 spigot 使用原生协程重构，以及其他一切我可能会用上的内容。\n不幸的是，C++20 的协程系统非常庞大、复杂，需要很多笔墨来解释。所以那三天的讲座中并没有完全讲完 C++20 的新特性，事实证明，甚至没有时间解释太多细节。（更别提你还要从解释协程是什么开始，因为有很多人并不知道协程）\n于是我写了这篇文章。\n努力学习并把它写完后，似乎自己藏着不太好。所以这篇文章是我的学习笔记，经过精心打磨后希望对其他人也有用。\n文章中我会展示所有的代码来阐述我自己的目的。大多数都不能工作：他们会缺失一部分，以免完全不相干的细节吸引了读者的注意力。有时为了清晰，我甚至会故意犯错（例如把函数定义放在类中，你应该避免这么做来防止前向声明）。大多数部分都有可下载的可以编译运行版本的代码。\nC++ 协程概览 C++ 协程有许多其他语言（例如 python generator）不具备的灵活性，但灵活也代表着你需要自定许多内容才能让其正常工作。他不像是协程系统，而更像是给你一个工具，让你自己搭建自己的协程系统。\n函数和协程之间原点比较像。你不需要在函数体外将其声明为协程。（即，调用者不需要知道他们调用的是否是协程，他们只需要知道当调用函数，会返回一个对象）\n在 Python 中，在函数中写一个 yield 即可，作用就是当你调用函数时，其内部的代码暂时不会执行，你只会得到一个 \u0026lsquo;generator\u0026rsquo; 对象，函数的代码是暂停的，直到你在 generator 对象上进行一些操作时才会执行一点。只有一种 generator，提供的操作也是固定的（next()和 send()），且他们做的内容也差不多。\nC++ 中同理，不同的是有三个关键字：co_yield, co_await and co_return。函数中使用任何一个关键字都会让编译器认为其是一个协程。但你可以控制其下一步执行的流程。\n举个例子，假如你的协程大部分情况下都是 接收数据，当其接收第一个 item 后你就希望立刻运行他。这样的话，当某人调用协程并创建它的实例时，这个实例已经处于准备好接收一个值的状态。Python 并不能这么做，因为 generator 总是在一开始暂停，由此正常的用法是在返回的对象上调用一次 next() 来获得第一项数据。但在 C++ 中，你可以按你的想法来定义协程的行为。\n在 Python 中，在协程内调用 yield 会暂停这部分代码的执行并且将控制权返回给调用 next() 的调用者。所以如果你想生成一个值并且把它传递给另外一个协程（就是说，从一个生产者协程将对象传递给一个消费者协程），你需要手动在调用者方实现。在 C++ 中，你可以以你喜欢的方式实现，但是你也可以 让协程自动在它们之间转移控制权。因此，在调用方的所需要的值实际可用之前，控制权不会返回给调用方。或者你也可以 co_yield 生成一个值但是完全不暂停协程，继续运行。\n在 Python 中，同样 yield 语句会生成一个值 且 接收一个输入值（如果协程需要）。在 C++ 中，co_yield 和 co_await 是分开的，你可以将其用于不同的用途：co_yield 向外传值，co_await 等待输入，或者（如果你喜欢的话）等待某些事件发生。所以如果你的协程需要从 “这里” 读取一个对象并把它写入 “那里”，那么这些语句可以帮在语义上你区分功能。\n在 Python 中，协程实际不存在与生成值流可区分的 “返回值” 的概念。在 C++ 中，是：你可以使用 co_return 来结束整个协程，你可以给他一个值返回，可以跟你 yield 的值不同类型不同语义。\n更复杂一点的例子，假设使用协程来实现一个网络协议，通过从 event loop 中重复调用回调来执行底层的网络 I/O 以发送或接收单独的协议消息或数据包。你可以 set it up 这样就可以通过 co_await 来获取下一个输入的数据包（可能不需要暂停协程，如果队列中已经存在收到的数据的话）可以调用 co_yield 来向外传递数据包；当其完成时，可以调用 co_return 来给整个流程发信号，例如整个事务是否成功。\n然而，这些都得你自己完成。为了使用 C++20 的协程，你必须编写大量的前置代码（造轮子），然后回答以下问题：\n协程在启动时需要暂停吗？ co_yield, co_await, co_return 需要的数据类型是什么？每一个关键字是干什么的？传递给他们的值会发生什么？如果有的话，协程恢复时从 co_await, co_yield 传回 的数据是什么？ co_await, co_yield 的具体哪一步会暂停协程？哪一个会立刻运行？ 协程暂停时，会立刻将控制权返回给上次恢复他的 caller 吗？还是切换到另外暂停一个协程？ Python 中，这些问题的答案是固定的。在 C++ 中，答案是：这些全部取决于你。你可以根据你的程序来决定具体采用哪种方式。但换句话说，你需要自己做完所有的工作才能找出答案。\n至少，在C++20标准中你只能自己完成这些工作。C++23 引入了一些协程系统，如 std::generator，类似 Python 的 generator。如果你需要的是类似于 Python 的 generator，那么你可以使用 C++23。\n但如果你想要额外的灵活性，或者无法使用 C++23，那么你需要自己完成全部工作，这也是这篇文章介绍的内容。\n数据类型的总结 C++ 的协程系统包含了许多不同的数据类型。在深入理解之前，这一部分我们先区分并且理解一下他们在内部是怎么交互的。\nC++ 实现自身提供了一个数据结构：coroutine handle。所有魔法都来自于他。它定义了你协程代码的一个特殊实例，包含了它内部的变量以及执行状态（例如它现在是否正在运行，如果不是的话，它下次会从哪里恢复）。它提供了一个 resume 方法，通过调用他就可以恢复协程执行。\n其他的数据类型都由你也就是实现者提供，因此你可以根据你自己想让协程执行的方式来定义他们。\n最明显的类型就是协程定义为返回值的类型。用户 唯一能看到的就是这个类型（不管他们是根据你的前置代码写协程，还是调用协程）。所以，在这篇文章我会把它称为：用户感知类型（user-facing type），它的实例则为：用户感知对象（user-facing object）\n用户感知类型是协程的 caller 实际交互的类型。所以你对其定义的方法取决于你希望 如何 与用户交互。例如，你可能想让他可以迭代（提供 begin() and end()，并且迭代器可以和自增运算符交互），这样你就可以使用 range-based for loop 了。（C++23 已经提供了 std::generator）或者你也可以选择像使用 istream/ostream 一样使用他，当然也可以是其他任何的方法，这都取决于你。\n实际上，C++对于用户感知类型 没有 什么特殊需求。不需要有任何特定名称的方法或者字段。甚至不需要是一个类类型，如果你不想的话。你可以让他是一个平凡类型，比如 int，让他扮演一个 index 来访问当前激活协程的一个巨大的表格。当然，让他成为类类型更常见，但不是必须。\n在这个实现中，你的特殊协程首要的 data type 叫做 promise type。\n我个人更喜欢称之为 \u0026lsquo;policy type\u0026rsquo;, 因为它主要的作用是定义你的协程策略。C++ 称他为 \u0026lsquo;promise\u0026rsquo; 是因为他也可以代表异步计算模型中的 \u0026lsquo;future/promise\u0026rsquo;。但其语义上，policy type always, promise type sometimes，所以我经常叫他 \u0026lsquo;policy type\u0026rsquo;，更接近于设计初衷。但是 \u0026lsquo;promise\u0026rsquo; 是标准的叫法，而且作为标识，所以以下我们也会称之为 promise。\nThis is inferred from the user-facing type (and, optionally, the rest of the coroutine’s arguments). 它必须是一个类类型，必须提供一些具有特殊名称的方法来控制执行策略，例如开始时是否暂停，结束时是否将控制权转移给其他协程，如果遇到 co_await, co_yield, co_return 后该如何执行。每个协程的实例只有一个（编译器在第一次调用协程时创建他），自然也方便存储协程有关的数据。例如，在 stacked 协程启动时，你可能需要一个指针在栈中来存储 promise object。在协程中通过 co_yield 向外传递值，放置 yielded value 最方便的地方就是在 promise object 中，之后用户感知对象就可以将其传递 caller。\n最后，有一种叫做 awaiters 的类型（有时也称之为 awaitable）。他为每个事件来设置策略以暂停协程。特别地，每次协程执行 co_yield, co_await, co_return，promise type 都会构造一个新的 awaiter 用于特殊事件，调用 awaiter 的方法来决定发生什么（例如是否暂停协程本身；如果暂停的话，是否将控制权返回给 caller 或是其他协程；协程什么时候恢复；通过 co_yield 或者 co_await 返回什么）。Awaiter 类型可以指定你的特殊行为，或者在多个类型的协程中共享。总之，标准库提供了一些定义好的 Awaiter 以完成最简单的功能，他们是：std::suspend_always 以及 std::suspend_never\n如何编写协程的 promise class 快速开始：让他至少能编译 在深入理解所有的方法是做什么的之前，我们先从最简单的协程开始，让他至少能够编译，并且执行一些代码。之后我会列出实现所必须的内容，你可以将他们与例子进行关联。\n事不宜迟，以下是协程的 Hello World：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;coroutine\u0026gt; #include \u0026lt;iostream\u0026gt; class UserFacing { public: struct promise_type { UserFacing get_return_object() { return {}; } std::suspend_never initial_suspend() { return {}; } void return_void() {} void unhandled_exception() {} std::suspend_always final_suspend() noexcept { return {}; } }; }; UserFacing demo_coro() { std::cout \u0026lt;\u0026lt; \u0026#34;Hello World\\n\u0026#34;; co_return; } int main() { UserFacing demo = demo_coro(); } 以上代码片段是协程的最小实现，满足了其最小要求。\n包括：\n用户感知类型中包含 promise_type。编译器看到你定义了协程的返回类型 UserFacing 时，首先要做的就是查找其关联的 promise_type\n默认 （但不是唯一）实现其的方式是实现 UserFacing::promise_type ，在这个简单的例子里我会直接把 promise type 写在 UserFacing 类中。第二种方法是分开定义，在 UserFacing 中包含其声明即可\n1 2 3 4 class UserFacing { public: using promise_type = TheActualPromiseType; }; 此外还有第三种方法，无需在用户感知类型中实现 任何 定义。这需要你提供你自己的 std::coroutine_traits 模板特化（重载默认寻找 UserFacing::promise_type 的版本）。我们之后会举例说明，例子中协程的返回值是 std::unique_ptr\n构造一个用户感知类型返回的实例。你的协程初始化时，C++实现会创建 promise_type 的实例，并为其分配内存。不过 caller 接受到的返回对象取决于你。\n这一步通过 promise_type 中的 get_return_object() 实现。在里子中，UserFacing 没有任何数据成员，所以 get_return_object() 通过完全平凡的方式来进行构造。\n如果不是平凡类型，那么你可能需要给用户感知对象更多的信息。例如，用户感知对象几乎都需要访问 coroutine handle 以及 promise type，这样才能跟其他暂停的协程通信。由于现在是最小实现，所以目前我们还没有实现他，下一部分会看到的。\n指定协程启动时是否暂停，或者直接运行。通过 initial_suspend() 实现，必须返回一个 awaiter。我们之后会看到 awaiter 的全部细节。目前，我们只是使用了 C++ 标准库提供的：std::suspend_never。这样协程就 不会 在开始执行之前暂停自己，意味着在控制流返回给 main() 前，协程会一直运行，并且输出 Hello World。\n如果我们让 initial_suspend() 返回另一个标准类型：std::suspend_always，那么新创建的协程会在函数体开始执行前就暂停，before 打印 hello world。所以直到 main 中的某一部分调用 resume 前都不会执行协程。但我们目前还没展示如何做。目前来看，我们的协程开始执行前不暂停，因为只有这样他才能打印正确的信息。\n(std::suspend_always 和 std::suspend_never 都不包含任何有趣的数据，他们只是返回固定值的方法。所以你不需要在你构造时提供任何信息，只是单纯调用 return {} 即可)\n指定在协程正常返回时的行为。在这个例子中，协程不返回任何值（co_return 语句没有参数）。所以我们在 promise_type 中实现一个 return_void() 函数，这是 co_return 或者协程结束时实际执行的函数（因为没有返回值）。\n如果我想让协程拥有一个 non-void 返回值，那么就应该实现 return_value() ，接受一个参数，之后会在执行 co_return 时被调用。\n注意，你必须 在二者中选择一个实现！都不实现，或者都实现都是错误。\n（如果你的协程想要返回值，而函数末尾不执行 co_return，那么这是ub，就像返回具体值的函数没有 non-void return 语句一样）\n指定异常从协程传出时的行为。如果协程内的代码抛出异常，并且没有东西 catch 住它，那么 promise 对象的 unhandled_exception() 方法会被调用。它会接受异常并存储它，之后做一些有用的事情。\n在之后的部分我们会看到其执行细节，并且展示一些复杂的案例。在这个最小示例中，unhandled_exception 什么都没干，这意味着异常会被无视，协程会保持相同状态，仿佛其正常终止一样。\n指定协程结束时的行为。通过 final_suspend 方法指定，和 initial_suspend 一样，除了他被声明为 noexcept（如果这时候有异常，就像在析构函数有异常一样）\nfinal_suspend 会在协程被以 任何 方式终止时调用，不管是 return 还是抛出异常。\n示例中，final_suspend 返回 std::suspend_always，意味着协程结束时（不管是 co_return，还是单纯执行完函数体），它都会暂停当前状态并返回控制权。\n你 不可以 通过 final_suspend 让协程继续运行来返回值，这会导致崩溃或者其他 ub。这里唯一的用途就是不直接将控制权返回给 caller，而是转给其他协程。后面会有示例。\nFull source code for this section: co_demo.minimal.cpp.\n使用 co_await 暂停协程 目前，我们的协程功能很少，因为你不能暂停和恢复它，而暂停和恢复才是协程的关键。\nC++ 提供了两个关键字来暂停协程：co_yield, co_await，co_await 更基础更常用。co_yield 是它的一个语法糖。所以我们先来介绍 co_await。\n提供两个关键字的点在于：await 用于提醒你想要 等待 一个东西，而 yield 则是表明你想要给某些人传递一个值。你并不强制需要为实现不同的目的使用两个关键字，你写代码是为了做事情，所以你可以按你的想法来。但通常的语义是这样。\n总的来说，不管你给 co_await 什么操作数，编译器都需要把它转换成 awaiter 这样才能管理暂停。\n最简单 的方法就是提供一个 已经 是 awaiter 的对象。我们前文已经提到了，std::suspend_always 和 std::suspend_never。所以我们可以简单改改 demo：\n1 2 3 4 5 6 UserFacing demo_coro() { std::cout \u0026lt;\u0026lt; \u0026#34;we\u0026#39;re about to suspend this coroutine\u0026#34; \u0026lt;\u0026lt; std::endl; co_await std::suspend_always{}; std::cout \u0026lt;\u0026lt; \u0026#34;this won\u0026#39;t be printed until after we resume\u0026#34; \u0026lt;\u0026lt; std::endl; co_return; } 这是最简单的暂停协程的方式，但更常见的，如果你的协程正等待什么事情，你需要在事件发生后恢复协程，所以你需要一些 handler。\n有两个地方可以插入 handler：\n如果你的 promise type 有 await_transform() 方法，接受的参数类型为你传递给 co_await 的参数的类型，那么会调用这个方法，co_await 的参数也会变成该函数的返回值。（你当然可以重载这个函数） 如果在作用域中有一个函数叫做 operator co_await() 接收相应的类型，那么会调用这个函数，同样参数也会被替换为返回值。 如果两个都存在，那么会按顺序调用，所以 co_await foo; 也许会通过 operator co_await(promise.await_transform(foo)) 来构造 awaiter\n不太明白使用 operator co_await() 的意义，因为他不能是类成员，只能是全局函数，所以不能访问 promise type 的对象。看起来灵活性不高。在我的例子中，我只会使用 await_transform()。\n所以你可以把想要等待得到的结果传递给 co_await，然后其在背后通过你的 promise type 的 await_transform() 来实际返回合适的 awaiter。\n实际的使用中，你大概会让 await_transform() 来做一些工作。例如，你的程序基于某些监听 I/O channel 的时间循环，比如网络连接，然后它可能持有一些数据结构来告诉它对于每个 IO 事件，当某些事件发生时该恢复哪个协程。（For example, if your program was based around some kind of event loop that was monitoring I/O channels like network connections, then it would have some data structure that told it what to do about each possible I/O event, perhaps including what coroutine(s) to resume when an event happened. ）\n所以如果一个协程想要在做其他工作前等待 IO，你可能会写 co_await event （可能你会实现一些方便在协程内部操作代表 IO 事件的类型），然后相应的 await_transform() 会将调用协程的代码插入 event loop 的数据结构中来管理好实际发生的事情。\n但我们在这个例子中不需要复杂的事件，我们尽量简单。我们假设存在一个 dummy event 类型，不包含数据，然后 await_transform() 接受他：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 struct Event { // you could put a description of a specific event in here }; class UserFacing { // ... class promise_type { public: // ... std::suspend_always await_transform(Event) { // you could write code here that adjusted the main // program\u0026#39;s data structures to ensure the coroutine would // be resumed at the right time return {}; } }; }; 然后你就可以 co_await 你的事件描述符了：\n1 2 3 4 5 6 UserFacing demo_coroutine() { std::cout \u0026lt;\u0026lt; \u0026#34;we\u0026#39;re about to suspend this coroutine\u0026#34; \u0026lt;\u0026lt; std::endl; co_await Event{}; std::cout \u0026lt;\u0026lt; \u0026#34;this won\u0026#39;t be printed until after we resume\u0026#34; \u0026lt;\u0026lt; std::endl; co_return; } 这个例子中，我的 await transform 返回的是 std::suspend_always。你也可以返回自定义 awaiter 类型，这样更加灵活。特别的，在某些时候，可能你等待的事件已经完成了，这时你自定义的 awaiter 类型最好不要暂停，而是继续执行。\n自定义 awaiter 也可以控制 co_await 表达式的返回值，例如，假如你要等待网络事件并输出一个值，或者传出一个成功或者失败的状态。那么你的代码可能就会像：\n1 2 3 4 5 6 7 8 9 10 11 UserFacing demo_coro() { // You might set up co_await to return actual data ip_address addr = co_await async_dns_lookup(\u0026#34;hostname.example.com\u0026#34;); // Or a boolean indicating success or failure if (co_await attempt_some_network_operation(addr)) { std::cout \u0026lt;\u0026lt; \u0026#34;succuess\\n\u0026#34;; } else { std::cout \u0026lt;\u0026lt; \u0026#34;failure.\\n\u0026#34;; } } 之后我们会实现一个自定义 awaiter。本节已经够长了。\nFull source code for this section: co_demo.await.cpp.\n恢复协程 现在我们几乎已经接近可用的协程了。我们可以构造一个协程，在里面运行代码，之后暂停它。但到这里协程依然没有用，我们需要在暂停后 恢复 协程。\n恢复协程的办法是在它的 coroutine handle 上调用 resume() ，那么首先我们需要获取协程的句柄。\ncoroutine handle 是一个泛型类型，参数是promise type。所以如果你的 Promise type 叫做 P（举例），那么使用 P 作为 promise type 的协程其句柄就叫做 std::coroutine_handle\u0026lt;P\u0026gt;\n（还有泛型 std::coroutine_handle\u0026lt;\u0026gt;，是 std::coroutine_handle\u0026lt;void\u0026gt; 的简写。这个句柄使用的是类型擦除后的 void* 泛型指针：可以存储 任何 类型的协程句柄，不管其promise type是什么）\n协程句柄和 promise type 在同一时间由编译器帮你构造，他们二者互相转化非常简单：\n通过 promise 得到 handle，调用 coroutine handle 的静态函数：from_promise() 即可，将你的 promise 对象传给他 通过 handle 得到 promise，调用 handle 的 promise() 方法，会返回响应 promise 对象的引用 我能构造协程实例时，实现会调用 Promise type 的 get_return_object() ，他已经跟 promise 对象的引用关联了（即*this），我们可以通过他来构造协程句柄。\n我们得到他之后要干什么呢？我们把它传递给用户感知类型的构造函数，因为那是用户通过操作对象来恢复协程，用户需要知道哪里来寻找 coroutine handle。\nstd::coroutine_handle\u0026lt;P\u0026gt; 非常明确而且有点长，所以以后会通过 alias 来将他称为 handle_type。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class UserFacing { public: class promise_type; using handle_type = std::coroutine_handle\u0026lt;promise_type\u0026gt;; class promise_type { public: UserFacing get_return_object() { auto handle = handle_type::from_promise(*this); return UserFacing{handle}; } // ... }; // ... }; 当然，你的构造函数也需要接受 coroutine handle 作为参数，然后把它作为数据保存。至少得是：\n1 2 3 4 5 6 7 8 9 10 11 12 class UserFacing { // ... private: handle_type handle; UserFacing(handle_type handle) : handle(handle) {} public: void resume() { handle.resume(); } }; 实现了一个最简单的版本，通过给用户感知类型一个 resume 函数，单纯调用 handle 的 resume。\n注意：构造函数现在是 private。我觉得这是一个使用 private 方法的不错例子：唯一合法的调用是在 promise_type 中调用的那个构造函数，这样的话 API 也完全是 promise type 和 用户感知类型之间内部的。因此你可以随心所欲的对其进行修改，而不用担心改变其他地方的用途。\n在这种场景下，构造函数的调用在 promise_type 中，其定义在 UserFacing 内部，因此他自动是 UserFacing 的 private 成员。如果我们想把二者分开定义，我们需要显式声明 promise_type 为 friend，或者让构造函数 public。\n现在我们就可以恢复我们的协程了，调用刚才实现的方法：\n1 2 3 4 5 6 7 8 9 10 11 UserFacing demo_coroutine() { std::cout \u0026lt;\u0026lt; \u0026#34;we\u0026#39;re about to suspend this coroutine\u0026#34; \u0026lt;\u0026lt; std::endl; co_await Event{}; std::cout \u0026lt;\u0026lt; \u0026#34;we\u0026#39;ve successfully resumed the coroutine\u0026#34; \u0026lt;\u0026lt; std::endl; } int main() { UserFacing demo_instance = demo_coroutine(); std::cout \u0026lt;\u0026lt; \u0026#34;we\u0026#39;re back in main()\u0026#34; \u0026lt;\u0026lt; std::endl; demo_instance.resume(); } 结果：\n1 2 3 we\u0026#39;re about to suspend this coroutine we\u0026#39;re back in main() we\u0026#39;ve successfully resumed the coroutine 终于……讲了三节，我们终于可以暂停和恢复协程了！\n（注意这里我移除了 co_return，之前他存在的意义是让函数变为协程，但是现在有 co_await 了，也能干一样的事，且我们不需要 co_return 来返回，我们可以让协程执行到底来自动返回）\nFull source code for this section: co_demo.resume.cpp.\n处理协程状态 现在我们把协程句柄存储在用户感知对象里了，现在是时候处理无聊的部分：内存管理。\n我们没有自己手动写分配 promise 对象的代码。C++ 实现帮我们在背后做了。所以我们需要担心的是他会如何被回收。如果我们不做的话，那么协程就会有 built-in 内存泄露。\n并不能自动回收协程，你需要手动管理，通过调用 handle 的 destroy()\n最简单的办法是先删除复制构造函数和复制赋值运算符，防止用户不小心赋值对象。其次，实现移动构造函数和移动赋值运算符，来移动 coroutine handle，这样的话如果用户移动了对象也不会造成 double free。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class UserFacing { // ... private: handle_type handle; UserFacing(handle_type handle) : handle(handle) {} UserFacing(const UserFacing \u0026amp;) = delete; UserFacing \u0026amp;operator=(const UserFacing \u0026amp;) = delete; public: UserFacing(UserFacing \u0026amp;\u0026amp;rhs) : handle(rhs.handle) { rhs.handle = nullptr; } UserFacing \u0026amp;operator=(UserFacing \u0026amp;\u0026amp;rhs) { if (handle) handle.destroy(); handle = rhs.handle; rhs.handle = nullptr; return *this; } ~UserFacing() { if (handle) handle.destroy(); } }; 如果你 需要 允许用户感知对象复制的话，那么你就得更小心谨慎的设计结构防止double free，最简单的方式可能就是使用 shared_ptr 来进行管理。\n通过 co_yield 传递值 现在我们理解了基础后，就可以进阶了。\n第一件事是 co_yield\n作为例子，我们让我们的 demo 协程生成一个值，并交给 caller，最后我们大致会写出类似：\n1 2 3 4 5 6 UserFacing demo_coro() { co_yield 100; for (int i = 1; i \u0026lt;= 3; ++i) co_yield i; co_yield 200; } 然后提供一个接口 next_value() 会按顺序返回 100,1,2,3,200\n为了让协程中使用 co_yield 合法，promise type 必须提供方法 yield_value(),接受你想要生成的值的类型作为参数。这个例子中，我们定义 yield_value(int)\nyield_value 的返回值接着会像你正常传给 co_await 一样，所以他必须是一个 awaiter，或者某些可以通过 await_transform 或者 operator co_await 转换为 awaiter 的类型。\n这种情况中，最简单的办法是单纯让他返回一个 awaiter，使用平凡的 std::suspend_always 即可。然后，每个 co_yield 都会将控制权传递给 caller，以便于 caller 使用生成的值。\n但是 co_yield 也会对他的参数做一些处理。C++实现本身不关心 yielded value 和协程的 caller 的交互。我们需要自己实现一些代码。\n最简单的办法是将其存储在 promise 对象中，单独给一个字段存储：\n1 2 3 4 5 6 7 8 9 10 class UserFacing { class promise_type { public: int yielded_value; std::suspend_always yield_value(int value) { yieleded_value = value; return {}; } }; }; 现在，当协程执行到 co_yield 100时，promise 对象会调用 yield_value(100)，根据上面的实现，100会被存储到成员变量中，之后返回 awaiter 来暂停协程。\n暂停协程意味着控制流交还给将会调用 handle.resume() 的东西，在前一部分，这个通过用户感知类型的方法调用。所以我们应该修改方法让其返回 int 而不是 void，并且取出存在于 promise type 中的值。\n1 2 3 4 5 6 7 class UserFacing { public: int next_value() { handle.resume(); return handle.promise().yielded_value; } }; 之后，前五次调用 next_value 会返回示例协程生成的值了。\n但 之后再 调用一次会返回什么呢？\n第六次调用 next_value() 协程会在 co_yield 200 语句后恢复，这是协程函数体中最后一个语句了，所以控制流会结束，之后协程执行完毕，并通过 final_suspend() 返回的 std::suspend_always 来暂停自己。\n但什么都没有生成，没有东西调用 yield_value，也没有东西写入成员变量，仍然会获得跟之前一样的值。\n换句话说，第六次调用会 再返回 一次 200，单纯是因为上一次调用产生的结果。\n修复这个最简单的办法是在恢复协程 之前 写一些 dummy value，之后，他代表没有生成任何值，在 resume 后 dummy value 仍然在这。\n我们可以考虑一些特殊的 int 值来代表 “没有被生成的值”，例如 0，-1，INT_MIN 或其他的东西。但是那不是 C++20 该做的，更好的办法是使用 std::optional\u0026lt;int\u0026gt;，\n1 2 3 4 5 6 7 8 9 10 11 class UserFacing { // ... public: std::optional\u0026lt;int\u0026gt; next_value() { auto \u0026amp;promise = handle.promise(); promise.yielded_value = std::nullopt; handle.resume(); return promise.yielded_value; } }; 现在的话，next_value 的返回值也是 std::optional\u0026lt;int\u0026gt;，这样 caller 就可以正确找到实际的值。\nFull source code for this section: co_demo.yield.cpp (the simpler version without std::optional), and co_demo.yield_optional.cpp (the full version that uses std::optional so it can can signal end of stream).\n检测协程是否执行完毕 在上一部分，我们假设你调用 next_value() 6次，你依次接收 std::optional\u0026lt;int\u0026gt; 5次，一次包括 100 1 2 3 200，之后返回代表空序列的 optional\n那继续调用 next_value 会发生什么？\n这时，协程已经到达结束的位置了；final_suspend() 已经被调用。在这之后恢复协程会发生错误，导致崩溃。\n如果你调用的代码 100% 会判断 std::nullopt，那么大概可以避免这个问题，因为你可能不会再次调用 next_value()，但如果你的代码不那么有条理，你想让多次调用 next_value 也安全，那么你可能需要在 所有 调用 next_value 之前先把 value 清空。\n我们需要了解协程什么时候完成，然后不应该再恢复他了。幸运的是这个很简单，因为 handle 提供了 done() 函数，返回 bool\n1 2 3 4 5 6 7 8 9 10 11 12 class UserFacing { // ... public: std::optional\u0026lt;int\u0026gt; next_value() { auto \u0026amp;promise = handle.promise(); promise.yielded_value = std::nullopt; if (!handle.done()) handle.resume(); return promise.yielded_value; } }; 好多了，现在你的协程就不会因为调用错误次数的 next_value() 而崩溃。\nFull source code for this section: co_demo.done.cpp.\n通过 co_return 返回最终结果 如何使用 co_return 返回一些额外的数据？\n大多数情况下你大概率不会需要这个，但如果协程在执行一些网络任务，每次数据到达时 event loop 执行回调，那么可能使用 co_yield 和 co_await 跟网络设备交互（收发数据），之后使用 co_return 和 程序 中的其他需要该数据的部分交互，确定任务是否完成，或者查询的结果\n如果你想 co_return 一个值，那么你需要定义 promise type 的 return_value 方法，接受一个你想 co_return 的类型的值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class UserFacing { // ... public: class promise_type { public: std::optional\u0026lt;std::string\u0026gt; returned_value; void return_value(std::string value) { returned_value = value; } }; // ... std::optional\u0026lt;std::string\u0026gt; final_result() { return handle.promise().returned_value; } }; 常规来讲，return value 的行为取决于你，我把它存到了另外一个成员变量，并且提供了一个根据要求返回它的方法。所以你可以实例化这种类型的协程，一直调用 next_value 直到协程完成，最后调用 final_result 来得到当前状态的信息。\n如果你这么做最重要的事情是：你必须移除 return_void 方法，这是标准规定，你 只能 实现 return_void 和 return_value 其一。\nFull source code for this section: co_demo.return.cpp.\n处理协程抛出的异常 我们已经实现了原始例子中的大部分方法，但是我们还有一个没有讲到的：unhandled_exception()\n你可以按往常一样在协程内部抛出、捕获异常（虽然你不可以在 catch 块中 co_await 或者 co_yield），如果你抛出的异常 没有 在协程内被捕获，那么会发生什么？\n首先，协程会自动关闭，就像普通函数抛出异常一样。你无法再恢复协程：因为你无从恢复。\n但是在那之前，unhandled_exception() 会被 promise 对象调用。它实际上不接收任何参数，但是可以通过调用 std::current_exception() 来获取现在发生的异常，它的返回值是 std::exception_ptr。然后你可以向外传播异常，通过 std::rethrow_exception 来重新抛出。\n许多情况下，最方便的方法是将协程中的异常传播到上次恢复时的调用点。例如，在 generator 式的协程中，你比较能接受的方式可能是将协程传播给调用 next_value 的人\n（如果没有其他副作用的话，这也是 python 中生成器的工作方式，所以如果你想要那种方式的话，可以参考这个做法）\n你的代码可能会是：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class UserFacing { // ... public: class promise_type { // ... public: std::exception_ptr exception = nullptr; void unhandled_exception() { exception = std::current_exception(); } }; std::optional\u0026lt;int\u0026gt; next_value() { auto \u0026amp;promise = handle.promise(); promise.yielded_value = std::nullopt; promise.exception = nullptr; if (!handle.done()) handle.resume(); if (promise.exception) std::rethrow_exception(promise.exception); return promise.yielded_value; } }; 注意我们让 promise.exception 初始化为 nullptr，原因与清除 promise.yielded_value 相同。如果不这么做的话，调用 next_value 时就会抛出跟上次相同的异常。\n如果 unhandled_exception 什么都不做，那么异常会在协程退出后被丢弃。就好像协程体包含在隐式 try/catch 中一样，其中 catch 调用 unhandled_exception，然后假设这就是它需要执行的全部操作。\n在协程抛出异常时，你可能不仅仅 想做这些事情，如果你的系统中的协程调用另外一个子协程（并且根据行为生成它），那么你可能会希望从子协程中抛出的异常传递给调用者协程，就像 caller/callee 普通函数一样。这种情况下，你可能仍然希望 unhandled_exception 存储异常，但是你需要在不同的场景下抛出。之后我们探讨这个问题。\nFull source code for this section: co_demo.exception.cpp.\n编写自定义 awaiter 每次你的协程暂停时，甚至是 潜在 暂停，都会构造一个 awaiter object，并且用它来控制是否发生暂停以及其影响。\n目前，我们都是使用标准库提供的两个 Awaiter，std::suspend_always and std::suspend_never。终于可以自己实现了。\nawaiter 类型不需要继承任何特殊的类，只是单纯实现三个方法（某些的类型并不是固定的）\n1 2 3 4 5 6 class Awaiter { public: bool await_ready(); SuspendReturnType await_suspend(std::coroutine_handle\u0026lt;OurPromiseType\u0026gt; handle); ResumeReturnType await_resume(); }; 第一个 await_ready(), 控制协程是否暂停。如果其返回 true，那么协程会继续执行，如果返回 false 那么线程暂停。\n（为什么这么设计？你执行 co_await 时大概是需要等待一些东西，例如，可能协程需要其他操作的返回结果，所以需要等待。那么这里的思想就是 await_ready() 一直测试 你等待的东西是否完成，如果完成，返回 true，不然你也知道不需要继续等待了。）\n如果 await_ready 返回 false，那么会调用 await_suspend，他接受协程 handle（这意味着他也可以访问 promise对象了，通过 handle.promise()），它的返回类型有几种选择：\nvoid，协程暂停并且将控制权返回给上次恢复它的东西 bool，返回 true 时暂停，false 代表协程不需要暂停 返回 另外一个协程句柄。这种情况下协程会暂停，但是控制权不会返回给上次恢复它的东西，而是恢复执行返回的 handle 对应的那个协程。当然那个协程 也 可以在暂停后转换到其他协程。只有协程暂停且 没有 指定需要恢复的另外一个协程时，控制权才会被返回给 resumer。 如果让 await_suspend 在某些条件下 将控制权传给另外一个协程怎么样？那么你需要将其 handle 声明为函数的返回值（否则根本就无法获得其他协程了），但他最后还是需要返回一个值，用来不恢复其他东西，只是返回调用者。\n为了实现这个，标准库提供了 \u0026rsquo;no-op coroutine\u0026rsquo; 总是暂停自己并且不做其他事情。所以如果你声明 await_suspend 返回协程 handle，然后在某些情况下你想返回给调用者，那么你通过返回 std::noop_coroutine 实现。\n好了，那么怎么才能让 await_suspend 也可以 在某些条件下 不暂停呢？\n这种情况，你需要返回你传入作为参数的那个协程 handle。然后同一个协程会被立马恢复，就好像一开始就没有暂停一样。\n所以返回协程 handle 版本的 await_suspend 是最通用的形式：可以选择不暂停（返回其参数），暂停并且返回给 caller（返回 std::noop_coroutine），或者 转移到其他协程。\nvoid 和 bool 版本是单纯上面行为的简化版子集。\n最后，await_resume() 会在协程准备好继续执行时被调用（不管是因为他一开始暂停然后恢复了，还是根本就没暂停）。await_resume() 的返回值被传递给协程自己，作为 co_await 或者 co_yield 表达式的返回值。\n例如，你决定写一个 awaiter，然后你可以使用 co_await 来等待一个网络任务完成，你就可以选择通过这个办法来将返回值传递给协程。你的代码会像是：\n1 2 3 4 5 6 7 8 9 10 11 12 UserFacing my_coroutine() { // ... std::optional\u0026lt;SomeData\u0026gt; result = co_await SomeNetworkTransaction(); if (result) { // do something with the output } else { // error handling } // ... } 就像你平时调用函数一样。\n以上是 awaiter 可以做的所有事情，这里总结一下：\n当协程被创建时，其让你可以选择它在开始时是否暂停，或者立刻执行直到遇到第一个 yield 或者 await 点。 在任何 co_await 或者 co_yield 调用时，awaiter 允许你配置那些操作是否暂停，或者将控制权交给不同的协程; 和程序交互，决定其他协程什么时候恢复；在 await 和 yield 结束后返回一个有用的值。 当协程结束时（不管是返回还是异常），这种情况下，不允许再运行协程，丹尼可以让他在终点暂停，或者将控制权转移给其他协程，作为其最后的行为。 Full source code for this section, demonstrating lots of simple custom awaiters: co_demo.awaiters.cpp.\n使用 std::coroutine_traits 分辨 promise type 在前面的所有例子中，我们的 promise type 都定义在用户感知类型中，但是前文也提到，我们不止可以这么做。\n当你写一个协程时发生了什么？C++实现会根据协程的函数签名实例化一个模板类 std::coroutine_traits，然后 询问 promise type 是什么。\n默认 的 STL 实现是寻找函数类型 T 的返回值，然后期望 T::promise_type 存在。但如果你不想在类中存储 promise type，你可以特化你自己的 std::coroutine_traits\n这么做的目的是什么？\n一个原因是有时候可能你无法将该类型放入你的类中，例如一些标准库类型，比如 std::unique_ptr。或者也可能是一些简单的东西，比如裸指针 甚至是 int。之后我们会展示一个例子，你可能会用到你无法控制的类型。\n另外一个原因是 std::coroutine_traits 模板并不只是关注协程的 返回 类型，而且会关注参数的类型。所以如果你的 promise type 依赖那些的话，那么你就需要写一个模板特化。\n以下是一个用来展示语法的简单示例：\n1 2 3 4 template \u0026lt;\u0026gt; struct std::coroutine_traits\u0026lt;UserFacing\u0026gt; { using promise_type = SomePromiseType; }; 这会告诉编译器：如果一个协程的返回值类型是 UserFacing，并且不接收任何参数，那么它的 promise type 就应该是 SomePromiseType（假设你已经定义好了）\n下一步，增加一些特殊参数：\n1 2 3 4 template \u0026lt;\u0026gt; struct std::coroutine_traits\u0026lt;UserFacing, bool, char*\u0026gt; { using promise_type = SomePromiseType; }; 这个会精确匹配到返回值是 UserFacing 且接受那两个类型参数的协程。\n但大部分情况下你应该不会关心参数，所以可能是这样：\n1 2 3 4 template \u0026lt;typename... Ts\u0026gt; struct std::coroutine_traits\u0026lt;UserFacing, Ts...\u0026gt; { using promise_type = SomePromiseType; }; 这个特化会匹配 任何 返回值是 UserFacing 的协程，不管他几个参数。所以如果你的 promise type 只 依赖协程的返回值，且你不想定义 UserFacing::promise_type，那么大概你就会这么做。\n允许 promise type 访问协程的参数 目前的示例中，我还没有展示 promise 类中的构造函数。所以，C++会自动生成一个默认构造。\n但这不是唯一的方式，如果有一个合适的构造函数，那么 promise 类将会按照接收的参数进行构造。例如，你可能会：\n1 2 3 4 5 6 7 8 9 10 11 12 13 class UserFacing { public: class promise_type { public: promise_type(int x, std::string_view sv) { /* ... */ } // ... }; }; UserFacing demo_coroutine(int x, std::string y) { // ... co_return; } 之后当你调用协程的时候，demo_coroutine(1, \u0026quot;foo\u0026quot;)，promise type 的构造函数就会被调用，接收到两个参数。\n参数的类型也不一定需要完全相同，只要可以转换到合适的类型即可，就像普通函数一样。例如，我这里的构造函数接受一个 std::string_view ，而函数体则是 std::string，并且一样能用，编译器会自动进行转换。\n这样做的话可以避免额外的拷贝：如果 promise_type 的构造函数单纯接收一个 string，那么就会额外调用一次拷贝构造来传递这个副本。除非你真的需要这么干，不然尽量避免节外生枝。\n（当然，promise type 的构造函数接收的也可以是 const std::string\u0026amp; ，以前的 C++可以这样，但是现在已经有 string_view了）\n为什么 要这么做？\n这样的话协程的参数可以被当做控制 promise 类的办法，而不是让协程本身使用的。例如，假设你需要 promise 类包含一个指向 main-loop 的指针。最简单的办法就是通过构造 promise 对象时传入，所以你可能会做类似这样的事情：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class UserFacing { public: class promise_type { MainLoopThingy *mlt; public: template\u0026lt;typename... ArgTypes\u0026gt; promise_type(MainLoopThingy *mlt, ArgTypes \u0026amp;\u0026amp;...) : mlt(mlt) { // maybe also tie this promise object into the main loop right here } // ... }; }; UserFacing demo_coroutine(MainLoopThingy *, int x, std::string y) { // this code ignores the MainLoopThingy and uses just the other parameters co_return; } 这个例子中，我使用变参模板实现 promise type 的构造函数，所以它并不在意除了 MainLoopThingy 之外的任何参数。所以协程使用该 promise 类的协程不需要有相同的函数原型：他们 只 需要拥有 MainLoopThingy* 作为第一个参数即可。\n如果你想这么干的话，你也许 也 会用到 std::coroutine_traits 来选择promise type，所以你可以使用不同的指针类型来定义协程，以此选择不同的 promise type。但这种情况的应用场景只在你需要让用户感知到的返回类型 相同。\n另外一个特殊的情况是，你的协程是一个类成员函数。（这个情况完全支持，且之后我会更详细的描述。）在这种情况下，promise type 的构造函数（如果你只声明了一个参数），那么会接收类本身的引用作为第一个参数。如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class MyClass; class UserFacing { public: class promise_type { MyClass *c; public: template\u0026lt;typename... ArgTypes\u0026gt; promise_type(MyClass \u0026amp;c, ArgTypes \u0026amp;\u0026amp;...) : c(\u0026amp;c) {} // ... }; }; class MyClass { public: UserFacing coroutine_method(int x, std::string y) { // ... co_return; } }; 这里，当 coroutine_method 被 MyClass 的实例调用时，promise type 的构造函数会接收该实例的引用（*this的引用），之后是 int 和 std::string 两个参数。\n在 promise type 中，也存在一个跟之前示例类似的模板构造函数。但是构造函数希望接收 MyClass\u0026amp; 作为第一个参数，并且会存储指向该类的指针。这个保证 promise type 跟与他管理的类正常运作。\n然而，注意！如果 MyClass 的实例是被拷贝的，那么 promise 类只能存储指向其中一个副本的指针。如果它被移动了，那么 promise 类也得更新指针。所以如果你这么做了，你就应该保证每个 MyClass 是不可移动的（delete copy ctor and move ctor and 运算符），或者让他是只能移动的类型并且在移动构造函数以及移动赋值运算符中更新与 promise type 管理的指针。\n（这也是为什么用存储指向 MyClass 的指针而不是引用，指针才能被修改）\n非平凡的协程系统的例子 现在我已经列出了许多 C++ 允许你使用 promise 和 awaiter 干的事情。所以原则上你已经有了足够的知识可以上路了。\n但是可能再展示一些有趣的例子会更有帮助。\n深入 producer/adapter/consumer 链 协程最初的用法之一 —— 可能是最早的用法，是 The Art of Computer Programming 中的展示。其中一个协程生产一系列对象，另一个进行消费。协程的特性会产生一种每一部分代码都是一个子例程的错觉，并且允许它以它认为最好的控制流执行代码，即使其中包括多个循环或者 if 语句，调用其他不同的例程。\n最明显的扩展就是增加链长，使其拥有超过2个例程。这样中间的协程就可以从其左边的协程接收消息流，然后把它处理后传递给右边的协程。意味着中间的协程需要有两种暂停方式：收到新消息/有消息要传递。\nC++ 中，我们恰好有两个语义代表这两种不同的行为：协程可以使用 co_await 来表明他正要等待一个值，使用 co_yield 来将值提供给消费者。当然，如果我们自定义了 awaiter，我们就可以让协程自动转移控制权并且沿着整个链前进，只有最终输出的值准备好时才返回给 caller。\n（有很多种方法实现这个过程。另外一个可选的方法是在 main 中实现一个 \u0026rsquo;executor\u0026rsquo; 循环，其拥有一些暂停的协程，当一个协程暂停自己时，它就被传递给 executor 并且表明下一个应该恢复哪个协程。在某些情况下你需要选择这个方法，例如在线程间迁移信息，或者轮询 IO 源。但在这个例子中我想描述的是如何使用自定义 awaiters 来实现一个纯计算的多协程装置，不需要 单独的 executor。\n我们来举一个例子：我会用协程来实现一个著名的 FizzBuzz 例子，从 1 开始迭代连续的整数，如果是3 的倍数输出 Fizz，5 的倍数输出 Buzz。如果既是3的倍数又是5的倍数就输出 FizzBuzz，都不是就输出数字自己。\n为了让协程之间互相直接传递，他们需要以某种方式连接起来，这样才能互相找到对方。我们通过传递协程的用户感知对象作为函数参数以此构造下一个对象。\n换句话说，我们大概是想写：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 UserFacing generate_numbers(int limit) { for (int i = 1; i \u0026lt;= limit; ++i) { Value v; v.number = i; co_yield v; } } UserFacing check_multiple(UserFacing source, int divisor, std::string fizz) { while (std::optional\u0026lt;Value\u0026gt; vopt = co_await source) { Value\u0026amp; v = *vopt; if (v.number % divisor == 0) { v.fizzes.push_back(fizz); } co_yield v; } } 在 main 函数中的调用会像\n1 2 3 4 5 6 7 8 int main() { UserFacing c = generator_numbers(200); c = check_multiple(std::move(c), 3, \u0026#34;Fizz\u0026#34;); c = check_multiple(std::move(c), 5, \u0026#34;Buzz\u0026#34;); while (std::optional\u0026lt;Value\u0026gt; vopt = c.next_value()) { // print; } } 我们先构造一个只生成一系列整数的协程，并且将他们包进 Value 中（where later coroutines can accumulate the fizzes and buzzes that will be printed for that number）。之后我们调用第二个协程 check_multiple() 来检查 3 和 5 的倍数并分别为其标记。\n每个用户感知对象都被以 std::move 传递作为参数并消费它的输出，因为我们的用户感知对象是 uncopyable 以此来避免协程的 double free。\n每个协程都通过 co_await 表达式，使用参数中的用户感知对象来请求输入，这代表我们的 promise type 必须实现 await_transform(UserFacing\u0026amp;) 这样才能返回正确的 awaiter。每个协程通过 co_yield 传递输出，这意味着我们需要实现 promise type 的 yield_value(Value) 来返回不同的 awaiter。\n注意，协程们知道他们正在 从哪 await 值，但不知道要把值 yield 给谁。特别的，check_multiple() 的两个实例会根据 co_yield 做出两个完全不同的反应：Fizz 协程会将生成的值传递给 Buzz 协程，但是 Buzz 协程会执行完全一样的代码，但是 它的 输出值会传回 main 并且从 c.next_value() 返回。\n同样，每个协程以 Value 形式生成值，但是当 values 到达消费者时（不管是另一个协程还是 main，都会变成 std::optional\u0026lt;Value\u0026gt;。这允许我们通过 std::nullopt 来表示当前流是否结束）\n好了，我们现在应该实现它了！\n要实现上述的协程，我们从 yielded_value 的例子开始，调用用户感知对象的 next_value 可以获取值。新的难点是消费者协程 C 必须 co_await 另一个协程 P，大概是以下的方式\nC 通过调用 co_await P 让自定义 Awaiter 来在暂停时将控制权给 P C 要告诉 P 它自己的身份，这样 P 才能知道把控制权给谁 P 把控制权传递给 C 通过 co_yield 自定义 Awaiter 但如果协程执行 co_yield 时 不是 先被其他协程 awaited，那么同一个 awaiter 必须暂停，将值返回给 main 的最终调用者。 当 C 的 awaiter 恢复 C，它必须取回 P 生成的值，这样才能变成 co_await 返回的值 我们通过两个 Awaiter 来完成这个事情，InputAwaiter 来解决 co_await 的数据请求，OutputAwaiter 解决 co_yield 生成值\n以下是 InputAwaiter，它通过 await_transform() 创建\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class UserFacing { //... class InputAwaiter { promise_type* promise_; public: InputAwaiter(promise_type* promise) : promise_(promise) {} bool await_ready() {return false;} std::coroutine_handle\u0026lt;\u0026gt; await_suspend(std::coroutine_handle\u0026lt;\u0026gt;) { promise-\u0026gt;yielded_value = std::nullopt; return handle_type::from_promise(*promise); } } // ... class promise_type { promise_type* consumer_; //... InputAwaiter await_transform(UserFacing\u0026amp; uf) { promise_type\u0026amp; producer = uf.handle.promise(); producer.consumer_ = this; return InputAwaiter{\u0026amp;producer}; } }; }; 译者：想看懂这个例子需要搞清楚前文所有的协程执行流程。译者翻译这里的时间和翻译前文的事件隔了很久，看了很久。\n上面的代码中，await_ready() 总是暂停协程。await_suspend() 将控制权交给我们输入的 awaiting 我们的结果的协程，实现方式是将指向那个协程 promise 对象的指针传递给 InputAwaiter 的构造函数。\n为了获取 producer 传给我们这个协程的生成值，await_resume() 通过其他 promise 对象的 yielded_value 恢复，就像之前的例子中 UserFacing::next_value() 的行为一样。同样，为了检测 producer 协程 没有 生成任何值结束了，await_suspend() 清除之前 yieled_value 的值，之后再传递控制权。所以获取值的逻辑在这（链中值被传递给下一个协程）和 next_value() 中（被返回给 main）是一样的。\n另外一个要点是我们的 promise 对象需要一个新的字段，这样 promise 对象才知道它的 consumer 是什么。就是说，协程要传递值的对象。这个通过 await_transform() 初始化：当一个 consumer 协程想要 await 一个 producer 的时候，它会被传递给 producer 的 consumer_ 字段，指向他自己。OutputAwaiter 通过这个就可以知道将控制权传递给谁了。\n以下是 OutputAwaiter，yield_value 方法返回他\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class UserFacing { // ... class OutputAwaiter { promise_type* promise_; public: OutputAwaiter(promise* promise) : promise_(promise) {} bool await_ready() {return false;} std::coroutine_handle\u0026lt;\u0026gt; await_suspend(std::coroutine_handle\u0026lt;\u0026gt;) { if(promise) return handle_type::from_promise(*promise); else return std::noop_coroutine(); } void await_resume() {} }; class promise_type { //... OutputAwaiter yield_value(Value val) { yielded_value = val return OutputAwaiter{consumer}; } }; }; 比 InputAwaiter 简单很多，yield_value() 要填写 promise 对象的 yielded_value 字段，但是它并不需要知道消费者是谁，因为工作原理是一样的。\n但是 await_suspend() 需要 知道，因为它要决定是将控制权交给 consumer 还是暂停自己返回给 main。就像之前说过的，通过 std::noop_coroutine 完成；\nFull source code for this example: co_shuttle.cpp. (As I warned in the introduction, the real code will have to move some methods out of line that are shown inside the class definitions above.)\n有栈生成器 很难不把C++ 和 python 的生成器一起比较。我在文章中已经提到了很多了。C++23 的 generator 和 python 自带的行为基本一致。他只能 co_yield 生成一系列值，并不能 co_await 输入或者 co_return 一个结果，并且用户感知类型是可以用于 for 循环迭代的，就像是views。\n我们有一个 python 的特性没提到，那就是 yield_from，generator 可以指定为其他的可迭代对象，当然也可以是 generator。就是说，第一个生成器可以调用第二个生成器作为 subroutines，并且让他按照自己的行为生成值。\n你可以伪造一个。让第一个 generator 在后来的 generator 上迭代，然后通过 co_yield 手动传递输出值。\n关于协程返回类型和位置的技巧 在协程和普通函数之间共享类型 我是协程的 fan，但即使是我也不推荐在程序的 每一个 部分使用协程。\n有时候，你需要相同接口的一簇返回值，但是他们中的 一些 被实现为协程，其他的则是一些 C++ 的原生类型。\n实现这个的方法是利用调用协程的 caller 不需要知道它是一个协程。假设你有两个函数，返回相同类型\n1 2 SomeReturnType this_is_a_coroutine(Argument); SomeReturnType this_is_an_ordinary_function(Argument); 从 caller 角度看，这些函数有相同的 API。你可以调用一个，然后获取特定返回类型。\n函数定义 决定了他是否是协程。假设一个函数有 co_await, co_yield 或者 co_return，另一个没有。那么没有 co_ 的函数会被当成普通的函数，它的函数体会按照常规返回合适类型的对象。\n1 2 3 4 5 SomeReturnType this_is_an_ordinary_function(Argument) { int value = some_intermediate_computation(); SomeReturnType to_return { value }; return to_return; } 但如果另外一个函数 有 co_ ，那么C++的协程机制会执行：根据函数签名找到 promise 对象并构造，然后 get_return_object() 来生成返回对象，最后返回给 caller。\n但在 caller 的角度，是以同样的方式调用函数的，并且在每个情形下，它都会返回一个看起来一样的对象。但是对象会有一些方法（比如 get_value()）在某个情况下正常实现，在另一个情况下通过恢复协程在后台实现。\n最明显的让一个对象有不同的行为的方式是使用一个抽象基类，通过虚方法，之后通过不同的方式继承并实现它。\n1 2 3 4 5 class AbstractBaseClass { public: virtual ~AbstractBaseClass() = default; virtual std::string get_value() = 0; }; 非协程的继承类实现一个原始 C++ 类型的接口\n1 2 3 4 5 6 7 class ConventionalDerivedClass : public AbstractBaseClass { public: ConventionalDerivedClass() = default; std::string get_value() override { return \u0026#34;hello from ConventionalDerivedClass::get_value\u0026#34;; } }; 我们可以再实现一个包装了协程句柄的派生类，通过恢复协程并且与 promise 通信来实现 get_value\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class CoroutineDerivedClass : public AbstractBaseClass { private: friend class Promise; Handle handle; CoroutineDerivedClass(Handle handle) : handle(handle) {} public: std::string get_value() override { handle.promise().yielded_value = \u0026#34;\u0026#34;; handle.resume(); return handle.promise().yielded_value; } ~CoroutineDerivedClass() { handle.destroy(); } }; 这里没有给出 promise 的实现，因为和之前实现过的例子大差不差。（get_value 返回了普通的 std::string 而不是 optional，只是为了看起来简单而已）\n诶一的问题是：对于协程和非协程函数，实际的返回类型是什么？并不能是 AbstractBaseClass 自己，因为两个派生类大小不同。必须使用指针指向一个动态分配的类型：不管是裸指针，还是例如 std::unique_ptr。\n无论哪种类型我们都不能返回包含 promise_type 的类。如果它是裸指针，那它根本不能包含命名字段，如果是智能指针，标准库可以控制它包含的命名字段，并且用户代码不能添加到那个字段（？），所以我们需要使用 std::coroutine_traits 来识别 promise type，和前文提到的一样。\nEither way, we can’t make that return type contain a thing called promise_type. If it’s a raw pointer, it can’t contain named fields at all; if it’s a smart pointer from the standard library, then the standard library is in control of what named fields it has, and user code can’t add to that. So we’re going to have to use the std::coroutine_traits technique for identifying the promise type\n1 2 3 4 template\u0026lt;typename... ArgTypes\u0026gt; struct std::coroutine_traits\u0026lt;std::unique_ptr\u0026lt;AbstractBaseClass\u0026gt;, ArgTypes...\u0026gt; { using promise_type = Promise; }; 这样的话我们定义一个函数，返回 std::unique_ptr\u0026lt;AbstractBaseClass\u0026gt;，并且它的函数体包含 co_ 关键字的话，那么它就会是一个协程，其 promise_type 是 Promise。之后 Promise::get_return_object() 就可以正常创建对象了，即 std::unique_ptr\u0026lt;AbstractBaseClass\u0026gt;\n1 2 3 4 5 6 7 8 class Promise { // ... public: std::unique_ptr\u0026lt;CoroutineDerivedClass\u0026gt; get_return_object() { return std::unique_ptr\u0026lt;CoroutineDerivedClass\u0026gt;( new CoroutineDerivedClass(Handle::from_promise(*this))); } }; 例子里没用 std::make_unique，因为它要求包装对象的构造函数是 public，但是例子中它是 private，Promise 因为是 friend 所以可以访问，但没办法更改 make_unique 的授权。\n现在就可以使函数拥有正确行为了：\n1 2 3 4 5 6 7 8 std::unique_ptr\u0026lt;AbstractBaseClass\u0026gt; demo_coroutine() { co_yield \u0026#34;hello from coroutine, part 1\u0026#34;; co_yield \u0026#34;hello from coroutine, part 2\u0026#34;; } std::unique_ptr\u0026lt;AbstractBaseClass\u0026gt; demo_non_coroutine() { return std::make_unique\u0026lt;ConventionalDerivedClass\u0026gt;(); } 现在 demo_non_coroutine() 会在调用时立刻执行，且会构造返回的对象，而demo_coroutine() 会暂停，并且只会构造 promise 对象。caller 只会得到实现了同一个抽象类的对象，并且在每个上面都调用 get_value()，不需要知道他到底是协程还是对象的实例。\n如果使用裸指针的话也一样可行。仍然可以使用 std::coroutine_traits 特化。区别在于 caller 需要自己管理内存了。\nFull source code for this example: co_abstract.cpp. (Again, the full source code fills in details I glossed over for clarity, like having to define methods out of line.)\n在类中隐藏协程的实现 协程的一个有用的属性是，有一个数据对象表明正在进行的计算，并且程序的其他部分也能访问这个对象，也就是说可以进行通信，而不单单是运行。\n例如，C++ 协程可以轻松放弃 掉一个你不需要的计算，通过销毁用户感知类型，同时也会销毁协程句柄，自然就会释放协程的 promise 对象，这样自然会销毁协程内部的所有状态。假设所有的析构器都做了他们的工作，释放了所有内存，所有资源，并且没崩溃。（类比之下释放一个线程就非常困难）\n另外一个你需要知道的是，你可能想要在协程暂停时 \u0026lsquo;peek into\u0026rsquo; 协程状态。例如，如果协程代表了 GUI 程序的正在进行的计算，那么可能需要经常看 GUI 来更新进度条。但在 free-function 风格中很尴尬，因为协程内部的变量无法从外部访问。\n你可以通过让协程成为类的方法来 work around。这样就可以像访问它的 local 变量一样访问类成员 - 所以如果你想在协程暂停期间监视的变量的话，你可以把它写作类成员。\n另外一种方法是参考 std::generator\n换句话说，我们想要让类的某个方法是协程；类的构造函数调用那个函数来获取协程句柄；但是类 自己 需要完成协程返回的用户感知对象所负责的任务。然后，类的某个方法实现是恢复协程，这样就可以以有状态的方式对每个调用进行一系列操作；但是其他方法可以跟那个方法互动，来访问同样的成员。\n简单的实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Promise; template\u0026lt;class... ArgTypes\u0026gt; struct std::coroutine_traits\u0026lt;std::coroutine_handle\u0026lt;Promise\u0026gt;, ArgTypes...\u0026gt; { using promise_type = Promise; }; class Promise { // ... public: std::coroutine_handle\u0026lt;Promise\u0026gt; get_return_object() { return std::coroutine_handle\u0026lt;Promise\u0026gt;::from_promise(*this); } }; 同样，我们用了 std::coroutine_tratis 特化来确定协程句柄返回的 promise 对象，然后它的 promise_type 就是 Promise。\n然后我们可以让协程作为 private 方法，并且之后就可以让协程句柄和该类分开\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class CoroutineHolder { int param; SomeType mutable_state; std::coroutine_handle\u0026lt;Promise\u0026gt; handle; std::coroutine_handle\u0026lt;Promise\u0026gt; coroutine() { for (int i = 0; i \u0026lt; param; i++) { co_await something_or_other; adjust(mutable_state); co_yield something_else; } } public: CoroutineHolder(int param) : param(param), handle(coroutine()) {} ~CoroutineHolder() { handle.destroy(); } void do_stateful_thing() { if (!handle.done()) handle.resume(); } int query_state() { return mutable_state.some_field; } }; 这样的话协程就可以读取成员变量，比如 param，然后因此他也不需要自己额外的参数就可以调用。并且它可以 写 成员变量（例如 mutable_state），这样用户就可以通过查询当前状态，然后来决定是不是恢复协程。\n当然，你仍然可以通过 promise 对象来让 co_await 和 co_yield 有正确行为。\n（实现这个的方法可能是你给与 promise 对象一个指针，使用之前 [允许 promise type 访问协程的参数] 中的例子，然后通过完美转发将类的方法委托给 await_transform() 以及 yield_value()。这样你就可以使用不同的 promise 让协程有不同的行为。但我不会展示，应该已经超越本文的范畴了。）\nFull source code for this example: co_class.cpp.\n让 lambda 成为协程 除了普通函数还是类方法，lambda 也可以是协程。lambda 和其他协程一样 work，只要你显式指明了它的返回类型\n1 2 3 4 5 6 7 8 9 10 11 int main() { auto lambda_coroutine = []() -\u0026gt; UserFacing { co_yield 100; for (int i = 1; i \u0026lt;= 3; i++) co_yield i; co_yield 200; }; UserFacing lambda_coroutine_instance = lambda_coroutine(); // now do something with that user-facing object } 拥有普通函数拥有的一切优点，此外你可以把协程的代码放在紧挨着使用它的代码旁，并且可以捕获变量。\n如果你在另外一个协程内这么干，它可能会拓宽一些有趣的并行方法。举个例子，你可能会写一些 \u0026lsquo;parallel while\u0026rsquo; ，通过使用这种形式的多个协程，发明一种 co_await 类型，将所有协程插入到程序的主事件循环，然后再继续包含协程之前等待所有协程完成。或者在其他情景下你可能想等待它们中的某一个完成，然后销毁剩余的，有无穷的可能性！\n其他：没有讨论到的细节 文章已经很长很长了，并且我仍然有一些 C++ 协程的细节没有说到。这里是一个 quick list。\n当一个协程被创建时，内部状态（包含协程的内部变量）动态分配。在嵌入的上下文中，你可能需要控制 how， 或者 where 关于内存分配。你可能通过重载协程 promise 的 operator new 或者 operator delete 来实现。同时，如果分配失败，你可能需要提供 get_return_object_on_allocation_failure() handler，作为 get_return_object 的补充。但我还没尝试那些，如果我要用的话会探索它的细节。\n在许多关于异常的例子中，我们向协程的 caller 传播异常，通过 promise 方法 unhandled_exception() 来存储异常，并且通过用户感知对象获取异常然后重新抛出（在协程的 resume() 方法返回时）。根据 C++ 标准，还有一个方法来实现，可能需要在 unhandled_exception() 内 重新抛出异常。但是没有什么 Example，不知道为什么没有使用其他的方法，可能是因为缺少灵活性吧。\n我通常认为协程是线程的代替品。但是，显然，C++拥有如此灵活的协程系统的原因是它可以和线程 结合：你可能在另外一个线程上恢复协程，这样协程可能有时会在同一个线程中互相让步（yield），也有可能在在不同协程中并行运行。（这可能是 promise type 命名的原因，而且一些标准例子中的用户感知类型称之为 future）我还没有讨论这个，因为我基本是单线程的程序员。但是如果你有 1000 个协程代表不同的进行中的特定任务，在 16 个硬件线程上调度可能会有额外的复杂性，可能需要互相共享数据，或者线程同步，或者避免死锁。\n最后，我只讨论了用户感知类型和协程的交互，并不是提供给用户的 API。对于我 generator 的例子 - 类型协程（一种产生一系列值的协程），我仅仅只使用了一个简单的 next_value() 方法，来让客户端调用来获取协程生成的下一个值。但是关于 API 仍然有很多值得讨论的。例如，generator 协程可能也可以支持迭代器，这样你可以使用 range-based for，或者结合 views。（C++23 的 generator 就是这么做的）我甚至还没有谈到那一步，因为他并不是关于协程的，而是关于range一个类支持 range based for，或者行为像 views 或者 iostream 等等，明显是 C++ 的部分，而不是协程的部分。可能是我之后的文章。\n当然，可能还有其他需要说的，甚至我都不知道是什么！\nConclusion Phew, that was a lot of words! No wonder it didn’t fit in that training course I went on.\nI said in the introduction that one of my aims in learning about all this was to find out whether it would be good to convert my existing C++ program spigot so that it uses C++ language coroutines in place of my preprocessor-based strategy. Now I’m done, I think the answer is: it would certainly be good to do that one way or another, but I have several options for exactly how to do it, and I’ll need to decide which!\n(The natural way to use my preprocessor-based coroutine system in C++ is to put the coroutine macros in one method of a class, so that the class’s member variables store all the coroutine state that persists between yields, and every time that particular method is called, it resumes from the last place it left off. In that respect, the closest thing to a drop-in replacement is the technique I described above for hiding a coroutine inside a class implementation. That gets you almost exactly the same code structure, without preprocessor hacks, and with the new ability to have the coroutine declare its local variables more like a normal function. But it also doesn’t get you any extra usefulness – it’s very possible that a more profound redesign of spigot would be a better idea.)\nI also wanted to find out what else this facility might be useful for. I’ve got a lot of ideas about that, but I’ve no idea which ones will be useful yet. I look forward to seeing what the rest of the world comes up with!\n","date":"2024-02-08T00:00:00Z","permalink":"https://rossqaq.github.io/article/coroutine-system/","title":"自定义你的 C++20 协程系统"},{"content":"Back to Basics: C++ API Design - Jason Turner - CppCon 2022\n一期 Back to Basics，讲解如何让你的 API 更难被误用。\n这次主讲 Jason Turner，老朋友。\n","date":"2024-01-23T00:00:00Z","image":"https://rossqaq.github.io/article/cppcon-2022-api/cppcon2022-cover_hu7c68731152d935aaf39331c224457d06_58010_120x120_fill_box_smart1_3.png","permalink":"https://rossqaq.github.io/article/cppcon-2022-api/","title":"C++ API Design"},{"content":"An Introduction to Multithreading in C++20 - Anthony Williams - ACCU 2022 CppCon 2022 也讲了，以前记录过。这次选用 ACCU 的版本，因为内容更全一些。\nAnthony 应该都认识，写《C++并发编程》第二版的那个作者。这是他在 ACCU/CppCon 的讲座的总结，内容是关于 C++20 的所有并发 API。\n首先那个并发执行策略直接跳过，17进入标准，马上就要废弃了纯纯没用。\n取消操作 假设你的 GUI 下载程序支持取消操作，你点一下下载，发现需要很长时间。你可能会说，啊，快取消这个操作，然后让其他线程帮他清理资源。\nC++20 提供了两个工具，std::stop_source, std::stop_token 来解决协作任务的取消。\nstd::stop_source 用来检查是否有人让你取消操作。\n取消是一个协作任务，如果别人让你取消，但你不检查 std::stop_source，那么什么都不会发生。\n具体的用法如下：\n创建 std::stop_source 从 std::stop_source 获取 std::stop_token 将 std::stop_token 传递给一个新的线程或者 task（std::async） 当你想取消操作的时候，就调用 source.request_stop() 周期性检测：token.stop_requested() 来查看是否有人让你暂停 如果你不检查，那么什么都不发生 1 2 3 4 5 6 7 8 9 10 11 12 void stoppable_func(std::stop_token st) { while (!st.stop_requested()) { do_stuff(); } } void stopper(std::stop_source source) { while(!done()) { do_something(); } source.request_stop(); } 他们背后并没有什么同步机制，总之你得自己检查。\n你可以使用 std::stop_callback 来提供你自己的取消机制，如：\n1 2 3 4 5 Data read_file(std::stop_token st, std::filesystem::path filename) { auto handle = open_file(filename); std::stop_callback cb(st, [\u0026amp;]{cancel_io(handle);}); return read_data(handle); // 阻塞 } 这样可以在结束后执行回调。\n管理线程 std::jthread C++20 后，std::jthread 才是你的首选；很少的情况下也许会使用 std::async。\nstd::jthread 会自动提供你 stop_token（当然，前提是你的函数接收这个参数，不接受的话就不会给你）\n1 2 std::jthread t{my_func, arg1, arg2};\t// 调用 jthread my_func(stop_token, arg1, arg2);\t// 会得到 stop_token 我们来看看 std::jthread 的 API：\nstd::jthread 默认构造 创建一个空的对象 std::jthread x{Callable, Args...} 创建新的 std::stop_source - src 创建新线程调用 Callable(src.get_token(), Args...) or Callable(Args...) 析构函数 调用 src.request_stop()，然后等待线程结束后帮你 join x.get_id() x.join() 等待线程结束，不会析构对象 std::jthread 是一个值类型，已经是一个 handle 了，是可移动的，可以转移所有权，可以被存储在容器里。不要 new。\nAnthony 表示求你了，人家已经是一个 handle 了，别再 new 了。（说实话我也不懂为什么有人这么干。对 std::thread 就有人这么干。难道是写 -\u0026gt; 运算符看起来高级吗？）\n线程：Callable and Args callabe 和 args 会被拷贝到新线程的 local。\n这个主要是防止悬垂引用和竞争，如果想用引用请用 std::ref() 或者 lambda。\n取消 API 1 2 3 4 5 6 7 8 9 std::jthread x{some_callable}; x.get_stop_source(); x.get_stop_token(); x.request_stop(); // 等同于 x.get_stop_source().request_stop() 同步工具 多数情况下，线程之间有交互，例如数据交互。那么要小心数据竞争。在 C++ 中，数据竞争全是 ub。\nC++20 提供了一大堆同步工具：\nlatches barriers futures mutexes semaphores atomics 这个顺序是一会讲解的顺序，也是推荐你使用的顺序，按照这个顺序依次思考，这个组件是否能解决你的问题。\nAnthony 表示，例如 atomic 就很容易用错，不过你的团队里总有人知道怎么正确使用。所以普通人不懂的就不要乱用。\n（确实，不懂内存序那也用不明白 atomic。）\nLatches std::latch 是只能使用一次的计数器，线程们等待它归零后通行。\n创建一个非 0 count 的 latch 一个或者多个线程减少 count（原子的） 其他线程可能等待 latch 被触发 当 latch 归零的时候，会保持触发，所有的等待它的线程都会被唤醒 1 2 3 4 5 6 7 8 9 10 std::latch x{cnt}; // 减少 count x.count_down(); // 等待 latch 触发 x.wait(); // x.count_down() + x.wait() x.arrive_and_wait(); 就像一个结界，latch 归 0，线程就都能通过了。\n这个也可以用于测试并发，让所有的线程等待一个 latch，之后执行你的可能会发生 data race 的代码。\nBarriers std::barrier\u0026lt;\u0026gt; 是一个模板类：\n构造一个 barrier，需要一个 count，以及一个 Completion Function 一个或者多个线程到达 barrier 等待 barrier 被触发 count 归 0，触发 barrier，会调用 Completion Function，然后重复以上过程。 1 2 3 4 5 6 7 8 9 10 11 12 13 std::barrier\u0026lt;task_type\u0026gt; x{cnt, task}; // 递减 count，如果触发了 barrier，就会执行 completion 函数 auto arrival_token = x.arrive(); // 等待 completion 函数完成 x.wait(arrival_token); // x.wait(x.arrive()); x.arrive_and_wait(); // 使 cnt 永远减少（当然也可能触发 completion 函数）而不需要等待 x.arrive_and_drop(); 在游戏渲染可能比较有用，因为游戏每一帧都要同步。而 nvidia 对这俩都有特殊的指令支持。\nbarrier 可以循环使用，提供了 completion function 也方便在触发后执行一些操作，比如写入文件。\nFutures std::future 有时你只是单纯想把数据从一个线程传递到另外一个线程，future 就是干这个的。\nfutures 用于线程间的数据传递。\nstd::async 发起任务，并返回一个值。推荐的使用方法时，使用 std::async 来立马进行一个计算，之后会使用 future 获取值。否则你可能需要的是 std::packaged_task std::promise 显式设定值 std::packaged_task 将返回一个值的任务封装。它会保存一个任务，你可以在未来对其进行调用，之后获取 future。可以使用这个配合线程池，来获取返回值 以上所有这些，你都可以使用 std::future\u0026lt;T\u0026gt; 来获取结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 // 空 future std::future\u0026lt;T\u0026gt; default_ctor; // 检查 future 的 state f.valid(); // 等待数据完成 f.wait(); f.wait_for(duration); f.wait_until(time_point); // 等待数据并且获取它。数据如果已经完成，那么也不会阻塞 x.get(); std::promise promise 可能是你用的最多的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 空 promise std::promise\u0026lt;T\u0026gt; default_ctor; // 检查 promise 的 state p.valid(); // state 中设置值 p.set_value(); // state 中设置异常 p.set_exception(ex_ptr); // 获取当前状态下的 future p.get_future(); 使用 future/promise 传递数据：\n1 2 3 4 5 std::promise\u0026lt;MyData\u0026gt; prom; std::future\u0026lt;MyData\u0026gt; f = prom.get_future(); std::jthread th1{ [f=std::move(f)] { do_stuff(f.get()); }}; std::jthread th2{ [\u0026amp;prom] { prom.set_value(make_data()); }}; 注意，future 是一次性的，所以你需要注意移动。此外，调用 get() 后，其就不拥有值了。\n对于异常：\n1 2 3 4 5 6 7 8 std::promise\u0026lt;MyData\u0026gt; prom; std::future\u0026lt;MyData\u0026gt; f = prom.get_future(); // 该线程内部抛出异常 std::jthread th1{ [f=std::move(f)] { do_stuff(f.get()); }}; std::jthread th2{ [\u0026amp;prom] { prom.set_exception( std::make_exception_ptr(my_exception{})); }}; std::async 还可以使用 std::async 来发起一个任务：\nstd::async 可以用来创建一个线程，只要你第一个参数传递 std::launch::async，否则的话是否新建一个线程是实现定义。\n1 auto f = std::async(std::launch::async, func, arg1, arg2); f.get() 会返回 func 的结果\nf 拥有一个类似 jthread 的线程，析构函数会帮你处理现成的\nstd::shared_future std::shared_future 允许你让多个线程收到执行结果。\n1 2 3 4 5 std::promise\u0026lt;Data\u0026gt; prom; std::shared_future\u0026lt;Data\u0026gt; f = prom.get_future().share(); std::jthread th1 {[f]{do_stuff(f.get());}}; std::jthread th2 {[f]{do_stuff(f.get());}}; std::mutex future 比 mutex 好一点，但因为它是一次性的。所以你也许需要 mutex\nC++ 提供了 6 种 mutex，实则有 5 个没啥用\n1 2 3 4 5 6 std::mutex;\t// ← 用这个 std::timed_mutex; std::recursive_mutex; std::recursive_timed_mutex; std::shared_mutex; // ← 读写锁，而实践中用这个很蛋疼。用 mutex 就行。 std::shared_timed_mutex; 对于上锁和解锁，我们也有 RAII 封装：\n1 2 3 4 std::scoped_lock;\t// ← 用这个 std::unique_lock; std::lock_guard; std::shared_lock; 你把所有的锁都给 std::scoped_lock ，他会一起给你上锁，而且保证不会死锁。\n等待数据 如何等待数据完成？\n忙等吗？这个是个 bad idea，浪费 cpu 性能。\n1 2 3 4 5 6 7 8 9 10 std::mutex m; std::optional\u0026lt;Data\u0026gt; data; void busy_wait() { while (true) { std::scoped_lock lock(m); if (data.has_value()) break; } process_data(); } 所以我们有 std::condition_variable 来通知，他并不能同步数据，但可以避免忙等待。\n我们需要一个 std::unique_lock，因为其跟 scoped_lock 不合\n1 2 3 4 5 6 7 8 9 10 std::mutex m; std::condition_variable cond; std::optional\u0026lt;Data\u0026gt; data; void cv_wait() { // 会锁定互斥量 std::unique_lock lock(m); cond.wait(lock, []{ return data.has_value(); }); process_data(); } 首先你需要给 mutex 上锁，然后你再调用条件变量来传递 lock 以及一个 lambda，表明：**你到底在等待什么？**当你的 lambda 返回 true 时，就会替你解锁。\n对于 std::condition_variable ，使用忙等实现是合法的，但是操作系统不会这么做，因为操作系统知道这样做不好。如何通知呢？你需要调用一下 notify()\n1 2 3 4 5 6 7 void cv_notify() { { std::scoped_lock lock(m); data = make_data(); } cond.notify_one(); } 如何使用条件变量配合取消操作呢？使用 std::condition_variable_any\n1 2 3 4 5 6 7 8 9 std::condition_variable_any cond; void cv_wait(std::stop_token token) { std::unique_lock lock(m); if(!cond.wait(lock, token, []{return data.has_value(); })) { return ; } process_data; } 现在 wait 会返回一个布尔变量，告诉你你的谓词是否返回 true，如果返回 false，就代表我需要暂停操作，因为某些线程告诉我 stop。\n当然，如果同时发生 stop 和数据准备好两个事件，那么依然会返回 true，那么依然会处理数据。具体怎么做取决于你，如果你的操作很快，那可以继续，如果想取消，就显式判断 stop。\n信号量 如果以上的工具都不能满足你（显然都不满足你有点难度），那么你可能需要信号量。\n信号量代表一些可以被使用的 \u0026ldquo;slots\u0026rdquo;。如果你 acquire 一个 slot，那么信号量会减少，直到你 release 该 slot。\nacquire 一个 slot，但是 count 为 0 时，会阻塞或者失败。\n信号量可以实现所有的同步机制，包括 latches, barriers, mutexes，当然，大部分情况下你直接用更高级的结构即可。\nbinary_semaphore 有 2 个状态：1 slot free，no slots free，就像 mutex 一样使用。\nC++20 提供了 std::counting_semaphore\u0026lt;max_count\u0026gt;, std::binary_semaphore 是其 max_count = 1 时的特化。\n有阻塞的 sem.acquire() 也有 sem.try_acquire()，..for, \u0026hellip;until，替代阻塞的版本。\n原子变量 原子变量是最最底层的同步设施了。在 C++ 里是 std::atomic\u0026lt;T\u0026gt;\nT 必须 可平凡拷贝，Bitwise comparable\n原子变量 lock_free 吗？ std::atomic\u0026lt;T\u0026gt; 可能不是 lock-free 的，可能会使用内部 mutex。\nstd::atomic_flags, std::atomic_signed_lock_free, std::atomic_unsigned_lock_free 是唯三保证 lock-free 的类型。\n在大多数平台上，std::atomic\u0026lt;integral-type\u0026gt; 以及 std::atomic\u0026lt;T*\u0026gt; 是 lock-free 的。\n你可以通过 std::atomic\u0026lt;T\u0026gt;::is_always_lock_free 来查看到底是不是 lock-free。\n","date":"2023-12-29T00:00:00Z","image":"https://rossqaq.github.io/article/cppcon-2022-concurrency/cppcon2022-cover_hu7c68731152d935aaf39331c224457d06_58010_120x120_fill_box_smart1_3.png","permalink":"https://rossqaq.github.io/article/cppcon-2022-concurrency/","title":"C++ 的并发 API 总结"},{"content":"本文翻译自：A beginner\u0026rsquo;s guide to C++ Ranges and Views. —— Hannes Hauswedell\nC++ Ranges 是 C++20 的新特性之一，\u0026ldquo;views\u0026rdquo; 是 ranges 的大头。这篇文章是给刚接触 C++ ranges 的程序员的一篇介绍。\n前言 你不需要拥有任何关于 C++ ranges 的前置知识，但你需要理解 C++ 迭代器，以及了解一些 C++ Concept 特性，这里有老爷子的文章。\n这篇文章基于写给 SeqAn3 library 的文档，原文在这，也有关于 Concept 的文章\n之后都会尝试搬运翻译。\n现在的标准库也都是 ranges v3 了，原始链接。\n动机 传统的 STL 泛型算法，例如 std::sort ，接受一对迭代器（如 begin() 的返回值），你需要调用\n1 2 3 std::sort(vec.begin(), vec.end()); // 而不是 std::sort(vec); 为什么这么设计？因为更加灵活，举个例子：\n只排序第五个元素之后的元素 1 std::sort(vec.begin() + 5, vec.end()); 使用反向迭代器排序 1 std::sort(vec.rbegin(), vec.rend()); 结合二者（排序，除最后5个元素） 1 std::sort(vec.rbegin() + 5, vec.rend()); 但这样的接口相比直接整体调用 std::sort 来排序你希望的部分更不直观，它也更可能出错，例如，混淆了两种不兼容的迭代器。\nC++20 引入了 ranges 并在 std::ranges:: 下重写了所有算法，例如 std::ranges::sort(vec)。现在，假如 vec 是 range，算法就可以正常运行。而 vector 就是 ranges！\n那么使用 ranges 版本算法的优点在哪呢？在 C++20，你可以：\n只排序第五个元素之后的元素 1 std::ranges::sort(std::views::drop(vec, 5)); 反向排序 1 std::ranges::sort(std::views::reverse(vec)); 结合 1 std::ranges::sort(std::views::drop(std::views::reverse(vec), 5)); 稍后我们讨论 std::views::reverse(vec) 的行为。现在只需要记住它返回某些 std::ranges::sort 可以排序的容器。之后你就会看到这种方式相较于传统迭代器更加灵活的地方。\n范围 范围 (Ranges) 是 “一些元素” 或者 “可迭代对象” 的抽象。最最基础的 range 定义只要求提供 begin() 和 end()。\n范围概念 有很多种方法解释 ranges，最重要的一种是根据其迭代器的能力。\nranges 通常可以是输入范围（可以读取）、输出范围（可以写入）二者之一，也可以都是。\n例如，std::vector\u0026lt;int\u0026gt; 就既是输入范围又是输出范围，std::vector\u0026lt;int\u0026gt; const 只能是输入范围（只读）。\n输入迭代器有不同的 强度，其通过不同的更精细的概念实现(即，满足更强概念的类型总是满足更弱的概念):\nConcept 描述 std::ranges::input_range 可以至少一次从头迭代至尾 std::ranges::forward_range 可以多次从头迭代至尾 std::ranges::bidirectional_range 迭代器可以通过 -- 反向移动 std::ranges::random_access_range 可以通过 [] 在常量时间内访问元素 std::ranges::contiguous_range 元素在内存中总是连续存储 这些概念直接从迭代器各自的概念继承而来。例如，如果一个 ranges 模型的迭代器满足 std::forward_iterator ，那么他就是一个 std::ranges::forward_range。\n对于常见的标准库容器，这里展示了他们满足的 ranges 模型：\nstd::forward_list std::list std::deque std::array std::vector std::ranges::input_range √ √ √ √ √ std::ranges::forward_range √ √ √ √ √ std::ranges::bidirectional_range √ √ √ √ std::ranges::random_access_range √ √ √ std::ranges::contiguous_range √ √ 也有一些概念独立于以上的输入输出要求。例如，std::ranges::sized_range 要求常量时间内通过 std::ranges::size() 获取 range 的容量。\n存储行为 容器是 ranges 最熟悉的，他们拥有自己的所有元素，STL 已经提供了许多容器，参上。\n视图 指经常通过另一个 range 以及其底层 range 执行算法、操作等变换得来的 ranges。视图不拥有除其算法外的任何数据，且其构造、析构、拷贝都不应依赖于其可以表示的元素的数量。算法要求惰性求值，所以结合多个 views 是可行的。\n存储行为与通过迭代器定义的范围概念是正交的。例如，你可以拥有一个容器，满足 std::ranges::random_access_range ，但其视图可以满足也可以不满足。\n视图 惰性求值 视图一个关键的特性就是，无论对其应用什么变换，他们总是在你需要一个元素时才执行，而并不是在视图创建时执行。\n1 2 std::vector vec{1, 2, 3, 4, 5}; auto v = std::views::reverse(vec); 这段代码中，v 是一个视图；创建他并不会改变 vec 的值，且 v 也不存储任何元素，构造 v 以及其在内存中的大小都和 vec 的大小无关。\n1 2 3 std::vector vec{1, 2, 3, 4, 5, 6}; auto v = std::views::reverse(vec); std::cout \u0026lt;\u0026lt; *v.begin() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; 会打印 \u0026ldquo;6\u0026rdquo;，但重要的是将 vec 的最后一个元素解析为 v 的第一个元素是按需发生的。这保证视图可以作为更灵活的迭代器来使用，但他意味着 view 有一些额外开销，如果一个相同元素需要使用多次，那么就得重复计算。\n组合能力 你可能想知道为什么文章中写\n1 auto v = std::views::reverse(vec); 而不是\n1 std::views::reverse v{vec}; 这是因为 std::views::reverse 并不是视图本身，他是一个底层视图（我们的例子中，是 vector）的 适配器 (adaptor)，并且返回一个基于 vector 的视图对象。视图的具体类型隐藏在 auto 身后。这有一些好处，我们不需要关心视图类型的模板参数，但是更重要的是适配器有一个额外的特性：适配器可以和其他适配器链起来\n1 2 3 4 std::vector vec{1, 2, 3, 4, 5, 6}; auto v = vec | std::views::reverse | std::views::drop(2); std::cout \u0026lt;\u0026lt; *v.begin() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; 会打印什么呢？\n会打印 4，因为 4 是反向后去掉 2个元素后的第一个元素。\n在上面的例子中，vector 是 piped（类似于 unix/linux 命令行）传入 reverse 适配器，之后传入 drop 适配器，最后组合出的视图被返回。管道是一种提升可读性的形式。例如\nvec | foo | bar(3) | baz(7) 等同于 baz(bar(foo(vec), 3), 7)\n注意，访问视图的 0th 元素仍然是惰性的，这也决定了访问时其映射的元素会发生什么。\n练习 基于 std::vector vec{1, 2, 3, 4, 5, 6} 创建一个视图，过滤掉所有的奇数，平方剩下的值。\n1 2 3 4 std::vector vec{1, 2, 3, 4, 5, 6}; auto v = vec | // ...? std::cout \u0026lt;\u0026lt; *v.begin() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // 应该打印 4 完成这个练习，你可以使用 std::views::transform 以及 std::views::filter 。他们都接受一个可调用对象。std::views::transform 会在底层 range 的元素上应用可调用对象，std::views::filter 会移除不满足可调用对象的元素。\n答案（我写的）：\n1 2 3 4 5 6 7 std::vector vec{ 1, 2, 3, 4, 5, 6 }; auto square = [](const int value) {return value * value; }; auto odd = [](const int value) {return value % 2 == 0; }; auto v = vec | std::views::filter(odd) | std::views::transform(square); std::cout \u0026lt;\u0026lt; *v.begin(); 视图概念 视图是特殊的 range，其实例化于 std::ranges::view 概念，每个通过视图适配器返回的视图都是符合该概念的模型，还有哪些范围概念是由视图建模的？\n这取决于底层 range 以及视图本身。很容易想到，视图并不会建模比其底层 range 更强的 range 概念（除了他们总是 std::ranges::view ），他会尽可能多地保留 range 的概念。\n例如，std::views::reverse 返回的视图满足 std::ranges::random_access_range（以及更弱的模型），前提是底层视图满足该概念，但他永远不会满足 std::ranges::contiguous_range，因为视图中的第三个元素在内存中并不位于第二个元素之后，而是其之前。\n这可能会震惊一些人，许多视图满足 std::ranges::output_range，如果其底层 range 满足的话。例如：非只读视图：\n1 2 3 4 std::vector vec{1, 2, 3, 4, 5, 6}; auto v = vec | std::views::reverse | std::views::drop(2); *v.begin() = 42; // now vec == {1, 2, 3, 42, 5, 6 } !! 练习 考虑上一道习题（filter + transform），v 可能满足哪些概念？\n其满足：\nConcept 满足与否 std::ranges::input_range √ std::ranges::forward_range √ std::ranges::bidirectional_range √ std::ranges::random_access_range std::ranges::contiguous_range std::ranges::view √ std::ranges::sized_range std::ranges::output_range filter 无法保证元素随机访问，因此并不连续。因为无法在常数时间内知道底层 range 的元素究竟是第几个元素。它不能“跳”过去，他需要遍历底层 range，这当然也代表我们无法在常数时间内知道大小。\ntransform 视图可以 jump，因为它总是对每个独立元素执行相同操作；它也可以保证 sized-ness 因为留下的 size 相同。在这些情况下，filter 都会丢弃这两只属性。换句话说，transform视图 在每次访问时产生新的元素，因此 v 不是输出范围，你不能向他的元素赋值。这也阻止了 contiguous-range 的建立（如果没有被 filter 处理掉的话，因为按需创建的值根本不在内存中存储）\n理解这些需要更多练习，在 SeqAn3 中提供了详细的文档。\n附录 — 一些常用示例 常用的 views:\nstd::views::take() std::views::filter() std::views::transform() std::views::iota() 如何从 views 生成对应容器？在 C++23 前，只能手动创建对象，使用 views 的迭代器来生成对象即可；在 C++23 后有了 std::ranges::to，用起来和 Rust 的 collect 感觉差不多。\n","date":"2023-12-27T00:00:00Z","image":"https://rossqaq.github.io/article/ranges-overview/ranges-cover_hua81d8bad95085fbb8c0f6baec7ed581b_84315_120x120_fill_box_smart1_3.png","permalink":"https://rossqaq.github.io/article/ranges-overview/","title":"C++20 Ranges overview"},{"content":"前言 记录一下老三样的使用方法，以及网络编程的疑难杂症。主要来自于 UNP。\n顺便，初始化 socket 就不重复写了。\n再者，文章中 EWOULDBLOCK 和 EAGAIN 在一般的实现中值是相同的。\n协议以及基础介绍 主要协议 IPv4: 32位 ip 地址，提供分组递送服务 IPv6: 128位 ip 地址 TCP：面向连接，提供全双工字节流，流套接字，关心确认、超时、重传等细节，支持IPv4, IPv6 UDP：无连接，数据包套接字，不保证到达目的地。支持IPv4, IPv6 ARP：地址解析协议。把 IPv4 地址映射成硬件地址，通常用于以太网。在 P2P 网络中不重要。 RARP：把硬件地址映射成 IPv4. UDP 用户数据报协议 应用程序往 UDP socket 写入数据，封装为一个 UDP 数据报，又被封装为 IP 数据报，然后发送。不保证到达顺序，不保证是否到达，不保证数据报只到达一次。\nUDP 数据报有一个长度，而 TCP 没有。\n说 UDP 无连接是说 UDP 客户和服务器不必存在任何长期关系。比如 UDP 客户端可以用同一个套接字给不同服务器发送消息。\nTCP 传输控制协议 TCP 提供客户与服务器的连接，TCP 客户先与某个给定服务器建立一个连接，再跨连接与那个服务器交换数据，然后终止连接。\nTCP 比较可靠，要求对端确认数据，如果没有收到确认就会自动重传并等待。数次失败后 会放弃。\nTCP 会估算客户和服务器之间的往返时间，以便知道需要等多久。\nTCP 会给其中每个小节关联一个序列号对发送数据进行排序。如果收到重复数据，会丢弃。\nTCP 提供流量控制，告知对方现在自己能接收多少数据。\n最后，TCP 全双工，意味着在一个连接上的引用可以在两个方向上既接受又发送数据。当然可以把它转化为单工连接。\nTCP 连接建立与终止 三次握手 TCP 连接过程：\n服务器通过 socket, bind, listen 三个函数准备好接受连接 客户端通过 connect 发起连接。此时客户 TCP 发送 SYN 服务器发送 ACK，SYN 客户端确认服务器的 SYN，回复 ACK 客户端 SYN 初始为 J，服务器端 SYN 初始为 K，期待的 ACK 都是对应的 SYN + 1.\nTCP 连接终止 某个应用调用 close() ，主动关闭，发送 FIN 收到 FIN 的一方执行被动关闭，需要确认，然后把他的接收作为一个 EOF 传递给接收端应用 一段时间后，接收 EOF 的进程调用 close() 关闭 socket，也发送一个 FIn 接收这个最终 FIn 的原发送端（主动关闭那一方）确认这个 FIN 某些情况下，步骤1 的 FIN 跟数据一起发送；步骤 2，3 都是出自被动关闭那一方，可能一起发送；\nTCP 状态图 实现箭头：客户的正常状态转换\n虚线箭头：服务器的正常状态转换\n应用：状态转换在应用进程发起操作时发生\n接收：表示接收分节时发生\n发送：表示转换发送什么\n输出缓冲区 每个 TCP socket 都有一个发送缓冲区，调用 write 内核会从应用程序的缓冲区中复制数据到套接字的发送缓冲区。如果 socket 为阻塞使用，且缓冲区已经满或者有其他数据或者进程缓冲区更大，那么程序都会挂起。\nwrite 返回时是内核已经把数据复制到发送缓冲区，仅代表可以使用教程的缓冲区了。\nUDP 套接字没有缓冲区，内核没必要保存数据，因为 UDP 不可靠。但是有一个发送缓冲区大小，如果发送数据太大会返回 EMSGSIZE 错误。应用进程的数据在传递时，通常会保存到某种格式的内核缓冲区，发送完就会被丢弃。而 TCP 因为要确认，所以会暂时保留。\nwrite 返回就表示数据报或者其所有片段都加入了数据链路层的输出队列，如果队列没有足够的空间，通常会返回 ENOBUFS（也许有的实现并不返回）\n阻塞与非阻塞 IO 不同的 IO 概念图 异步是让内核帮我们完成收取数据，复制到应用，完成后通知我们，而 IO 多路复用则是阻塞在 select 和 poll 这两个函数上。\n网络编程 网络编程无非就几个事件，\n连接：服务器为 accept，客户端 connect 读： read/readv/recv/recvfrom/recvmsg 写： write, 断开连接 对于输入（读）操作，\n在阻塞情况下，TCP 若 socket 的接收缓冲区中没有数据，则休眠；如果有数据，就立马读； 在非阻塞情况下，TCP 若没有至少一个字节可以读，则会立马返回 EWOULDBLOCK 对于输出（写）操作，\n在阻塞情况下，若发送缓冲区没有空间，将阻塞，直到有空间为止 在非阻塞情况下，如果缓冲区没有空间，会立即返回 EWOULDBLOCK；如果有一些空间，会返回的是能够复制到该缓冲区中的字节数。 接受连接，即 accept：\n在阻塞情况下，会阻塞到直到有新的连接到达。 在非阻塞情况下，会立即返回 EWOULDBLOCK 发起连接，connect：\n在阻塞情况下，会等待三次握手后连接建立 在非阻塞情况下，会发起三次握手，然后直接返回 EINPROGRESS（在服务器和主机是同一个服务器的情况，可能会成功返回，所以非阻塞也得考虑成功的情况） 套接字选项 1 int setsockopt(int fd, int level, int optname, const void* optval, socklen_t optlen); level 是指定系统重解释选项的代码 或者为 通用套接字代码 或者为某个特定协议 optval 用于读取待设置的新值（一般是1代表启用） SO_KEEPALIVE 2个小时没有数据流动，就会自动发送一个保持存活探测分节：\n对端以期望的 ACK 响应。一切正常。 对端以 RST 响应，告知本端 TCP：对端崩溃且已经重启，该套接字本身会被关闭 对端没有响应，会继续探测，持续一段时间后如果还没有响应就会放弃。 当然，你也可以在应用层手动设置心跳（heartbeat）机制来确认。\nSO_LINGER 指定 close 函数面对面向连接协议的操作。默认 close 会立刻返回，但如果有数据残留在发送缓冲区，那么会试着把数据发出去。\n这时需要处理 close 的返回值。\nSO_REUSEADDR 和 SO_REUSEPORT 必须开启，防止因为服务器重启而不能绑定。\nSO_REVTIMEO 本选项一旦设置到某个描述符，超时设置会应用于该描述符上的所有读操作。\nSO_SNDTIMEO 本选项一旦设置到某个描述符，超时设置会应用于该描述符上的所有写操作。\nclose()/shutdown() close 会把 fd 的引用计数 -1，仅在计数为 0 才关闭 socket，此外，会直接关闭读写两个方向的数据传输。 使用 shutdown 可以不管引用计数直接激发 TCP 的正常连接终止，可以选择半关闭套接字。 我们需要考虑到，关闭 socket 时可能还会有数据在路上，没收到。\nselect 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 #include \u0026lt;sys/select.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;array\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026#34;util.hpp\u0026#34; int main(int argc, char* argv[]) { if (argc != 2) { std::cerr \u0026lt;\u0026lt; \u0026#34;Usage: ./select port\\n\u0026#34;; return -1; } int sockfd = socket_init(atoi(argv[1])); std::cout \u0026lt;\u0026lt; \u0026#34;Listen: \u0026#34; \u0026lt;\u0026lt; sockfd \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // select 可以监视上述读事件和写事件 // 监视的 socket 集合，1024 bit 的 bitmap (int[32]) // 操作位图的宏： // void FD_CLR(int fd, fd_set* set) // int FD_ISSET(int fd, fd_set* set) // void FD_SET(int fd, fd_set* set) // void FD_ZERO(fd_set* set) fd_set fds; FD_ZERO(\u0026amp;fds); FD_SET(sockfd, \u0026amp;fds); int max_fd = sockfd; for (;;) { timeval timeout{ .tv_sec = 10, .tv_usec = 0 }; // 先拷贝一份 bitmap，因为会被修改 fd_set tmpfds = fds; // select // p1: bitmap size (max + 1) // p2: 监视读事件的 bitmap // p3: 监视写事件的 bitmap，如果监视写事件，那么发送缓冲区没满就会一直通知 // p4: 监视异常事件的 bitmap int nfds = select(max_fd + 1, \u0026amp;tmpfds, nullptr, nullptr, nullptr); if (nfds \u0026lt; 0) { std::cerr \u0026lt;\u0026lt; \u0026#34;select() failed\\n\u0026#34;; } if (nfds == 0) { std::cerr \u0026lt;\u0026lt; \u0026#34;select() timeout\\n\u0026#34;; } // if \u0026gt; 0 for (int eventfd{}; eventfd \u0026lt;= max_fd; ++eventfd) { if (FD_ISSET(eventfd, \u0026amp;tmpfds) == 0) continue; // 发生事件的是 linsten socket，那么说明有新的客户端连接 if (eventfd == sockfd) { sockaddr_in client; socklen_t len = sizeof(sockaddr_in); int client_sock = accept(sockfd, (sockaddr*)\u0026amp;client, \u0026amp;len); if (client_sock \u0026lt; 0) { std::cerr \u0026lt;\u0026lt; \u0026#34;accept() failed\\n\u0026#34;; continue; } std::cout \u0026lt;\u0026lt; \u0026#34;accept client. socket = \u0026#34; \u0026lt;\u0026lt; client_sock \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // 把新连接的 socket 也要进行监听 FD_SET(client_sock, \u0026amp;fds); max_fd = std::max(max_fd, client_sock); } else { // 如果是客户端的 socket 发生事件， // 那么 1. 说明是接收到了数据; 2. 客户端断开连接 std::array\u0026lt;char, 1024\u0026gt; buf{}; // 客户端断开连接 if (read(eventfd, buf.data(), buf.size()) \u0026lt;= 0) { std::cout \u0026lt;\u0026lt; \u0026#34;Disconnected. socket = \u0026#34; \u0026lt;\u0026lt; eventfd \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; close(eventfd); FD_CLR(eventfd, \u0026amp;fds); // 恰好是最后一个客户端，那么就要重新计算 max_fd if (eventfd == max_fd) { for (int i = max_fd; i \u0026gt; 0; --i) { if (FD_ISSET(i, \u0026amp;fds)) { max_fd = i; break; } } } } else { // 如果客户端有数据发送 std::cout \u0026lt;\u0026lt; \u0026#34;client: \u0026#34; \u0026lt;\u0026lt; eventfd \u0026lt;\u0026lt; \u0026#34;\\nmsg: \u0026#34; \u0026lt;\u0026lt; buf.data(); write(eventfd, buf.data(), buf.size()); } } } } return 0; } select 遵循水平触发，fd 发生事件 select 就会返回通知；如果事件没有被处理，那么再次调用 select 也会返回。\n问题：\n轮询方式扫描 bitmap，socket一多性能就拉胯 每次都得拷贝 bitmap bitmap 数量有限制 poll 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 #include \u0026lt;poll.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;array\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026#34;util.hpp\u0026#34; int main(int argc, char* argv[]) { if (argc != 2) { std::cerr \u0026lt;\u0026lt; \u0026#34;Usage: ./select port\\n\u0026#34;; return -1; } int sockfd = socket_init(atoi(argv[1])); std::cout \u0026lt;\u0026lt; \u0026#34;Listen: \u0026#34; \u0026lt;\u0026lt; sockfd \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // fds 存放需要监视的 socket pollfd fds[1024]; // poll 会忽略 -1 的 socket for (int i{}; i \u0026lt; 1024; ++i) { fds[i].fd = -1; } // 监视 listen socket fds[sockfd].fd = sockfd; fds[sockfd].events = POLLIN; // POLLIN | POLLOUT int max_fd = sockfd; for (;;) { int nfds = poll(fds, 1024, -1); if (nfds \u0026lt; 0) { std::cerr \u0026lt;\u0026lt; \u0026#34;poll() failed.\\n\u0026#34;; } for (int eventfd{}; eventfd \u0026lt;= max_fd; ++eventfd) { if (fds[eventfd].revents \u0026amp; POLLIN == 0) continue; // 发生事件的是 linsten socket，那么说明有新的客户端连接 if (eventfd == sockfd) { sockaddr_in client; socklen_t len = sizeof(sockaddr_in); int client_sock = accept(sockfd, (sockaddr*)\u0026amp;client, \u0026amp;len); if (client_sock \u0026lt; 0) { std::cerr \u0026lt;\u0026lt; \u0026#34;accept() failed\\n\u0026#34;; continue; } std::cout \u0026lt;\u0026lt; \u0026#34;accept client. socket = \u0026#34; \u0026lt;\u0026lt; client_sock \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; fds[client_sock].fd = client_sock; fds[client_sock].events = POLLIN; max_fd = std::max(max_fd, client_sock); } else { // 如果是客户端的 socket 发生事件， // 那么 1. 说明是接收到了数据; 2. 客户端断开连接 std::array\u0026lt;char, 1024\u0026gt; buf{}; // 客户端断开连接 if (read(eventfd, buf.data(), buf.size()) \u0026lt;= 0) { std::cout \u0026lt;\u0026lt; \u0026#34;Disconnected. socket = \u0026#34; \u0026lt;\u0026lt; eventfd \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; close(eventfd); fds[eventfd].fd = -1; // 恰好是最后一个客户端，那么就要重新计算 max_fd if (eventfd == max_fd) { for (int i = max_fd; i \u0026gt; 0; --i) { if (fds[eventfd].fd != -1) { max_fd = i; break; } } } } else { // 如果客户端有数据发送 std::cout \u0026lt;\u0026lt; \u0026#34;client: \u0026#34; \u0026lt;\u0026lt; eventfd \u0026lt;\u0026lt; \u0026#34;\\nmsg: \u0026#34; \u0026lt;\u0026lt; buf.data(); write(eventfd, buf.data(), buf.size()); } } } } } poll 基本就是 select 的 plus 版，没啥太大区别\npoll 的数据结构是数组，在内核中为链表 调用一次 select 要拷贝两次 bitmap (自己拷贝一次，内核拷贝一次)，poll 要拷贝一次结构体数组 poll 没有 1024 限制，但也很烦 epoll LT 水平触发：不管是读事件还是写事件，只要有数据，那么调用 epoll_wait 就会通知，触发事件。\n也就是说，epoll 会一直通知你，直到你把数据发送/接收完。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 #include \u0026lt;sys/epoll.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;array\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026#34;util.hpp\u0026#34; int main(int argc, char* argv[]) { if (argc != 2) { std::cerr \u0026lt;\u0026lt; \u0026#34;Usage: ./select port\\n\u0026#34;; return -1; } int sockfd = socket_init(atoi(argv[1])); std::cout \u0026lt;\u0026lt; \u0026#34;Listen: \u0026#34; \u0026lt;\u0026lt; sockfd \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // 创建 epoll fd int epollfd = epoll_create(1); // 为服务端准备读事件 epoll_event ev; // 指定事件的自定义数据，会随 epoll_wait() 返回的事件一起返回 ev.data.fd = sockfd; ev.events = EPOLLIN; // 需要监听的 socket 加入 epoll epoll_ctl(epollfd, EPOLL_CTL_ADD, sockfd, \u0026amp;ev); // 事件数组，可以随意设置大小 epoll_event evs[10]; for (;;) { int nfds = epoll_wait(epollfd, evs, 10, -1); if (nfds \u0026lt; 0) { std::cerr \u0026lt;\u0026lt; \u0026#34;epoll_wait() failed.\\n\u0026#34;; break; } if (nfds == 0) { std::cerr \u0026lt;\u0026lt; \u0026#34;epoll_wait() timeout.\\n\u0026#34;; continue; } for (int i{}; i \u0026lt; nfds; ++i) { // 如果发生事件的是 sockfd 表示有新连接 if (evs[i].data.fd == sockfd) { sockaddr_in client; socklen_t len = sizeof(sockaddr_in); int client_sock = accept(sockfd, (sockaddr*)\u0026amp;client, \u0026amp;len); if (client_sock \u0026lt; 0) { std::cerr \u0026lt;\u0026lt; \u0026#34;accept() failed\\n\u0026#34;; continue; } std::cout \u0026lt;\u0026lt; \u0026#34;accept client. socket = \u0026#34; \u0026lt;\u0026lt; client_sock \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // 为新的连接准备事件 ev.data.fd = client_sock; ev.events = EPOLLIN; epoll_ctl(epollfd, EPOLL_CTL_ADD, client_sock, \u0026amp;ev); } else { // 如果是客户端的 socket 发生事件， // 那么 1. 说明是接收到了数据; 2. 客户端断开连接 std::array\u0026lt;char, 1024\u0026gt; buf{}; // 客户端断开连接 if (recv(evs[i].data.fd, buf.data(), buf.size(), 0) \u0026lt;= 0) { std::cout \u0026lt;\u0026lt; \u0026#34;Disconnected. socket = \u0026#34; \u0026lt;\u0026lt; evs[i].data.fd \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; close(evs[i].data.fd); // socket 关闭后会自动被删除 // epoll_ctl(epollfd, EPOLL_CTL_DEL, evs[i].data.fd, 0); } else { // 如果客户端有数据发送 std::cout \u0026lt;\u0026lt; \u0026#34;client: \u0026#34; \u0026lt;\u0026lt; evs[i].data.fd \u0026lt;\u0026lt; \u0026#34;\\nmsg: \u0026#34; \u0026lt;\u0026lt; buf.data(); send(evs[i].data.fd, buf.data(), buf.size(), 0); } } } } return 0; } ET 边缘触发：\n读事件：只有新的数据到达，才会触发读事件，不管有没有处理读事件，epoll_wait 对于每个事件只提醒一次。也就是说，如果数据没读完，那也不会再通知你；每次只会读 buffer 数量的数据（下一次有新数据时继续读）\n写事件：epoll_wait 触发写后，如果发送缓冲区仍然没有写满，那么就不会再次触发。发送缓冲区从满 -\u0026gt; 不满，才会触发写事件。\n监听 socket 采用边缘触发时，要使用非阻塞模式，否则会有 socket 在队列中没有被处理；然后使用循环。\n如果客户端连接进来的 socket 使用边缘触发，也要设置为非阻塞模式，之后循环调用 recv\nUDP 编程 以下是经典的 UDP 客户/服务器程序的函数调用。\n客户不与服务器建立连接，只是单纯使用 sendto() 发送数据报，必须指定目的地地址。类似地，服务器不接受连接，只是使用 recvfrom() 函数，等待某个客户端的数据到达。\n1 2 3 4 5 6 #include \u0026lt;sys/socket.h\u0026gt; ssize_t recvfrom(int sockfd, void* buff, size_t nbytes, int flags, struct sockaddr* from, socklen_t* addrlen); ssize_t sendto(int sockfd, void* buf, size_t nbytes, int flags, const struct sockaddr* to, socklen_t* addrlen); flag 以后再说。\n对于 UDP 来说，写一个长度为 0 的数据报是可以接受的，不像 TCP 中返回 0 代表关闭连接。\nUDP 层中隐含有排队情况发生，每个 UDP 套接字都有一个接收缓冲区，到达该套接字的每个数据报都进入这个套接字接受缓冲区。进程调用 recvfrom 时，缓冲区中的下一个数据包以 FIFO 顺序返回给进程。\n在进程能够读取该套接字中排队的数据之前，如果有多个数据包到达该套接字，那么只会到达缓冲区中，然而缓冲区大小有限。(SO_RECVBUF)\n众所周知 UDP 不可靠。举个例子，例如 echo 服务器。\n如果一个客户数据报丢失，客户就永远阻塞在 recvfrom 了，防止这样的办法一般是设置一个超时。\n如果服务器未启动就运行客户端会怎么样？sendto 可以发消息，但是会永远阻塞在 recvfrom。服务器主机会响应一个 port unreachable 错误的 ICMP 消息。不过这个不会返回给客户端进程。\n为什么呢？这种错误称为 异步错误。sendto 引起该错误，但其本身会返回成功。因为返回成功仅仅代表输出队列中存放了所形成的 IP 数据报，而 ICMP 则直到后来才返回。\n那该怎么办？使用 connect 函数。而 UDP socket 上使用 connect 只是检查是否存在立即可知的错误（例如一个不可达的目的地），然后返回给进程。我们必须区分：\n未连接 UDP socket，新建的 UDP socket 默认如此。 已连接 UDP socket，对 UDP socket 调用 connect 的结果。 对于已连接的 UDP socket，有几个变化：\n不能使用 sendto，而是使用 write 或者 send，写到已连接 UDP 套接字上的任何内容都自动发送到由 connect 指定的协议地址。 不能使用 recvfrom ，而是 read/recv或者 recvmsg。在已连接的 UDP socket 上，只会收到早先连接到的地址上的数据报。 已连接 UDP socket 引发的错误会返回给他们所在的进程。 在性能上，内核在连接的套接字上，只会复制一次地址信息，否则每次都要复制。\n","date":"2023-12-27T00:00:00Z","permalink":"https://rossqaq.github.io/article/io_multiplxer/","title":"select/poll/epoll 老三样"},{"content":"Back to Basics: Move Semantics - Nicolai Josuttis - CppCon 2021\nC++11 圣经之二 —— 移动语义。\n我感觉大多数人不懂移动语义。\n动机 首先来看当年的拷贝语义（C++98/03 年代）\n1 2 3 4 5 6 7 std::vector\u0026lt;std::string\u0026gt; coll; coll.reserve(3); // 假设返回的是一个很长的 string std::string s{getData()}; coll.push_back(s); coll.push_back(getData()); 在以前的 C++，getData() 会返回一个临时对象，然后再被拷贝过去，然后再自己销毁。这显然没有什么意义，\n在 C++ 11 之后，支持移动语义，那么编译器就不会再拷贝这个临时对象了，它只会 move 这个对象，类似于某些语言的浅拷贝。\n很正常，因为我们也不会使用这个临时对象。\n之后调用析构函数，不过它并不会释放任何内存，因为已经被移动走了，只是单纯的销毁临时对象。\n这里告诉我们，可以尽量使用不具有名字的对象。（亡值）\nstd::move 但显然，大部分时候对象都是具有名字的，不然会非常不方便管理。\n1 2 3 std::string str{getData()}; coll1.push_back(str);\t// copy, 之后仍然需要 str coll2.push_back(str);\t// copy, 之后不需要 str 如果对象有名字（左值），那么会默认拷贝。\n当你需要处理参数时：\n1 2 3 4 void reinit(std::string\u0026amp; s) { history.push_back(s);\t// copy, 但你不需要 str 了 s = getDefaultValue(); } 为了处理这些情况，我们有了函数 std::move\n**std::move：我不再会需要这些值了。**move，并不 move，move 在语义上表示的是，你不再需要某些变量存在了。\n1 2 3 std::string str{getData()}; coll1.push_back(str);\t// copy, 之后仍然需要 str coll2.push_back(std::move(str));\t// move, 之后不需要 str 那么回到之前的例子，有一个有趣的问题。\n1 2 3 4 5 6 7 std::vector\u0026lt;std::string\u0026gt; coll; coll.reserve(3); // 假设返回的是一个很长的 string std::string s{getData()}; coll.push_back(s); coll.push_back(std::move(s));\t// move move 后 s 的状态是什么？\nC++ 标准保证，对于 标准库 组件，move 后其处于 valid but unspecified 状态。具体能否使用要依赖实现。\n1 2 std::cout \u0026lt;\u0026lt; s; // ok, some value int i = s.size()\t// ok, 但你不知道 i 是什么 你可以 reuse move 后的对象\n1 2 3 4 5 std::vector\u0026lt;std::string\u0026gt; allRows; std::string row; while (std::getline(myStream, row)) { allRows.push_back(std::move(row)); } 右值引用 在 C++03：\n容器全部都是值语义\n新的元素会被拷贝进入容器 不会修改传递的参数 在 C++11 后：\n使用右值引用你可以选择移动语义\n右值引用绑定给右值：\ncaller 不再需要 value 可能会 steal （代表 no const）但仍 valid 移动语义通常使用以下实现：\n移动构造（优化拷贝）\n移动赋值运算符（优化拷贝）\nsteal 原来的对象，但仍然保持其 valid\n引用的重载 1 void foo(const T\u0026amp;);\t// 只读 可以绑定所有变量 不会拷贝 1 void foo(T\u0026amp;);\t// 写 只能绑定 non-const 左值引用对象 可以更改对象 1 void foo(T\u0026amp;\u0026amp;);\t// move 传入一个你不再会使用的值 使用 std::move() 或者 临时对象 1 void foo(const T\u0026amp;\u0026amp;)\t// 语义冲突，不明觉厉 已经有 const T\u0026amp; 了为啥用这个？ 类的移动语义 基本的移动支持 标准库保证：除非有其他的指明，否则默认的 moved-from 对象之后应该是 valid but unspecified 状态。\n如果没有提供移动支持，那么会使用 copy 作为 fallback，当然你也可以选择 disable 这个。通常 move-only 类型是这么干的，比如 std::thread, std::unique_ptr\n默认的移动语义支持：自动生成移动构造、移动赋值运算符，除非\n没有用户声明的复制构造函数 没有用户声明的复制赋值运算符 没有用户声明的析构函数 注意，用户声明包括 =default 这种，用户提供不包括。此外，=default =delete 都是函数定义。\n此外，注意写 noexcept，vector 这样的容器在 resize 扩容时会使用 std::move_if_noexcept，来决定是调用移动还是拷贝构造。\n多态类型中的移动 声明虚析构函数会抑制移动的生成。\n完美转发 考虑以下情况，\n1 2 3 4 5 6 7 8 9 10 11 12 class C {...}; void foo(const C\u0026amp;); void foo(C\u0026amp;); void foo(C\u0026amp;\u0026amp;); C v; const C c; foo(v);\t//-\u0026gt; foo(C\u0026amp;) foo(c);\t//-\u0026gt; foo(const C\u0026amp;) foo(C{});\t//-\u0026gt; foo(C\u0026amp;\u0026amp;) foo(std::move(v))\t//-\u0026gt; foo(C\u0026amp;\u0026amp;) 完美，没有问题。\n那么假设我们需要一个中间层来调用 foo，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 class C {...}; void foo(const C\u0026amp;); void foo(C\u0026amp;); void foo(C\u0026amp;\u0026amp;); void callFoo(const C\u0026amp; x) { foo(x);\t//-\u0026gt; foo(const C\u0026amp;) } void callFoo(C\u0026amp; x) { foo(x);\t//-\u0026gt; foo(C\u0026amp;) } void callFoo(C\u0026amp;\u0026amp; x) { foo(std::move(x));\t//-\u0026gt; foo(C\u0026amp;\u0026amp;) } C v; const C c; callFoo(v);\t//-\u0026gt;foo(C\u0026amp;) callFoo(c);\t//-\u0026gt;foo(const C\u0026amp;) callFoo(C{});\t//-\u0026gt;foo(C\u0026amp;\u0026amp;) callFoo(std::move(v)) //foo(C\u0026amp;\u0026amp;) 我们自然不想写三个重载，可以使用模板，那样就需要使用完美转发。\n想使用模板转发，那么你需要：\n模板参数 模板形参声明为 \u0026amp;\u0026amp; 1 2 3 4 template\u0026lt;typename T\u0026gt; void callFoo(T\u0026amp;\u0026amp; arg) { foo(std::forward\u0026lt;T\u0026gt;(arg)); } arg 称为 universal (or forwarding) reference\nemplace 中的完美转发 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 template\u0026lt;typename T, ...\u0026gt; class vector { public: ... template\u0026lt;typename... Args\u0026gt; void emplace_back(Args\u0026amp;\u0026amp;... args) { place_element_in_memory( T(std::forward\u0026lt;Args\u0026gt;(args)...) ); } }; class Cust { private: std::string first; std::string last; int val; public: Cust(...)...{} } std::string first{\u0026#34;Jil\u0026#34;}; std::string last{\u0026#34;Cook\u0026#34;}; std::vector\u0026lt;Cust\u0026gt; cv; cv.emplace_back(std::move(first), last, 39); // 不需要 first，直接移动 // last 拷贝 // 39 拷贝 完美转发返回值 如果你想对返回值使用完美转发，那么\n声明返回值为 auto\u0026amp;\u0026amp; 也是万能引用 forward 1 2 3 4 5 6 7 8 // 直接使用 process(compute(t)); // 或者如果你需要使用参数的话: auto\u0026amp;\u0026amp; val = compute(t); ...; process(std::forward\u0026lt;decltype(val)\u0026gt;(val)); 万能引用可以存储一切，包括引用性和常量性。\nranges 和完美转发 const views 可能不支持迭代，因为迭代中他们可能修改自身的状态。这时你需要万能引用 1 2 3 4 5 6 7 8 9 10 11 12 13 template\u0026lt;typename T\u0026gt; void print(const T\u0026amp; coll) {\t// 将其改为 T\u0026amp;\u0026amp; 即可 for (const auto\u0026amp; elem : coll) { std::cout \u0026lt;\u0026lt; elem \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } } std::vector vec{1, 2, 3, 4, 5}; print(vec);\t// ok print(vec | std::views::drop(3));\t// ok print(vec | std::views::filter(...));\t// bad std::list lst{1, 2, 3, 4, 5}; print(lst | std::views::drop(3));\t// bad ","date":"2023-12-27T00:00:00Z","image":"https://rossqaq.github.io/article/cppcon-2021-move-semantics/cppcon2021-cover_hu12c72e74cc107b1dec0a72d3e09dd6fc_58474_120x120_fill_box_smart1_3.png","permalink":"https://rossqaq.github.io/article/cppcon-2021-move-semantics/","title":"移动语义"},{"content":"CppCon 2019: Arthur O\u0026rsquo;Dwyer “Back to Basics: Smart Pointers”\nC++11 的面试圣经 —— 智能指针\n我发现这个人讲的还是不错的，就是语速太快……不过好在他的 lecture 都有官方字母。\n智能指针发展历史 auto_ptr : C++98 的遗老，C++17被移除\nunique_ptr: C++11. 用来替代 auto_ptr，C++14 加入了 std::make_unique()\nshared_ptr: C++11. 引用计数，支持std::make_shared() 。C++17 加入了 std::shared_ptr\u0026lt;T[]\u0026gt;\nweak_ptr : C++11. 弱引用。\nC++20 : std::make_shared\u0026lt;T[]\u0026gt;\nstd::unique_ptr ：独占所有权 std::unique_ptr 可以自动替你管理资源。\n原始指针是可以拷贝的，那么如果我拷贝了原始指针，那么谁来清理资源呢？这个不太好说。\nstd::unique_ptr 是 move-only，它的移动构造会将原来的指针置为 nullptr。\n只有一个指针指向资源，std::unique_ptr 会自动帮你管理资源。\n此外，std::unique_ptr 有一个对 T[] 的特化：\n1 2 3 4 5 6 7 8 template\u0026lt;typename T\u0026gt; class unique_ptr\u0026lt;T[]\u0026gt; { T* p_ {nullptr}; ~unique_ptr() { delete [] p_; } }; std::unique_ptr 还有一个模板参数：Deleter。你可以显式的传入一个 deleter。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 template\u0026lt;typename T, typename Deleter = std::default_delete\u0026lt;T\u0026gt;\u0026gt; class unique_ptr { T* p_{nullptr}; Deleter d_; ~unique_ptr() { if (p_) d_(p_); } }; template\u0026lt;typename T\u0026gt; struct default_delete { void opeartor()(T *p) const { delete p; } }; 假设我们使用一个 FILE*\n1 2 3 4 5 6 7 8 9 struct FileCloser { void operator()(FILE* fp) const { assert(fp != nullptr); fclose(fp); } }; FILE *fp = fopen(\u0026#34;input.txt\u0026#34;, \u0026#39;r\u0026#39;); std::unique_ptr\u0026lt;FILE, FileCloser\u0026gt; uptr(fp); 这样的话可以更加异常安全，而且可以完美适配 C API。\n如果你使用类似于 OpenSSL 这样的 C API 的话，就可以使用这个用法。unique_ptr 可以作为 low-level (C API), non-RAII, raw resource 和 高级 API 间的粘合剂。\n使用智能指针时的推荐做法 像对待裸指针一样对待智能指针 pass by value return by value（当然） 对指针传引用太异味了，自然对智能指针也是 如果一个函数接受 unique_ptr by value，那么意味着所有权的转移 智能指针通常作为实现细节以及胶水 在接口中暴露 unique_ptr/shared_ptr 有点 code smell，你应该把他们放在类里。 std::shared_ptr：共享所有权 控制块 std::shared_ptr 代表共享所有权，使用 引用计数 实现。计数归零就会析构对象。引用计数可以使用一个 std::atomic\u0026lt;int\u0026gt;\n对于一个 std::shared_ptr ，一般有两个成员，一个指向被管理对象的指针，另外一个指向控制块（control block）的指针。\n控制块包含：引用计数、弱引用计数、自定义 deleter、指向管理对象的指针。\n每个被管理的对象拥有一个控制块。\n拷贝 shared_ptr，会拷贝两个指针，然后引用计数 +1。如果销毁 shared_ptr ，引用计数 -1\nshared_ptr 通过控制块参与所有权的管理。\n那么为什么控制块要有一个指向控制对象的指针呢？\n类的布局 考虑以下的结构：\n1 2 3 4 struct Fruit {int juice;}; struct Vegetable {int fiber;}; struct Apple : Fruit {int red;}; struct Tomato : Fruit, Vegetable {int sauce;}; Apple 继承 Fruit，实际上的布局大概是 |juice|red| 这样。\n类似的，Tomato 大概是 |juice|fiber|sauce|\nApple is a Fruit，也就是说我有一个指向 Apple 的指针的同时也代表了指向 Fruit，先是 Fruit 的成员之后才是 Apple 的成员。\nTomato 类似。\n就是说，如果我有一个 std::shared_ptr\u0026lt;Fruit\u0026gt; 和一个 std::shared_ptr\u0026lt;Vegetable\u0026gt;，他们都指向了 Tomato。指向 vegetable 的那个指针会有一些偏移。并没有指向直接需要管理的对象。\n所以控制块中需要一个指针来决定对谁来执行 delete，在这里就是保存一个 tomato 对象的指针。\nshared_ptr 的 aliasing construct 1 2 3 4 5 6 7 8 9 10 11 12 13 using Vec = std::vector\u0026lt;int\u0026gt;; std::shared_ptr\u0026lt;int\u0026gt; foo() { auto elts = {1, 2, 3, 4, 5}; std::shared_ptr\u0026lt;Vec\u0026gt; pvec = std::make_shared\u0026lt;Vec\u0026gt;(elts); return std::shared_ptr\u0026lt;int\u0026gt;(pvec, \u0026amp;(*pvec)[2]);\t// 与 pvec 共享所有权，但指向 \u0026amp;(*pvec)[2] } int main() { std::shared_ptr\u0026lt;int\u0026gt; ptr = foo(); for (int i = -2; i \u0026lt; 3; ++i) { std::cout \u0026lt;\u0026lt; ptr.get()[i] \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } } 在以上的代码中，shared_ptr 中指向对象的成员指针指向的是 vec[2]，但控制块中的指针指向的是 vector\n最后一个 shared_ptr 销毁时就会销毁 vector\n优先选择 make_unique()/make_shared() 现代 C++ 的目的之一就是，没有 new/delete 出现，且只调用 new 看起来也很难受。\n比如下面这样：\n1 2 std::shared_ptr\u0026lt;Widget\u0026gt; w(new Widget()); use(w) 也就是说，如果没调用 delete，那也应该尽量避免 new。标准库所以提供了 make_foo()\n1 2 auto w = std::make_shared\u0026lt;Widget\u0026gt;(); use(w); make_shared 也可以被优化，可以少一次内存分配，现在的库基本都能做到。例如：\n1 2 3 4 5 template\u0026lt;typename T, typename... Args\u0026gt; std::shared_ptr\u0026lt;T\u0026gt; make_shared(Args\u0026amp;\u0026amp;... args) { auto* raw_ptr = new ControlBlockAnd\u0026lt;T\u0026gt;(std::forward\u0026lt;T\u0026gt;(args)...); return std::shared_ptr\u0026lt;T\u0026gt;::From(raw_ptr); } 总之：\n多使用 make_shared/make_unique 避免 new 你不 new 就不会内存泄漏 make_shared 可以优化 顺便，unique_ptr 可以隐式转换为 shared_ptr\n1 std::shared_ptr\u0026lt;Widget\u0026gt; sptr = std::make_unique\u0026lt;Widget\u0026gt;(); std::weak_ptr：解决 shared_ptr 的悬垂 weak_ptr 在内存上看和 shared_ptr 差不多，都有一个指向管理对象的指针和一个指向控制块的指针。\n区别在于，如果你拷贝 weak_ptr ，那么它会增加 弱引用计数 。\n如果引用计数归零，那么对象会被销毁，而此时如果弱引用计数不为0，就会出现 weak_ptr 悬垂。shared_ptr 知道控制块还有 weak_ptr 在使用，所以也不会销毁控制块。\n你并不能解引用 weak_ptr weak_ptr 并不是指针，它只是你在未来构造 shared_ptr 时的门票。 你可以显式类型转换，或者调用 weak_ptr.lock()，虽然不会 lock 任何东西，它只是会返回一个 shared_ptr（如果对象没有被销毁的话） 如果想 get a ticket，那么只能使用显式类型转换 1 2 3 4 5 6 7 void recommended(std::weak_ptr\u0026lt;T\u0026gt; wptr) { // std::shared_ptr\u0026lt;T\u0026gt; sptr{wptr}; 不要这么做 std::shared_ptr\u0026lt;T\u0026gt; sptr = wptr.lock(); if (sptr != nullptr) { use(sptr); } } 其实可以在 if 语句内直接声明（这也是 if 内声明有用的几个情景之一）\n1 2 3 if (auto sptr = wptr.lock()) { use(sptr); } 顺便一提，另一个情景是 RTTI\n1 2 3 if (RedWidget *p = dynamic_cast\u0026lt;RedWidget*\u0026gt;(widgetpr)) { use_red_widget(p); } 通过 raw ptr 获得 shared_ptr 我们之前说 weak_ptr 是 ticket for shared_ptr，那么如果你只有一个裸指针怎么办？\n1 2 3 4 5 6 7 class Widget { std::weak_ptr\u0026lt;Widget\u0026gt; wptr_ = ???; public: std::shared_ptr\u0026lt;Widget\u0026gt; shared_from_this() const { return wptr.lock(); } }; 自然我们不会每次都自己写，所以我们把 weak_ptr 放到基类，叫做 std::enable_shared_from_this，他的作用就是提供 shared_from_this() 成员函数。\n这个你自己是实现不了的，因为它跟 shared_ptr 的构造函数有关联。\n它使用的是 CRTP 模式。\ntrick 的是 Widget 的 shared_from_this() 成员函数返回的是 shared_ptr\u0026lt;Widget\u0026gt;。我们通过某种方式，让基类知道了子类的名字。方法是我们让 base 类是一个模板，模版参数是子类的名字。这样的话，Widget 继承自 std::enable_shared_from_this\u0026lt;Widget\u0026gt;，这样就可以了。 ","date":"2023-12-25T00:00:00Z","image":"https://rossqaq.github.io/article/cppcon-2019-smart-pointers/cppcon2019-cover_hu93d2f8befaf9243db44dc194e94262d5_58262_120x120_fill_box_smart1_3.png","permalink":"https://rossqaq.github.io/article/cppcon-2019-smart-pointers/","title":"智能指针"},{"content":"Lecture: Back to Basics: RAII and the Rule of Zero - Arthur O\u0026rsquo;Dwyer - CppCon 2019\nSlides PDF\nRAII 即：Resource Acquisition Is Initialization，资源获取即初始化。\n不会 RAII 等于不会 C++。\t—— Roses\n资源 Resource 资源代表某些我们需要手动管理的东西。C++ 中常见的资源有：\n分配的内存（malloc/free, new/delete, new[]/delete[]） POSIX 文件句柄 （open/close） C 文件句柄（fopen/fclose） mutex 锁 C++ 线程 我们无需关心资源是否唯一（例如mutex 的设计就是唯一的，而分配的内存显然可以拥有拷贝）\n我们需要关心的是程序中需要 显式 使用某些操作来 释放 资源\n之后会一直使用堆分配的内存作为例子。\n以 naive vector 为例 基础实现 1 2 3 4 5 6 7 8 9 10 11 12 13 class NaiveVector { int* ptr_; size_t size_; public: NaiveVector() : ptr_(nullptr), size_(0) {} void push_back(int value) { int* new_ptr = new int[size_ + 1]; std::copy(ptr_, ptr_ + size, new_ptr); delete[] ptr_; ptr_ = new_ptr; ptr_[size_++] = value; } }; 这里 push_back 先分配内存，再将原来的数据进行拷贝，最后写入新的数据，释放原来位置的内存，看起来没有问题。\n考虑以下使用\n1 2 3 4 5 { NaiveVector vec; vec.push_back(1); vec.push_back(2); } 这里，出作用域后，vec 的内存并没有被释放，显然是发生内存泄漏了。\n也就是说，需要在 vector 的生命周期结束时，释放其拥有的内存。\n析构函数 众所周知，在创建一个类类型的对象时，编译器会调用某个构造函数；在一个类类型对象的生命周期结束时，编译器会调用析构函数。\n在 C++ 中，常用的限制某对象生命周期的方法就是使用一个大括号。\n1 2 3 { NaiveVector vec;\t// 调用构造函数 }\t// 调用析构函数 1 2 3 4 5 6 class NaiveVector { ... public: ... ~NaiveVector() {delete[] ptr_;} }; 现在 NaiveVector 就不会在被销毁时发生内存泄漏了。\n拷贝构造函数 考虑代码：\n1 2 3 4 5 6 7 8 { NaiveVector v; v.push_back(1); { NaiveVector w = v;\t//(1) } std::cout \u0026lt;\u0026lt; v[0]; } 在 (1) 处调用了编译器自动生成的拷贝构造函数，默认的拷贝构造函数只是单纯的拷贝每个成员，这会导致二者持有指向同一块内存的指针，w 析构时内存会被释放，此时 v 访问的是已经被释放的内存。\n(1) 处的操作某些语言称之为“浅拷贝”。\n需要注意的是，C++ 的设计哲学使得类对象应该具有值语义（标准库组件也是这么做的）。\n换句话说，对对象进行拷贝应该像拷贝 int 等类型一样，进行“深拷贝”而不是所谓“浅拷贝”。\n我其实并不想用在 C++ 中用这两个词语来描述，只是这样更容易理解。\n这也是为什么 C++ 提供了拷贝构造函数的原因。你需要他来为资源创建副本。\n我们来实现他：\n1 2 3 4 5 6 7 8 9 10 11 12 class NaiveVector { ... public: NaiveVector() : ptr_(nullptr), size_(0) {} ~NaiveVector() {delete[] ptr_;} ... NaiveVector(const NaiveVector\u0026amp; rhs) { ptr_ = new int[rhs.size_]; size_ = rhs.size_; std::copy(rhs.ptr_, rhs.ptr_ + size_, ptr_); } }; 初始化不是赋值 1 NaiveVector w = v;\t// 调用拷贝构造，创建一个新的对象 1 2 NaiveVector w; w = v;\t// 对 w 的赋值，调用赋值运算符 这个问题似乎困扰了很多初学者，虽然看起来都使用了 = ，但实际不是一回事。\n实际很容易理解，初始化时 w 什么都没有，自然需要构造，自然调用的是拷贝构造函数。\n而在赋值时，w 已经是初始化结束的，或者被使用过的，内部已经存在数据了，可能需要对其进行其他处理，故自然不能调用拷贝构造，需要使用赋值运算符。\n1 2 3 4 5 6 7 8 9 { NaiveVector v; v.push_back(1); { NaiveVector w; w = v; } std::cout \u0026lt;\u0026lt; v[0]; } 编译器默认生成的赋值运算符也是单纯的拷贝赋值所有数据成员，所以我们也需要实现他。\n1 2 3 4 5 6 7 8 9 10 11 12 13 class NaiveVector { ... public: NaiveVector() : ptr_(nullptr), size_(0) {} ~NaiveVector() {delete[] ptr_;} NaiveVector(const NaiveVector\u0026amp; rhs) {...} ... NaiveVector\u0026amp; operator=(const NaiveVector\u0026amp; rhs) { NaiveVector copy = rhs; copy.swap(*this);\t// copy and swap，我们需要实现 swap return *this; } }; 记住：\n当你提供了析构函数时，大概率也需要提供一个拷贝构造函数 和 一个拷贝赋值运算符 析构函数的职责是防止资源泄漏，拷贝构造函数的职责是防止 double free 这些规则适用于内存等任何你需要手动管理的资源 The Rule of Three 如果你的类直接管理某些资源（见上文），你需要提供以下三个成员函数：\n析构函数，用于释放资源\n拷贝构造函数，用于拷贝资源，同时防止 double free\n拷贝赋值运算符，释放 left-hand 资源，并拷贝 right-hand 资源\n推荐使用 copy-and-swap 技巧来实现赋值。\n原因在于，手动实现不能很好的处理嵌套结构中 self-assignment 的情况。[关于自赋值的检测 重载operator=要不要检查自赋值？ - mq白]\n使用 copy-and-swap 可以防止你在自赋值一些复杂的嵌套数据结构时爆炸。\n1 2 3 4 5 NaiveVector\u0026amp; NaiveVector::operator=(const NaiveVector\u0026amp; rhs) { NaiveVector copy(rhs); copy.swap(*this); return *this; } 先对 rhs 做个拷贝，这样不管是任何的引用关系还是所有权，都不会对我们造成影响。\nRAII 与异常安全 虽然 RAII 是关于初始化的，但实际上他真正的意思是 cleanup\n也许应该 RAII 应该称作：Resource Freeing Is Destruction\n析构函数帮助我们的程序在异常状态下也能稳定运行。\nC++支持 try/catch 以及 throw 异常抛出时，runtime 在调用者栈中查找一个与异常类型对应的 catch，假设他找到的话…… runtime 进行 stack unwinding。对于每个 throw 和 catch 之间的 local scope 中的变量调用析构函数 为避免泄漏，请在析构函数中清理你的代码 1 2 3 4 5 6 7 8 9 int main() { try { int* arr = new int[4]; throw std::runtime_error(\u0026#34;BAD RAII Example\u0026#34;); delete[] arr;\t// 无法执行的 cleanup } catch (const std::exception\u0026amp; ex) { std::cout \u0026lt;\u0026lt; \u0026#34;Exception: \u0026#34; \u0026lt;\u0026lt; ex.what() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } } 这里调用了 new，如果发生了异常，那么无法执行 delete，无法 cleanup，就会造成内存泄漏。\n我们要做的是写一个自己的 RAII 类型\n1 2 3 4 5 6 7 8 9 10 11 12 13 struct RAIIPtr { int* ptr_; RAIIPtr(int* p) : ptr_(p) {} ~RAIIPtr() {delete[] ptr_;} }; int main() { try { RAIIPtr arr = new int[4]; throw std::runtime_error(\u0026#34;example\u0026#34;); } catch (const std::exception\u0026amp; ex) { std::cout \u0026lt;\u0026lt; \u0026#34;Exception: \u0026#34; \u0026lt;\u0026lt; ex.what() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } } 把 delete 放入析构函数，发生异常时进行 stack unwinding 会析构 RAIIPtr，此时会正确调用。\n但实际上 RAIIPtr 还是很危险，因为他有默认拷贝构造函数（没有遵循 Rule of Three）。\n如果我们不想让 RAIIPtr 允许被拷贝，那么可以将其拷贝构造函数、拷贝赋值运算符都声明为 = delete 。\nThe Rule of Zero 如果你的类没有 直接 管理某些资源，只是单纯用了一些库组件，例如 std::vector 或者 std::string ，那么你 不 应该写特殊成员函数， 直接声明他们为 default。\n让编译器自动生成那些函数即可。\n你也可以自己写 swap，也许会提高一些性能（编译器会ADL查找非成员函数的 swap）\n(这里的意思是针对那 5 个成员函数，而不是针对构造函数，你可以实现一些构造函数，不会打破 rule of zero.)\n尽可能多选择 Rule of Zero 以下两种值语义的类都是 well-designed :\nBusiness-logic classes，不管理任何资源，遵循 Rule of Zero\n他们把管理资源的工作 委托 给数据成员，例如类中使用 std::string, std::vector, std::unique_ptr 等。这些类默认都遵守 RAII。\nResource-management classes(small, single-purpose), 遵循 Rule of Three\n构造函数获取资源，析构函数释放资源，在赋值运算符中 copy-and-swap 以及其他特殊成员函数\nThe Rule of Five 在 C++11 之后，有了移动语义加持，我们引入了 The rule of five.\n如果你的类直接管理某些资源（例如 new 出的指针），那么你需要手写五个特殊成员函数来确保正确的行为：\n析构函数 释放资源 拷贝构造函数 拷贝资源 移动构造函数 转义资源的所有权 拷贝赋值运算符 释放 left-hand 资源，拷贝 right-hand 资源 移动赋值运算符 释放 left-hand 资源，将 right-hand 的资源所有权转移 根本原因是用户定义（或者声明为 =default, = delete）的构造函数、拷贝构造函数、拷贝赋值运算符，都会阻止移动构造和移动赋值的生成，所以支持移动语义的类都需要你手动写出所有的特殊成员函数。\n所有权，ownership，C++11之后 std::unique_ptr 等即代表独占所有权，配合移动语义，是一个较为重要的概念。但也有人不太喜欢这种说法。\n隔壁 rust 好像很喜欢。\n赋值运算符很容易出错，所以活用 copy-and-swap\n那么移动赋值运算符怎么写 copy-and-swap 呢？\n1 2 3 4 5 NaiveVector\u0026amp; NaiveVector::opeartor=(NaiveVector\u0026amp;\u0026amp; rhs) { NaiveVector copy(std::move(rhs)); copy.swap(*this); return *this; } The Rule of Four(and a half) By-value 的赋值运算符？ 虽然看似传值可以行为正确，但 STL 总是分开写移动和复制，所以你也应该将他们分开。更不能把 operator= 写成模板函数。\nThe Rule of Four (and a half) 如果你的类直接管理某些资源（例如 new 出的指针），那么你需要手写四个特殊成员函数来确保正确的行为\n析构函数 释放资源 拷贝构造函数 拷贝资源 移动构造函数 转义资源的所有权 By-value 的赋值运算符，释放 left-hand 资源，转移 right-hand 资源的所有权 1/2 - （非成员 swap 函数，理想情况下还要有一个成员函数版本）\ncopy-and-swap 你需要编写一个 swap 函数才能实现 copy-and-swap，不然要么编译错误，要么使用 std::swap\n那 std::swap 干了什么？\n调用移动构造，调用移动赋值，再调用一次移动赋值。\n如果你的赋值运算符的实现使用了 swap，然后还调用了 std::swap，然后 std::swap 又调用你的移动赋值运算符。恭喜你。\n所以强烈推荐你，如果使用 copy-and-swap，那么就自己实现一个 swap 函数。\n不再 Naive 的 vector 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 class NaiveVector { int* ptr_; size_t size_; ... Vec(const Vec\u0026amp; rhs) { ptr_ = new int[rhs.size_]; size_ = rhs.size_; std::copy(rhs.ptr_, rhs.ptr_ + size_, ptr_); } Vec(Vec\u0026amp;\u0026amp; rhs) noexcept { ptr_ = std::exchange(rhs.ptr_, nullptr); size_ = std::exchange(rhs.size_, 0); } // 两个参数的 swap，让你的类 std::swappable friend void swap(Vec\u0026amp; a, Vec\u0026amp; b) noexcept { a.swap(b); } ~Vec() { delete[] ptr_; } Vec\u0026amp; operator=(const Vec\u0026amp; vec) { Vec copy(vec); copy.swap(*this); return *this; } Vec\u0026amp; operator=(Vec\u0026amp;\u0026amp; vec) noexcept { Vec copy(std::move(vec)); copy.swap(*this); return *this; } void swap(Vec\u0026amp; rhs) noexcept { using std::swap; swap(ptr_, rhs.ptr_); swap(size_, rhs.size_); } }; std::exchange，以 new_value 替换 obj 的值，并返回 obj 的旧值。\n注意两个参数的 swap，这里使用了叫 \u0026ldquo;hidden friend idiom\u0026rdquo;。\n让两个参数的 swap 被 friend 标记，这样编译器就知道他不是成员函数（不是成员函数所以需要两个参数），这个 swap 支持 ADL 查找。这里他唯一做的就是调用一下成员函数 swap。\n管理资源类的例子 std::unique_ptr 以 std::unique_ptr 为例，它管理了堆内存的裸指针。\n构造函数释放资源 对裸指针调用 delete 拷贝构造函数复制资源 显然不应该复制，它独占了这个资源的所有权。故 =delete 移动构造函数转移资源所有权 转移裸指针，确保 rhs 清空 拷贝赋值运算符释放 left-hand 资源，并复制 right-hand 资源 同拷贝构造 移动赋值运算符释放 left-hand 资源，并转移 right-hand 资源所有权 对 left-hand 调用 delete，转移 right-hand 资源并情况 std::shared_ptr 以 std::shared_ptr 为例，它管理的是引用计数。\n构造函数释放资源 减少引用计数（清理资源，如果引用计数归零） 拷贝构造函数复制资源 增加引用计数 移动构造函数转移资源所有权 保持引用计数不变，释放（disengages）右侧 拷贝赋值运算符释放 left-hand 资源，并复制 right-hand 资源 减少 left-hand 引用计数，增加 right-hand 引用计数 移动赋值运算符释放 left-hand 资源，并转移 right-hand 资源所有权 减少引用计数，释放（disengages）右侧 “盗取”暗示了“空”状态 每个例子的移动操作，都释放了右侧的资源，也就是清空右侧状态。\n如果你忘了，那么可能会 double-free\n如果你忘记 destroy 右侧的对象，那么他可能就会处于空状态。\n你可以只做 copy 和 destroy，如果你的对象复制开销不大的话。\n当然 RAII 也可以 只 用于 destroy，单纯 =delete 你的复制和移动操作，就像 std::lock_guard\n","date":"2023-12-23T00:00:00Z","image":"https://rossqaq.github.io/article/cppcon-2019-raii/cppcon2019-cover_hu93d2f8befaf9243db44dc194e94262d5_58262_120x120_fill_box_smart1_3.png","permalink":"https://rossqaq.github.io/article/cppcon-2019-raii/","title":"RAII and the Rule of Zero"},{"content":"终于，经过几天的折腾，拥有了自己的博客。\n这里应该会记录关于我的一切，如果我想的话。\n但重要的自然是 C++。\n不应该忘记 2023.12.31 第一次应酬。印象深刻的跨年。酩酊大醉。\n2024.02.07 半年的实习结束了。不知道是否会回来。\n2024.03.02 世界上竟然真的有如此相似的二人。我遇到了她。\n我比她大了 3 岁，我们会向他人展示什么才是正确的异地恋、什么才是真正的喜欢以至于什么才是真正的爱。\n2024.05.13 找到了心怡的工作；毕业答辩结束；大学生涯要结束了。\n","date":"2023-12-18T00:00:00Z","image":"https://rossqaq.github.io/article/hello-world/cover_hu5d5eb0f05aa04cf7de0e6f7010329196_920962_120x120_fill_box_smart1_3.png","permalink":"https://rossqaq.github.io/article/hello-world/","title":"Hello Hugo"},{"content":"","date":"0001-01-01T00:00:00Z","permalink":"https://rossqaq.github.io/article/","title":""}]